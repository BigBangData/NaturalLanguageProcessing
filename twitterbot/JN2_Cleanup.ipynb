{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checklist**\n",
    "\n",
    "- check for dupes in ingestion? \n",
    "    - not needed, no dupes, and text dupes should be checked after cleaning\n",
    "- use textBlob as yet another way to perform basic sentiment analysis?\n",
    "    - yes, TODO, but maybe not during cleanup\n",
    "- create an incremental cleanup module?\n",
    "    - overkill, just reprocess everything bc of dupes, \n",
    "      script takes 8 secs for 20k tweets, that's ~6 min for a million if linear\n",
    "- improve script?\n",
    "    - add logs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "\n",
    "import string\n",
    "import datetime\n",
    "import urlextract\n",
    "import pandas as pd\n",
    "\n",
    "from html import unescape\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_todays_data():\n",
    "    filepath = os.path.join(\"..\",\"data\",\"1_raw\",\"tweets\")\n",
    "    today_prefix = datetime.datetime.now().strftime(\"%Y%m%d\")\n",
    "    dfm = []\n",
    "    for f in os.listdir(filepath):\n",
    "        if re.match(today_prefix, f):\n",
    "            dfm.append(pd.read_csv(os.path.join(filepath, f)))\n",
    "    df = pd.concat(dfm)\n",
    "    df = df.reset_index(drop=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_todays_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24800, 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test for duplicated IDs\n",
    "ids = df[\"ID\"]\n",
    "df[ids.isin(ids[ids.duplicated()])].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6358, 5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test for duplicated Text\n",
    "txt = df[\"Text\"]\n",
    "df[txt.isin(txt[txt.duplicated()])].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AlluArjun373788</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loveme134340x</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CParambarai</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ezeaccountant80</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lady_Minna</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ID\n",
       "User               \n",
       "AlluArjun373788   9\n",
       "loveme134340x     6\n",
       "CParambarai       4\n",
       "ezeaccountant80   3\n",
       "Lady_Minna        3"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at users with more than 1 tweet?\n",
    "grouped = df[['User', 'ID']].groupby('User').count().sort_values('ID', ascending=False)\n",
    "\n",
    "grouped[grouped['ID']>1].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding Retweet Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_retweet(col):\n",
    "\n",
    "    for i in range(len(col)):\n",
    "        if re.match(r'^RT', col) is not None:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0      \n",
    "        \n",
    "def map_is_retweet(col):\n",
    "   \n",
    "    bool_map = map(lambda x: is_retweet(x), col)       \n",
    "    return(list(bool_map)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Retweet'] = map_is_retweet(df['Text'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup_tweet(tweet):\n",
    "    \"\"\"Cleans up a tweet with the following steps:\n",
    "        1. make lower case\n",
    "        2. remove URLs\n",
    "        3. unescape HTML entities\n",
    "        4. remove user references (including username) or hashtags, etc.\n",
    "        5. remove punctuation\n",
    "        6. remove emojis\n",
    "        7. discard non-ascii decodable text after utf-8 encoding\n",
    "        8. tokenize\n",
    "        9. filter stop words from tokens\n",
    "        10. stem filtered tokens\n",
    "        \n",
    "    The function returns a 3-tuple with cleaned versions 8 through 10.\n",
    "    \"\"\"\n",
    "    # 1\n",
    "    tweet = tweet.lower()\n",
    "\n",
    "    # 2\n",
    "    # URL_pattern = r'\\w+:\\/{2}[\\d\\w-]+(\\.[\\d\\w-]+)*(?:(?:\\/[^\\s/]*))*'\n",
    "    # tweet = re.sub(URL_pattern, '', tweet, flags=re.MULTILINE)\n",
    "    # better, albeit slower, version\n",
    "    urls = list(set(url_extractor.find_urls(tweet)))\n",
    "    if len(urls) > 0:\n",
    "        for url in urls:\n",
    "            tweet = tweet.replace(url, \"\")\n",
    "    # 3\n",
    "    tweet = unescape(tweet)\n",
    "    \n",
    "    # 4\n",
    "    pattern = r'\\@\\w+|\\#|\\¥|\\â|\\«|\\»|\\Ñ|\\Ð|\\¼|\\½|\\¾|\\!|\\?|\\¿\\\n",
    "                |\\x82|\\x83|\\x84|\\x85|\\x86|\\x87|\\x88|\\x89|\\\n",
    "                |\\x8a|\\x8b|\\x8c|\\x8d|\\x8e|\\°|\\µ|\\´|\\º|\\¹|\\³'\n",
    "    tweet = re.sub(pattern, '', tweet)\n",
    "\n",
    "    # 5\n",
    "    tweet = tweet.translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "    # 6\n",
    "    tweet = re.sub(r'[^\\x00-\\x7F]+', '', tweet).strip()\n",
    "\n",
    "    # 7\n",
    "    def is_ascii(text):\n",
    "        try:\n",
    "            text.encode(encoding='utf-8').decode('ascii')\n",
    "        except UnicodeDecodeError:\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "    \n",
    "    if is_ascii(tweet) == False:\n",
    "        return \" \"\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    # 8 tokenized only (remove retweet prefix)\n",
    "    tweet_tokens = word_tokenize(tweet)\n",
    "    retweet = ['rt']\n",
    "    tweet_tokens = [token for token in tweet_tokens if not token in retweet]\n",
    "    \n",
    "    # 9 tokenized + filtered\n",
    "    # NLTK's set(stopwords.words('english')) removes too many words\n",
    "    # using list of 25 semantically non-selective words (Reuters-RCV1 dataset)\n",
    "    stop_words = ['a','an','and','are','as','at','be','by','for','from',\n",
    "                  'has','he','in','is','it','its','of','on','that','the',\n",
    "                  'to','was','were','will','with'] \n",
    "    filtered_tokens = [token for token in tweet_tokens if not token in stop_words]\n",
    "\n",
    "    # 10 tokenized + filtered + stemmed\n",
    "    ps = PorterStemmer()\n",
    "    filtered_stemmed_tokens = [ps.stem(token) for token in filtered_tokens]\n",
    "        \n",
    "    v8 = \" \".join(tweet_tokens)\n",
    "    v9 = \" \".join(filtered_tokens)\n",
    "    v10 = \" \".join(filtered_stemmed_tokens)  \n",
    "    \n",
    "    return (v8, v9, v10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_extractor = urlextract.URLExtract()\n",
    "tuples = [cleanup_tweet(tweet) for tweet in df.loc[:,'Text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, 'tokenized'], df.loc[:, 'filtered'], df.loc[:, 'stemmed'] = \\\n",
    "[x[0] for x in tuples], [x[1] for x in tuples], [x[2] for x in tuples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>User</th>\n",
       "      <th>Text</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Retweet</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>filtered</th>\n",
       "      <th>stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1305170993015644160</td>\n",
       "      <td>2020-09-13 15:46:28</td>\n",
       "      <td>SassySnipez</td>\n",
       "      <td>Thinking about cutting my hair but idk 🤔 #NewP...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>thinking about cutting my hair but idk newprof...</td>\n",
       "      <td>thinking about cutting my hair but idk newprof...</td>\n",
       "      <td>think about cut my hair but idk newprofilep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1305170992952565760</td>\n",
       "      <td>2020-09-13 15:46:28</td>\n",
       "      <td>nunubestboy</td>\n",
       "      <td>RT @milkypmh: thank you for working hard for t...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>thank you for working hard for this debut ever...</td>\n",
       "      <td>thank you working hard this debut everyone so ...</td>\n",
       "      <td>thank you work hard thi debut everyon so excit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1305170992352825344</td>\n",
       "      <td>2020-09-13 15:46:28</td>\n",
       "      <td>irisskhryss</td>\n",
       "      <td>RT @chicheesticks: ya'll actually finished the...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>yall actually finished the tommy video</td>\n",
       "      <td>yall actually finished tommy video</td>\n",
       "      <td>yall actual finish tommi video</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1305170992151621638</td>\n",
       "      <td>2020-09-13 15:46:28</td>\n",
       "      <td>shalexusss</td>\n",
       "      <td>RT @PrincessTaaaty: I need a date night 🥺, whe...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>i need a date night where we talk eat and vibe</td>\n",
       "      <td>i need date night where we talk eat vibe</td>\n",
       "      <td>i need date night where we talk eat vibe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1305170991841116170</td>\n",
       "      <td>2020-09-13 15:46:28</td>\n",
       "      <td>codepinkanime</td>\n",
       "      <td>@RyTanaka2 @lucysupremacy @KawasPhattyCake @0I...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>i love you so much</td>\n",
       "      <td>i love you so much</td>\n",
       "      <td>i love you so much</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    ID            Timestamp           User  \\\n",
       "0  1305170993015644160  2020-09-13 15:46:28    SassySnipez   \n",
       "1  1305170992952565760  2020-09-13 15:46:28    nunubestboy   \n",
       "2  1305170992352825344  2020-09-13 15:46:28    irisskhryss   \n",
       "3  1305170992151621638  2020-09-13 15:46:28     shalexusss   \n",
       "4  1305170991841116170  2020-09-13 15:46:28  codepinkanime   \n",
       "\n",
       "                                                Text  Polarity  Retweet  \\\n",
       "0  Thinking about cutting my hair but idk 🤔 #NewP...        -1        0   \n",
       "1  RT @milkypmh: thank you for working hard for t...        -1        1   \n",
       "2  RT @chicheesticks: ya'll actually finished the...        -1        1   \n",
       "3  RT @PrincessTaaaty: I need a date night 🥺, whe...        -1        1   \n",
       "4  @RyTanaka2 @lucysupremacy @KawasPhattyCake @0I...        -1        0   \n",
       "\n",
       "                                           tokenized  \\\n",
       "0  thinking about cutting my hair but idk newprof...   \n",
       "1  thank you for working hard for this debut ever...   \n",
       "2             yall actually finished the tommy video   \n",
       "3     i need a date night where we talk eat and vibe   \n",
       "4                                 i love you so much   \n",
       "\n",
       "                                            filtered  \\\n",
       "0  thinking about cutting my hair but idk newprof...   \n",
       "1  thank you working hard this debut everyone so ...   \n",
       "2                 yall actually finished tommy video   \n",
       "3           i need date night where we talk eat vibe   \n",
       "4                                 i love you so much   \n",
       "\n",
       "                                             stemmed  \n",
       "0        think about cut my hair but idk newprofilep  \n",
       "1  thank you work hard thi debut everyon so excit...  \n",
       "2                     yall actual finish tommi video  \n",
       "3           i need date night where we talk eat vibe  \n",
       "4                                 i love you so much  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>User</th>\n",
       "      <th>Text</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Retweet</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>filtered</th>\n",
       "      <th>stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24795</th>\n",
       "      <td>1305332767639711744</td>\n",
       "      <td>2020-09-14 02:29:18</td>\n",
       "      <td>CherylRGilmer1</td>\n",
       "      <td>RT @TAftermath2020: Hell yeah! Trump says he w...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>hell yeah trump says he wants biden to take a ...</td>\n",
       "      <td>hell yeah trump says wants biden take drug tes...</td>\n",
       "      <td>hell yeah trump say want biden take drug test ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24796</th>\n",
       "      <td>1305332767530430469</td>\n",
       "      <td>2020-09-14 02:29:18</td>\n",
       "      <td>KareyandKareful</td>\n",
       "      <td>RT @GreggsBooks: Follow everyone who likes or ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>follow everyone who likes or retweets this</td>\n",
       "      <td>follow everyone who likes or retweets this</td>\n",
       "      <td>follow everyon who like or retweet thi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24797</th>\n",
       "      <td>1305332767526354945</td>\n",
       "      <td>2020-09-14 02:29:18</td>\n",
       "      <td>earth2delisha</td>\n",
       "      <td>the blacker the berry....😉 https://t.co/7aM09o...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>the blacker the berry</td>\n",
       "      <td>blacker berry</td>\n",
       "      <td>blacker berri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24798</th>\n",
       "      <td>1305332767459172352</td>\n",
       "      <td>2020-09-14 02:29:18</td>\n",
       "      <td>JoEy_ChAvEz21</td>\n",
       "      <td>RT @thecheckdown: Larry Fitzgerald really hand...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>larry fitzgerald really handdelivered the ball...</td>\n",
       "      <td>larry fitzgerald really handdelivered ball ref...</td>\n",
       "      <td>larri fitzgerald realli handdeliv ball ref vet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24799</th>\n",
       "      <td>1305332767455154177</td>\n",
       "      <td>2020-09-14 02:29:18</td>\n",
       "      <td>Vickaric</td>\n",
       "      <td>RT @nowthisnews: The Rock sent a personalized ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>the rock sent a personalized birthday message ...</td>\n",
       "      <td>rock sent personalized birthday message this 1...</td>\n",
       "      <td>rock sent person birthday messag thi 100yearol...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        ID            Timestamp             User  \\\n",
       "24795  1305332767639711744  2020-09-14 02:29:18   CherylRGilmer1   \n",
       "24796  1305332767530430469  2020-09-14 02:29:18  KareyandKareful   \n",
       "24797  1305332767526354945  2020-09-14 02:29:18    earth2delisha   \n",
       "24798  1305332767459172352  2020-09-14 02:29:18    JoEy_ChAvEz21   \n",
       "24799  1305332767455154177  2020-09-14 02:29:18         Vickaric   \n",
       "\n",
       "                                                    Text  Polarity  Retweet  \\\n",
       "24795  RT @TAftermath2020: Hell yeah! Trump says he w...         1        1   \n",
       "24796  RT @GreggsBooks: Follow everyone who likes or ...         1        1   \n",
       "24797  the blacker the berry....😉 https://t.co/7aM09o...         1        0   \n",
       "24798  RT @thecheckdown: Larry Fitzgerald really hand...         1        1   \n",
       "24799  RT @nowthisnews: The Rock sent a personalized ...         1        1   \n",
       "\n",
       "                                               tokenized  \\\n",
       "24795  hell yeah trump says he wants biden to take a ...   \n",
       "24796         follow everyone who likes or retweets this   \n",
       "24797                              the blacker the berry   \n",
       "24798  larry fitzgerald really handdelivered the ball...   \n",
       "24799  the rock sent a personalized birthday message ...   \n",
       "\n",
       "                                                filtered  \\\n",
       "24795  hell yeah trump says wants biden take drug tes...   \n",
       "24796         follow everyone who likes or retweets this   \n",
       "24797                                      blacker berry   \n",
       "24798  larry fitzgerald really handdelivered ball ref...   \n",
       "24799  rock sent personalized birthday message this 1...   \n",
       "\n",
       "                                                 stemmed  \n",
       "24795  hell yeah trump say want biden take drug test ...  \n",
       "24796             follow everyon who like or retweet thi  \n",
       "24797                                      blacker berri  \n",
       "24798  larri fitzgerald realli handdeliv ball ref vet...  \n",
       "24799  rock sent person birthday messag thi 100yearol...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dupes = df[df['tokenized'].duplicated(keep='first')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24084677419354839"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dupes.shape[0]/df.shape[0] # % dupes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8861543612924828"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dupes[dupes['Retweet']==1].shape[0]/dupes.shape[0] # % of dupes that are retweets"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
