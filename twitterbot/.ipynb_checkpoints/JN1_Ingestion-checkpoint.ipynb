{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checklist**\n",
    "\n",
    "- check for dupes in ingestion? \n",
    "    - not needed, no dupes, and text dupes should be checked after cleaning\n",
    "- use textBlob as yet another way to perform basic sentiment analysis?\n",
    "    - yes, TODO, but maybe not during cleanup\n",
    "- create an incremental cleanup module?\n",
    "    - overkill, just reprocess everything bc of dupes, \n",
    "      script takes 8 secs for 20k tweets, that's ~6 min for a million if linear\n",
    "- improve script?\n",
    "    - add logs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "\n",
    "import string\n",
    "import datetime\n",
    "import urlextract\n",
    "import pandas as pd\n",
    "\n",
    "from html import unescape\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_todays_data():\n",
    "    filepath = os.path.join(\"..\",\"data\",\"1_raw\",\"tweets\")\n",
    "    today_prefix = datetime.datetime.now().strftime(\"%Y%m%d\")\n",
    "    dfm = []\n",
    "    for f in os.listdir(filepath):\n",
    "        if re.match(today_prefix, f):\n",
    "            dfm.append(pd.read_csv(os.path.join(filepath, f)))\n",
    "    df = pd.concat(dfm)\n",
    "    df = df.reset_index(drop=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_todays_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21600, 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "#def load_data():\n",
    "#    filepath = os.path.join(\"data\",\"raw\",\"tweets\") \n",
    "#\n",
    "#    dfm = []\n",
    "#    for f in os.listdir(filepath):\n",
    "#        dfm.append(pd.read_csv(os.path.join(filepath,f)))\n",
    "#        \n",
    "#    df = pd.concat(dfm)\n",
    "#    df = df.reset_index(drop=True)\n",
    "#    \n",
    "#    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test for duplicated IDs\n",
    "ids = df[\"ID\"]\n",
    "df[ids.isin(ids[ids.duplicated()])].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5507, 5)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test for duplicated Text\n",
    "txt = df[\"Text\"]\n",
    "df[txt.isin(txt[txt.duplicated()])].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AlluArjun373788</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CParambarai</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HabboRubbishBin</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lady_Minna</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tobesotee</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ID\n",
       "User               \n",
       "AlluArjun373788   9\n",
       "CParambarai       4\n",
       "HabboRubbishBin   3\n",
       "Lady_Minna        3\n",
       "tobesotee         3"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at users with more than 1 tweet?\n",
    "grouped = df[['User', 'ID']].groupby('User').count().sort_values('ID', ascending=False)\n",
    "\n",
    "grouped[grouped['ID']>1].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding Retweet Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_retweet(col):\n",
    "\n",
    "    for i in range(len(col)):\n",
    "        if re.match(r'^RT', col) is not None:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0      \n",
    "        \n",
    "def map_is_retweet(col):\n",
    "   \n",
    "    bool_map = map(lambda x: is_retweet(x), col)       \n",
    "    return(list(bool_map)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Retweet'] = map_is_retweet(df['Text'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup_tweet(tweet):\n",
    "    \"\"\"Cleans up a tweet with the following steps:\n",
    "        1. make lower case\n",
    "        2. remove URLs\n",
    "        3. unescape HTML entities\n",
    "        4. remove user references (including username) or hashtags, etc.\n",
    "        5. remove punctuation\n",
    "        6. remove emojis\n",
    "        7. discard non-ascii decodable text after utf-8 encoding\n",
    "        8. tokenize\n",
    "        9. filter stop words from tokens\n",
    "        10. stem filtered tokens\n",
    "        \n",
    "    The function returns a 3-tuple with cleaned versions 8 through 10.\n",
    "    \"\"\"\n",
    "    # 1\n",
    "    tweet = tweet.lower()\n",
    "\n",
    "    # 2\n",
    "    # URL_pattern = r'\\w+:\\/{2}[\\d\\w-]+(\\.[\\d\\w-]+)*(?:(?:\\/[^\\s/]*))*'\n",
    "    # tweet = re.sub(URL_pattern, '', tweet, flags=re.MULTILINE)\n",
    "    # better, albeit slower, version\n",
    "    urls = list(set(url_extractor.find_urls(tweet)))\n",
    "    if len(urls) > 0:\n",
    "        for url in urls:\n",
    "            tweet = tweet.replace(url, \"\")\n",
    "    # 3\n",
    "    tweet = unescape(tweet)\n",
    "    \n",
    "    # 4\n",
    "    pattern = r'\\@\\w+|\\#|\\¥|\\â|\\«|\\»|\\Ñ|\\Ð|\\¼|\\½|\\¾|\\!|\\?|\\¿\\\n",
    "                |\\x82|\\x83|\\x84|\\x85|\\x86|\\x87|\\x88|\\x89|\\\n",
    "                |\\x8a|\\x8b|\\x8c|\\x8d|\\x8e|\\°|\\µ|\\´|\\º|\\¹|\\³'\n",
    "    tweet = re.sub(pattern, '', tweet)\n",
    "\n",
    "    # 5\n",
    "    tweet = tweet.translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "    # 6\n",
    "    tweet = re.sub(r'[^\\x00-\\x7F]+', '', tweet).strip()\n",
    "\n",
    "    # 7\n",
    "    def is_ascii(text):\n",
    "        try:\n",
    "            text.encode(encoding='utf-8').decode('ascii')\n",
    "        except UnicodeDecodeError:\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "    \n",
    "    if is_ascii(tweet) == False:\n",
    "        return \" \"\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    # 8 tokenized only (remove retweet prefix)\n",
    "    tweet_tokens = word_tokenize(tweet)\n",
    "    retweet = ['rt']\n",
    "    tweet_tokens = [token for token in tweet_tokens if not token in retweet]\n",
    "    \n",
    "    # 9 tokenized + filtered\n",
    "    # NLTK's set(stopwords.words('english')) removes too many words\n",
    "    # using list of 25 semantically non-selective words (Reuters-RCV1 dataset)\n",
    "    stop_words = ['a','an','and','are','as','at','be','by','for','from',\n",
    "                  'has','he','in','is','it','its','of','on','that','the',\n",
    "                  'to','was','were','will','with'] \n",
    "    filtered_tokens = [token for token in tweet_tokens if not token in stop_words]\n",
    "\n",
    "    # 10 tokenized + filtered + stemmed\n",
    "    ps = PorterStemmer()\n",
    "    filtered_stemmed_tokens = [ps.stem(token) for token in filtered_tokens]\n",
    "        \n",
    "    v8 = \" \".join(tweet_tokens)\n",
    "    v9 = \" \".join(filtered_tokens)\n",
    "    v10 = \" \".join(filtered_stemmed_tokens)  \n",
    "    \n",
    "    return (v8, v9, v10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_extractor = urlextract.URLExtract()\n",
    "tuples = [cleanup_tweet(tweet) for tweet in df.loc[:,'Text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, 'tokenized'], df.loc[:, 'filtered'], df.loc[:, 'stemmed'] = \\\n",
    "[x[0] for x in tuples], [x[1] for x in tuples], [x[2] for x in tuples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>User</th>\n",
       "      <th>Text</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Retweet</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>filtered</th>\n",
       "      <th>stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1305170993015644160</td>\n",
       "      <td>2020-09-13 15:46:28</td>\n",
       "      <td>SassySnipez</td>\n",
       "      <td>Thinking about cutting my hair but idk 🤔 #NewP...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>thinking about cutting my hair but idk newprof...</td>\n",
       "      <td>thinking about cutting my hair but idk newprof...</td>\n",
       "      <td>think about cut my hair but idk newprofilep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1305170992952565760</td>\n",
       "      <td>2020-09-13 15:46:28</td>\n",
       "      <td>nunubestboy</td>\n",
       "      <td>RT @milkypmh: thank you for working hard for t...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>thank you for working hard for this debut ever...</td>\n",
       "      <td>thank you working hard this debut everyone so ...</td>\n",
       "      <td>thank you work hard thi debut everyon so excit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1305170992352825344</td>\n",
       "      <td>2020-09-13 15:46:28</td>\n",
       "      <td>irisskhryss</td>\n",
       "      <td>RT @chicheesticks: ya'll actually finished the...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>yall actually finished the tommy video</td>\n",
       "      <td>yall actually finished tommy video</td>\n",
       "      <td>yall actual finish tommi video</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1305170992151621638</td>\n",
       "      <td>2020-09-13 15:46:28</td>\n",
       "      <td>shalexusss</td>\n",
       "      <td>RT @PrincessTaaaty: I need a date night 🥺, whe...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>i need a date night where we talk eat and vibe</td>\n",
       "      <td>i need date night where we talk eat vibe</td>\n",
       "      <td>i need date night where we talk eat vibe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1305170991841116170</td>\n",
       "      <td>2020-09-13 15:46:28</td>\n",
       "      <td>codepinkanime</td>\n",
       "      <td>@RyTanaka2 @lucysupremacy @KawasPhattyCake @0I...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>i love you so much</td>\n",
       "      <td>i love you so much</td>\n",
       "      <td>i love you so much</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    ID            Timestamp           User  \\\n",
       "0  1305170993015644160  2020-09-13 15:46:28    SassySnipez   \n",
       "1  1305170992952565760  2020-09-13 15:46:28    nunubestboy   \n",
       "2  1305170992352825344  2020-09-13 15:46:28    irisskhryss   \n",
       "3  1305170992151621638  2020-09-13 15:46:28     shalexusss   \n",
       "4  1305170991841116170  2020-09-13 15:46:28  codepinkanime   \n",
       "\n",
       "                                                Text  Polarity  Retweet  \\\n",
       "0  Thinking about cutting my hair but idk 🤔 #NewP...        -1        0   \n",
       "1  RT @milkypmh: thank you for working hard for t...        -1        1   \n",
       "2  RT @chicheesticks: ya'll actually finished the...        -1        1   \n",
       "3  RT @PrincessTaaaty: I need a date night 🥺, whe...        -1        1   \n",
       "4  @RyTanaka2 @lucysupremacy @KawasPhattyCake @0I...        -1        0   \n",
       "\n",
       "                                           tokenized  \\\n",
       "0  thinking about cutting my hair but idk newprof...   \n",
       "1  thank you for working hard for this debut ever...   \n",
       "2             yall actually finished the tommy video   \n",
       "3     i need a date night where we talk eat and vibe   \n",
       "4                                 i love you so much   \n",
       "\n",
       "                                            filtered  \\\n",
       "0  thinking about cutting my hair but idk newprof...   \n",
       "1  thank you working hard this debut everyone so ...   \n",
       "2                 yall actually finished tommy video   \n",
       "3           i need date night where we talk eat vibe   \n",
       "4                                 i love you so much   \n",
       "\n",
       "                                             stemmed  \n",
       "0        think about cut my hair but idk newprofilep  \n",
       "1  thank you work hard thi debut everyon so excit...  \n",
       "2                     yall actual finish tommi video  \n",
       "3           i need date night where we talk eat vibe  \n",
       "4                                 i love you so much  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>User</th>\n",
       "      <th>Text</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Retweet</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>filtered</th>\n",
       "      <th>stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21595</th>\n",
       "      <td>1305306124665712640</td>\n",
       "      <td>2020-09-14 00:43:26</td>\n",
       "      <td>_MiaMiaMia_</td>\n",
       "      <td>@_BrittneyJanee IT'S JUST SUGAR OMG 😂</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>its just sugar omg</td>\n",
       "      <td>just sugar omg</td>\n",
       "      <td>just sugar omg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21596</th>\n",
       "      <td>1305306124586045441</td>\n",
       "      <td>2020-09-14 00:43:26</td>\n",
       "      <td>MotorCityDemon</td>\n",
       "      <td>RT @e_seduisante: Clear Skin , Pretty Face 🍷❤️...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>clear skin pretty face</td>\n",
       "      <td>clear skin pretty face</td>\n",
       "      <td>clear skin pretti face</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21597</th>\n",
       "      <td>1305306124581777409</td>\n",
       "      <td>2020-09-14 00:43:26</td>\n",
       "      <td>MisGuidedGenXer</td>\n",
       "      <td>RT @Ebonyteach: I’m in tears! CLAUDINE! Curtis...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>im in tears claudine curtis mayfield</td>\n",
       "      <td>im tears claudine curtis mayfield</td>\n",
       "      <td>im tear claudin curti mayfield</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21598</th>\n",
       "      <td>1305306124531318784</td>\n",
       "      <td>2020-09-14 00:43:26</td>\n",
       "      <td>andrejohnson174</td>\n",
       "      <td>I see y’all hearting them RT if you need a ble...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>i see yall hearting them if you need a blessing</td>\n",
       "      <td>i see yall hearting them if you need blessing</td>\n",
       "      <td>i see yall heart them if you need bless</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21599</th>\n",
       "      <td>1305306124485263360</td>\n",
       "      <td>2020-09-14 00:43:26</td>\n",
       "      <td>Im_TheMove</td>\n",
       "      <td>RT @SHAAANEE_: idc how much i like you, i’ll l...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>idc how much i like you ill leave you alone</td>\n",
       "      <td>idc how much i like you ill leave you alone</td>\n",
       "      <td>idc how much i like you ill leav you alon</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        ID            Timestamp             User  \\\n",
       "21595  1305306124665712640  2020-09-14 00:43:26      _MiaMiaMia_   \n",
       "21596  1305306124586045441  2020-09-14 00:43:26   MotorCityDemon   \n",
       "21597  1305306124581777409  2020-09-14 00:43:26  MisGuidedGenXer   \n",
       "21598  1305306124531318784  2020-09-14 00:43:26  andrejohnson174   \n",
       "21599  1305306124485263360  2020-09-14 00:43:26       Im_TheMove   \n",
       "\n",
       "                                                    Text  Polarity  Retweet  \\\n",
       "21595              @_BrittneyJanee IT'S JUST SUGAR OMG 😂         1        0   \n",
       "21596  RT @e_seduisante: Clear Skin , Pretty Face 🍷❤️...         1        1   \n",
       "21597  RT @Ebonyteach: I’m in tears! CLAUDINE! Curtis...         1        1   \n",
       "21598  I see y’all hearting them RT if you need a ble...         1        0   \n",
       "21599  RT @SHAAANEE_: idc how much i like you, i’ll l...         1        1   \n",
       "\n",
       "                                             tokenized  \\\n",
       "21595                               its just sugar omg   \n",
       "21596                           clear skin pretty face   \n",
       "21597             im in tears claudine curtis mayfield   \n",
       "21598  i see yall hearting them if you need a blessing   \n",
       "21599      idc how much i like you ill leave you alone   \n",
       "\n",
       "                                            filtered  \\\n",
       "21595                                 just sugar omg   \n",
       "21596                         clear skin pretty face   \n",
       "21597              im tears claudine curtis mayfield   \n",
       "21598  i see yall hearting them if you need blessing   \n",
       "21599    idc how much i like you ill leave you alone   \n",
       "\n",
       "                                         stemmed  \n",
       "21595                             just sugar omg  \n",
       "21596                     clear skin pretti face  \n",
       "21597             im tear claudin curti mayfield  \n",
       "21598    i see yall heart them if you need bless  \n",
       "21599  idc how much i like you ill leav you alon  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dupes = df[df['tokenized'].duplicated(keep='first')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23555555555555555"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dupes.shape[0]/df.shape[0] # % dupes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8966194968553459"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dupes[dupes['Retweet']==1].shape[0]/dupes.shape[0] # % of dupes that are retweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create a subset with cols of interest\n",
    "#sub_df = df[['ID','Retweet','Text','Polarity']].copy()\n",
    "#\n",
    "## dedupe (text duplicates)\n",
    "#dupes = sub_df[sub_df['Text'].duplicated(keep='first')]\n",
    "#\n",
    "#final_df = sub_df[~sub_df.ID.isin(list(dupes['ID']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
