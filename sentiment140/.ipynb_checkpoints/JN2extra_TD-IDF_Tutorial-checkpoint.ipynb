{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Twitter Setiment Analysis \n",
    "\n",
    "### Part 2: TD - IDF Tuturial with sentiment140 dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import load_data as ld\n",
    "df = ld.run_processes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>filtered</th>\n",
       "      <th>stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>is upset that he cant update his facebook by t...</td>\n",
       "      <td>upset cant update his facebook texting might c...</td>\n",
       "      <td>upset cant updat hi facebook text might cri re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "      <td>i dived many times for the ball managed to sav...</td>\n",
       "      <td>i dived many times ball managed save 50 rest g...</td>\n",
       "      <td>i dive mani time ball manag save 50 rest go ou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>my whole body feels itchy like fire</td>\n",
       "      <td>my whole bodi feel itchi like fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "      <td>no its not behaving at all im mad why am i her...</td>\n",
       "      <td>no not behaving all im mad why am i here becau...</td>\n",
       "      <td>no not behav all im mad whi am i here becaus i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kwesidei not the whole crew</td>\n",
       "      <td>not the whole crew</td>\n",
       "      <td>not whole crew</td>\n",
       "      <td>not whole crew</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target                                               text  \\\n",
       "0       0  is upset that he can't update his Facebook by ...   \n",
       "1       0  @Kenichan I dived many times for the ball. Man...   \n",
       "2       0    my whole body feels itchy and like its on fire    \n",
       "3       0  @nationwideclass no, it's not behaving at all....   \n",
       "4       0                      @Kwesidei not the whole crew    \n",
       "\n",
       "                                           tokenized  \\\n",
       "0  is upset that he cant update his facebook by t...   \n",
       "1  i dived many times for the ball managed to sav...   \n",
       "2     my whole body feels itchy and like its on fire   \n",
       "3  no its not behaving at all im mad why am i her...   \n",
       "4                                 not the whole crew   \n",
       "\n",
       "                                            filtered  \\\n",
       "0  upset cant update his facebook texting might c...   \n",
       "1  i dived many times ball managed save 50 rest g...   \n",
       "2                my whole body feels itchy like fire   \n",
       "3  no not behaving all im mad why am i here becau...   \n",
       "4                                     not whole crew   \n",
       "\n",
       "                                             stemmed  \n",
       "0  upset cant updat hi facebook text might cri re...  \n",
       "1  i dive mani time ball manag save 50 rest go ou...  \n",
       "2                 my whole bodi feel itchi like fire  \n",
       "3  no not behav all im mad whi am i here becaus i...  \n",
       "4                                     not whole crew  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import ML pre-processing modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.utils import random \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop NAs created during cleanup\n",
    "\n",
    "We don't want to impute nor anything else since these are empty texts we cannot use for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfm = df.dropna()\n",
    "dfm.index = range(1,len(dfm) + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorize with TF IDF\n",
    "\n",
    "What does that mean?\n",
    "\n",
    "Explain...\n",
    "\n",
    "But first, random sample the 1.6M dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_sample(df):\n",
    "    \"\"\"\n",
    "    Sample 1% without replacement.\n",
    "    \"\"\"\n",
    "    ix = random.sample_without_replacement(n_population=len(df),\n",
    "                                           n_samples=round(len(df)/100),\n",
    "                                           random_state=42)\n",
    "    out = df.loc[ix, ]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7979</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        text\n",
       "target      \n",
       "0       7983\n",
       "1       7979"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ensure equal amounts\n",
    "\n",
    "# divide into negatives and positives\n",
    "df0 = dfm[dfm['target'] == 0].copy()\n",
    "df1 = dfm[dfm['target'] == 1].copy()\n",
    "df1.index = range(0, len(df1))\n",
    "\n",
    "# sample 1% from each and concatenate\n",
    "df0_sample = random_sample(df0)\n",
    "df1_sample = random_sample(df1)\n",
    "df_sample = pd.concat([df0_sample, df1_sample])\n",
    "df_sample.index = range(0, len(df_sample))\n",
    "\n",
    "# counts grouped by target\n",
    "df_sample.loc[:, ('target','text')].groupby(['target']).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF IDF vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate TF IDF vectorizer\n",
    "vectorizer = TfidfVectorizer(sublinear_tf=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y is just an array with the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.array(df_sample.iloc[:, 0]).ravel()\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using tokenized feature \n",
    "X = vectorizer.fit_transform(np.array(df_sample.iloc[:, 2]).ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15962, 19580)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting to dense format so we can visualize data\n",
    "col = [i for i in vectorizer.get_feature_names()] \n",
    "temp = pd.DataFrame(X.todense(), columns=col) \n",
    "temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13290 0.7416339690431502\n"
     ]
    }
   ],
   "source": [
    "# hunting down nonzero feature row\n",
    "for i, e in enumerate(temp.loc[:, 'camo']):\n",
    "    if e != 0:\n",
    "        print(i, e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>camisado</th>\n",
       "      <th>cammy</th>\n",
       "      <th>camo</th>\n",
       "      <th>camp</th>\n",
       "      <th>campaign</th>\n",
       "      <th>campbell</th>\n",
       "      <th>camper</th>\n",
       "      <th>campers</th>\n",
       "      <th>campim</th>\n",
       "      <th>camping</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13285</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13286</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13287</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13288</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13289</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13290</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.741634</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13291</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13292</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13293</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13294</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       camisado  cammy      camo  camp  campaign  campbell  camper  campers  \\\n",
       "13285       0.0    0.0  0.000000   0.0       0.0       0.0     0.0      0.0   \n",
       "13286       0.0    0.0  0.000000   0.0       0.0       0.0     0.0      0.0   \n",
       "13287       0.0    0.0  0.000000   0.0       0.0       0.0     0.0      0.0   \n",
       "13288       0.0    0.0  0.000000   0.0       0.0       0.0     0.0      0.0   \n",
       "13289       0.0    0.0  0.000000   0.0       0.0       0.0     0.0      0.0   \n",
       "13290       0.0    0.0  0.741634   0.0       0.0       0.0     0.0      0.0   \n",
       "13291       0.0    0.0  0.000000   0.0       0.0       0.0     0.0      0.0   \n",
       "13292       0.0    0.0  0.000000   0.0       0.0       0.0     0.0      0.0   \n",
       "13293       0.0    0.0  0.000000   0.0       0.0       0.0     0.0      0.0   \n",
       "13294       0.0    0.0  0.000000   0.0       0.0       0.0     0.0      0.0   \n",
       "\n",
       "       campim  camping  \n",
       "13285     0.0      0.0  \n",
       "13286     0.0      0.0  \n",
       "13287     0.0      0.0  \n",
       "13288     0.0      0.0  \n",
       "13289     0.0      0.0  \n",
       "13290     0.0      0.0  \n",
       "13291     0.0      0.0  \n",
       "13292     0.0      0.0  \n",
       "13293     0.0      0.0  \n",
       "13294     0.0      0.0  "
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what that rare non-zero value and surrounding data looks like\n",
    "temp.iloc[13285:13295, 3010:3020]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TfidfVectorizer**\n",
    "\n",
    "Transforms text into feature vectors that can be used as an input to estimators. When the `fit()` method is called, it creates a dictionary that stores each term in the corpus and its assigned feature index. This dictionary is the vectorizer's `.vocabulary_`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(sublinear_tf=True)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.fit(np.array(df_sample.iloc[:, 1]).ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 up\n",
      "1 way\n",
      "2 too\n",
      "3 early\n",
      "4 in\n",
      "25893 followando\n",
      "25894 tbm\n",
      "25895 intothestreet\n",
      "25896 1bj\n",
      "25897 twittts\n"
     ]
    }
   ],
   "source": [
    "for ix, doc in enumerate(vectorizer.vocabulary_):\n",
    "    if ix < 5 or ix > len(vectorizer.vocabulary_)-6:\n",
    "        print(ix, doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As opposed to `Countvectorizer`, `TfidfVectorizer` doesn't simply one-hot encode each of these terms as features in a sparse matrix; rather, it assigns **scores** based on the $TF * IDF$ formula."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Term Frequency (TF)**\n",
    "\n",
    "TF is the frequecy of a term in a document (a word in a Tweet).\n",
    "\n",
    "If the word is common (like \"the\") it appears with high frequency. From [Zipf's law](https://en.wikipedia.org/wiki/Zipf's_law) we learn that very frequent terms are uninformative in linguistics, \n",
    "these so-called \"stop words\" are often removed (as I did in the 'filtered' feature). Therefore we'd like to decrease the weight (or score) assigned to this word.\n",
    "\n",
    "One problem with implementing TF alone is that rare words in a document may be uninformative in the context of entire corpus (all Tweets), so we want to balance the weight assigned to them in a document with another weight assigned via their frequency in all the documents (the corpus).\n",
    "\n",
    "Enters...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inverse Document Frequency (IDF)**\n",
    "\n",
    "IDF is \n",
    "\n",
    "log of {number of docs in your corpus divided by the number of docs in which this term appears}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
