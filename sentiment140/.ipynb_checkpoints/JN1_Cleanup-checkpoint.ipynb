{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Twitter Setiment Analysis \n",
    "\n",
    "### Part 1: sentiment140 dataset cleanup\n",
    "\n",
    "The code was originally inspired Gaurav Singhal's guide: [Building a Twitter Setiment Analysis in Python.](https://www.pluralsight.com/guides/building-a-twitter-sentiment-analysis-in-python)\n",
    "\n",
    "The data comes from Marios Michailidis' sentiment140 dataset hosted in [Kaggle.](https://www.kaggle.com/kazanova/sentiment140/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleanup Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All details of cleanup steps can be found in the custom python script `cleanup_module.py`. \n",
    "\n",
    "Michailidis' dataset consists of 1.6 M rows evenly split into negative and positive Tweets. The labels were created automatically simply using emoticons (happy face is positive, and vice versa).  \n",
    "\n",
    "Since my cleanup function entails heavy CPU-bound processes I use multiprocessing, splitting the data into 32 50k-row chunks which are processed 8 at a time (my laptop has 8 logical processors). The order of processing is asynchronous.\n",
    "\n",
    "Here I just run that script by passing a command to the command line. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving cleaned up train dataset: 6\n",
      "Saving cleaned up train dataset: 5\n",
      "Saving cleaned up train dataset: 3\n",
      "Saving cleaned up train dataset: 2\n",
      "Saving cleaned up train dataset: 1\n",
      "Saving cleaned up train dataset: 4\n",
      "Saving cleaned up train dataset: 8\n",
      "Saving cleaned up train dataset: 7\n",
      "Saving cleaned up train dataset: 9\n",
      "Saving cleaned up train dataset: 10\n",
      "Saving cleaned up train dataset: 12\n",
      "Saving cleaned up train dataset: 11\n",
      "Saving cleaned up train dataset: 13\n",
      "Saving cleaned up train dataset: 15\n",
      "Saving cleaned up train dataset: 14\n",
      "Saving cleaned up train dataset: 16\n",
      "Saving cleaned up train dataset: 17\n",
      "Saving cleaned up train dataset: 18\n",
      "Saving cleaned up train dataset: 19\n",
      "Saving cleaned up train dataset: 20\n",
      "Saving cleaned up train dataset: 22\n",
      "Saving cleaned up train dataset: 23\n",
      "Saving cleaned up train dataset: 21\n",
      "Saving cleaned up train dataset: 24\n",
      "Saving cleaned up train dataset: 25\n",
      "Saving cleaned up train dataset: 26\n",
      "Saving cleaned up train dataset: 28\n",
      "Saving cleaned up train dataset: 27\n",
      "Saving cleaned up train dataset: 30\n",
      "Saving cleaned up train dataset: 29\n",
      "Saving cleaned up train dataset: 31\n",
      "Saving cleaned up train dataset: 32\n",
      "Finished in 304.84 second(s)\n"
     ]
    }
   ],
   "source": [
    "cmd = 'python cleanup_module.py'\n",
    "!{cmd}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Even without compiling the regex patterns the entire dataset runs in just under 5 mins, which is good enough for me since it's a one-time process. \n",
    "\n",
    "This is how we revert back to the original data (which includes Tweet IDs, etc) from the cleaned data. The key is basically the list of parameters passed to the multiprocessing executor; for example, this last set of parameters indicates that the cleaned dataset 32 contains the range from 1550000 to 1600000:\n",
    "\n",
    "```\n",
    "(range(1550000, 1600001), 32)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../data/1_raw/sentiment140/training.1600000.processed.noemoticon.csv\",\n",
    "                 encoding='latin-1', \n",
    "                 usecols=[0,5])\n",
    "\n",
    "df.columns = ['target','text']\n",
    "              \n",
    "df_clean =  pd.read_csv(\"../data/2_clean/sentiment140/train_32.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1550401</th>\n",
       "      <td>4</td>\n",
       "      <td>Going to see Ghosts of Girlfriends Past with @...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1550402</th>\n",
       "      <td>4</td>\n",
       "      <td>@sarah_cawood can't wait to see the movie, it ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1550403</th>\n",
       "      <td>4</td>\n",
       "      <td>@ScottHuska rock the boat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1550404</th>\n",
       "      <td>4</td>\n",
       "      <td>@DooneyStudio me and the remaining web develop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1550405</th>\n",
       "      <td>4</td>\n",
       "      <td>Wooh powergun Haha washing away</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1550406</th>\n",
       "      <td>4</td>\n",
       "      <td>@mileycyrus NO MILEY IM NOT VOTING FOR YOU &amp;gt...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         target                                               text\n",
       "1550401       4  Going to see Ghosts of Girlfriends Past with @...\n",
       "1550402       4  @sarah_cawood can't wait to see the movie, it ...\n",
       "1550403       4                         @ScottHuska rock the boat \n",
       "1550404       4  @DooneyStudio me and the remaining web develop...\n",
       "1550405       4                   Wooh powergun Haha washing away \n",
       "1550406       4  @mileycyrus NO MILEY IM NOT VOTING FOR YOU &gt..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[1550401:1550406,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>1</td>\n",
       "      <td>go see ghost girlfriend past</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>1</td>\n",
       "      <td>cant wait see movi look so good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>1</td>\n",
       "      <td>rock boat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>1</td>\n",
       "      <td>me remain web develop have plan keep compani a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>1</td>\n",
       "      <td>wooh powergun haha wash away</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>1</td>\n",
       "      <td>no miley im not vote you hhahahah joke cours i</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     target                                               text\n",
       "401       1                       go see ghost girlfriend past\n",
       "402       1                    cant wait see movi look so good\n",
       "403       1                                          rock boat\n",
       "404       1  me remain web develop have plan keep compani a...\n",
       "405       1                       wooh powergun haha wash away\n",
       "406       1     no miley im not vote you hhahahah joke cours i"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.loc[401:406,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
