{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter Sentiment Analysis - POC\n",
    "---\n",
    "\n",
    "## 7. Quickly train various models\n",
    "\n",
    "**Current State**: I've trained three baseline models with little tweaking, and fine-tuned a single decision tree, on a Bag-of-Word subset of $m\\approx250k, n=50k$ of the training data, using cross validation, and got the following mean accuracy scores:\n",
    "\n",
    "- Logistic Regression: $78.8\\%$\n",
    "- Naive Bayes: $77.6\\%$ \n",
    "- SGD (log loss): $77.1\\%$ \n",
    "- Decision Tree: $69.0\\%$\n",
    "\n",
    "**This Notebook**: Build random forests (DIY and using Scikit-learn's RandomForestClassifier class), and perform small grid searches to see whether I can quickly crack $80\\%$ accuracy on the test set. \n",
    "\n",
    "- Results: the best accuracy I could get was $75\\%$, but I also at most used 8,000 instances (out of roughly 200,000 for the training set) so this result can be improved with more data. In the next notebook I'll take the best two estimators and plot their learning curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "\n",
    "from sklearn.base import clone\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load $m\\approx250k$, $n=50k$ training subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processed dir\n",
    "proc_dir = os.path.join(\"..\",\"data\",\"3_processed\",\"sentiment140\")\n",
    "X_train_transformed = sp.load_npz(os.path.join(proc_dir, \"X_train_transformed_BoW_250k_50k.npz\"))\n",
    "with open(os.path.join(proc_dir, \"y_array_250k.npy\"), 'rb') as f:\n",
    "    y_array = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_train_transformed, \n",
    "                                                    y_array, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DIY Random Forest\n",
    "\n",
    "In the [POC for growing your own random forest](10.extra_GrowingRandomForests) I used 1,000 trees of 100 instances each for an 8,000 training dataset. If I were to mimic these proportions with the roughly 200,000 instances in our training data I'd have to train about 25,000 trees with 2,500 instances each. That might take too long so I'll start with the same 1,000 trees of 100 instances each and see where I get.\n",
    "\n",
    "I'm setting `max_featuers=sqrt(n_features)` such that we'll have more diverse trees and hopefully improve accuracy. Also, it will help make the forest run faster, since instead of usign all $50,000$ features, we'll use only $\\sqrt{50,000}\\approx224$  max features. The square root is the default for Scikit-learn's **RandomForestClassifier** class, not the **DecisionTreeClassifier** class, whose default is `max_features=n_features`. [(source)](https://github.com/scikit-learn/scikit-learn/blob/0fb307bf39bbdacd6ed713c00724f8f871d60370/sklearn/tree/_classes.py#L597)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_trees = 1000\n",
    "n_instances = 100\n",
    "subsets = []\n",
    "\n",
    "rs = ShuffleSplit(n_splits=n_trees, test_size=X_train.shape[0] - n_instances, random_state=42)\n",
    "for train_sub_ix, test_sub_ix in rs.split(X_train):\n",
    "    X_sub_train = X_train[train_sub_ix]\n",
    "    y_sub_train = y_train[train_sub_ix]\n",
    "    subsets.append((X_sub_train, y_sub_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this loop we get `subsets`: a 1,000-long list of 100 by 50k sparse matrices of features and 1000-long numpy arrays with target values. \n",
    "\n",
    "We start our forest by cloning our best estimator from the previous notebook 1,000 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_estimator_ = DecisionTreeClassifier(random_state=42, \n",
    "                                         max_leaf_nodes=99,\n",
    "                                         max_features=\"sqrt\")\n",
    "\n",
    "forest = [clone(best_estimator_) for _ in range(n_trees)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we train each tree in our forest, make predictions on the test set and get the accuracy for each of these predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 101 out of 1000 tasks | elapsed: 0m 6s | remaining: 0m 51s\n",
      "Done 201 out of 1000 tasks | elapsed: 0m 11s | remaining: 0m 45s\n",
      "Done 301 out of 1000 tasks | elapsed: 0m 17s | remaining: 0m 39s\n",
      "Done 401 out of 1000 tasks | elapsed: 0m 23s | remaining: 0m 34s\n",
      "Done 501 out of 1000 tasks | elapsed: 0m 29s | remaining: 0m 29s\n",
      "Done 601 out of 1000 tasks | elapsed: 0m 35s | remaining: 0m 23s\n",
      "Done 701 out of 1000 tasks | elapsed: 0m 40s | remaining: 0m 17s\n",
      "Done 801 out of 1000 tasks | elapsed: 0m 46s | remaining: 0m 11s\n",
      "Done 901 out of 1000 tasks | elapsed: 0m 51s | remaining: 0m 6s\n",
      "Done 1000 out of 1000 tasks | elapsed: 0m 57s | finished\n"
     ]
    }
   ],
   "source": [
    "accuracy_scores = []\n",
    "start_loop = time.time()\n",
    "\n",
    "for ix, (tree, (X_sub_train, y_sub_train)) in enumerate(zip(forest, subsets)):        \n",
    "    tree.fit(X_sub_train, y_sub_train)\n",
    "    y_pred = tree.predict(X_test)\n",
    "    accuracy_scores.append(accuracy_score(y_test, y_pred))\n",
    "    if ix % 100 == 0 and ix != 0:\n",
    "        ix_time = time.time()\n",
    "        mins, secs = divmod(ix_time - start_loop, 60)\n",
    "        avg_ix_time = (ix_time-start_loop)/(ix+1)\n",
    "        rest_ix = n_trees-ix\n",
    "        rest_mins, rest_secs = divmod(rest_ix * avg_ix_time, 60)\n",
    "        print(f'Done {ix+1:0.0f} out of {n_trees:0.0f} tasks | \\\n",
    "elapsed: {mins:0.0f}m {secs:0.0f}s | remaining: {rest_mins:0.0f}m {rest_secs:0.0f}s')\n",
    "    if ix == n_trees-1:\n",
    "        ix_time = time.time()\n",
    "        mins, secs = divmod(ix_time - start_loop, 60)\n",
    "        print(f'Done {ix+1:0.0f} out of {n_trees:0.0f} tasks | \\\n",
    "elapsed: {mins:0.0f}m {secs:0.0f}s | finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5371"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(np.mean(accuracy_scores), 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the **\"magic\"** step:\n",
    "\n",
    "- for each test set instance, generate the predictions of the trees \n",
    "- keep only the most frequent prediction (the *mode*)\n",
    "\n",
    "This procedure gives you the majority-vote predictions over the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50294"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate a 1,000 x 50,294 matrix\n",
    "Y_pred = np.empty([1000, X_test.shape[0]], dtype=np.uint8) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mode\n",
    "\n",
    "# generate predictions for each classifier\n",
    "for tree_ix, tree in enumerate(forest):              \n",
    "    Y_pred[tree_ix] = tree.predict(X_test)\n",
    "\n",
    "# compute the mode for each y_pred\n",
    "y_pred_majority_votes, n_votes = mode(Y_pred, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6929"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get accuracy of preds on test target\n",
    "round(accuracy_score(y_test, y_pred_majority_votes.reshape([-1])), 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That shows some potential, so let's scale it up to 10,000 trees of 2,000 instances each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_trees = 10000\n",
    "n_instances = 2000\n",
    "subsets = []\n",
    "\n",
    "rs = ShuffleSplit(n_splits=n_trees, test_size=X_train.shape[0] - n_instances, random_state=42)\n",
    "for train_sub_ix, test_sub_ix in rs.split(X_train):\n",
    "    X_sub_train = X_train[train_sub_ix]\n",
    "    y_sub_train = y_train[train_sub_ix]\n",
    "    subsets.append((X_sub_train, y_sub_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_estimator_ = DecisionTreeClassifier(random_state=42, \n",
    "                                         max_leaf_nodes=99,\n",
    "                                         max_features=\"sqrt\")\n",
    "\n",
    "forest = [clone(best_estimator_) for _ in range(n_trees)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 501 out of 10000 tasks | elapsed: 0m 15s | remaining: 4m 36s\n",
      "Done 1001 out of 10000 tasks | elapsed: 0m 29s | remaining: 4m 22s\n",
      "Done 1501 out of 10000 tasks | elapsed: 0m 44s | remaining: 4m 7s\n",
      "Done 2001 out of 10000 tasks | elapsed: 0m 59s | remaining: 3m 55s\n",
      "Done 2501 out of 10000 tasks | elapsed: 1m 13s | remaining: 3m 40s\n",
      "Done 3001 out of 10000 tasks | elapsed: 1m 28s | remaining: 3m 25s\n",
      "Done 3501 out of 10000 tasks | elapsed: 1m 43s | remaining: 3m 10s\n",
      "Done 4001 out of 10000 tasks | elapsed: 1m 57s | remaining: 2m 56s\n",
      "Done 4501 out of 10000 tasks | elapsed: 2m 12s | remaining: 2m 42s\n",
      "Done 5001 out of 10000 tasks | elapsed: 2m 27s | remaining: 2m 27s\n",
      "Done 5501 out of 10000 tasks | elapsed: 2m 41s | remaining: 2m 12s\n",
      "Done 6001 out of 10000 tasks | elapsed: 2m 56s | remaining: 1m 57s\n",
      "Done 6501 out of 10000 tasks | elapsed: 3m 11s | remaining: 1m 43s\n",
      "Done 7001 out of 10000 tasks | elapsed: 3m 26s | remaining: 1m 28s\n",
      "Done 7501 out of 10000 tasks | elapsed: 3m 41s | remaining: 1m 14s\n",
      "Done 8001 out of 10000 tasks | elapsed: 3m 55s | remaining: 0m 59s\n",
      "Done 8501 out of 10000 tasks | elapsed: 4m 10s | remaining: 0m 44s\n",
      "Done 9001 out of 10000 tasks | elapsed: 4m 25s | remaining: 0m 29s\n",
      "Done 9501 out of 10000 tasks | elapsed: 4m 40s | remaining: 0m 15s\n",
      "Done 10000 out of 10000 tasks | elapsed: 4m 54s | finished\n"
     ]
    }
   ],
   "source": [
    "accuracy_scores = []\n",
    "start_loop = time.time()\n",
    "\n",
    "for ix, (tree, (X_sub_train, y_sub_train)) in enumerate(zip(forest, subsets)):\n",
    "    tree.fit(X_sub_train, y_sub_train)\n",
    "    y_pred = tree.predict(X_test)\n",
    "    accuracy_scores.append(accuracy_score(y_test, y_pred))\n",
    "    if ix % 500 == 0 and ix != 0:\n",
    "        ix_time = time.time()\n",
    "        mins, secs = divmod(ix_time - start_loop, 60)\n",
    "        avg_ix_time = (ix_time-start_loop)/(ix+1)\n",
    "        rest_ix = n_trees-ix\n",
    "        rest_mins, rest_secs = divmod(rest_ix * avg_ix_time, 60)\n",
    "        print(f'Done {ix+1:0.0f} out of {n_trees:0.0f} tasks | \\\n",
    "elapsed: {mins:0.0f}m {secs:0.0f}s | remaining: {rest_mins:0.0f}m {rest_secs:0.0f}s')\n",
    "    if ix == n_trees-1:\n",
    "        ix_time = time.time()\n",
    "        mins, secs = divmod(ix_time - start_loop, 60)\n",
    "        print(f'Done {ix+1:0.0f} out of {n_trees:0.0f} tasks | \\\n",
    "elapsed: {mins:0.0f}m {secs:0.0f}s | finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.593"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(np.mean(accuracy_scores), 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**magic** step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = np.empty([n_trees, X_test.shape[0]], dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate predictions for each classifier\n",
    "for ix, tree in enumerate(forest):         \n",
    "    Y_pred[ix] = tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute mode for each y_pred\n",
    "y_pred_majority_votes, n_votes = mode(Y_pred, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6842"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get accuracy of preds on test target\n",
    "round(accuracy_score(y_test, y_pred_majority_votes.reshape([-1])), 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting, maybe we need to add more features given the larger instance space, I'll change only `max_features=11000` to match a classifier found in the POC and train the same forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_trees = 10000\n",
    "n_instances = 2000\n",
    "subsets = []\n",
    "\n",
    "rs = ShuffleSplit(n_splits=n_trees, test_size=X_train.shape[0] - n_instances, random_state=42)\n",
    "for train_sub_ix, test_sub_ix in rs.split(X_train):\n",
    "    X_sub_train = X_train[train_sub_ix]\n",
    "    y_sub_train = y_train[train_sub_ix]\n",
    "    subsets.append((X_sub_train, y_sub_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_estimator_ = DecisionTreeClassifier(random_state=42, \n",
    "                                         max_leaf_nodes=99,\n",
    "                                         max_features=11000)\n",
    "\n",
    "forest = [clone(best_estimator_) for _ in range(n_trees)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 501 out of 10000 tasks | elapsed: 1m 40s | remaining: 31m 44s\n",
      "Done 1001 out of 10000 tasks | elapsed: 3m 20s | remaining: 29m 57s\n",
      "Done 1501 out of 10000 tasks | elapsed: 4m 58s | remaining: 28m 9s\n",
      "Done 2001 out of 10000 tasks | elapsed: 6m 37s | remaining: 26m 28s\n",
      "Done 2501 out of 10000 tasks | elapsed: 8m 16s | remaining: 24m 47s\n",
      "Done 3001 out of 10000 tasks | elapsed: 9m 55s | remaining: 23m 8s\n",
      "Done 3501 out of 10000 tasks | elapsed: 11m 33s | remaining: 21m 27s\n",
      "Done 4001 out of 10000 tasks | elapsed: 13m 12s | remaining: 19m 48s\n",
      "Done 4501 out of 10000 tasks | elapsed: 14m 51s | remaining: 18m 9s\n",
      "Done 5001 out of 10000 tasks | elapsed: 16m 30s | remaining: 16m 29s\n",
      "Done 5501 out of 10000 tasks | elapsed: 18m 8s | remaining: 14m 50s\n",
      "Done 6001 out of 10000 tasks | elapsed: 19m 47s | remaining: 13m 11s\n",
      "Done 6501 out of 10000 tasks | elapsed: 21m 26s | remaining: 11m 33s\n",
      "Done 7001 out of 10000 tasks | elapsed: 23m 5s | remaining: 9m 54s\n",
      "Done 7501 out of 10000 tasks | elapsed: 24m 44s | remaining: 8m 15s\n",
      "Done 8001 out of 10000 tasks | elapsed: 26m 23s | remaining: 6m 36s\n",
      "Done 8501 out of 10000 tasks | elapsed: 28m 2s | remaining: 4m 57s\n",
      "Done 9001 out of 10000 tasks | elapsed: 29m 41s | remaining: 3m 18s\n",
      "Done 9501 out of 10000 tasks | elapsed: 31m 19s | remaining: 1m 39s\n",
      "Done 10000 out of 10000 tasks | elapsed: 32m 58s | finished\n"
     ]
    }
   ],
   "source": [
    "accuracy_scores = []\n",
    "start_loop = time.time()\n",
    "\n",
    "for ix, (tree, (X_sub_train, y_sub_train)) in enumerate(zip(forest, subsets)):\n",
    "    tree.fit(X_sub_train, y_sub_train)\n",
    "    y_pred = tree.predict(X_test)\n",
    "    accuracy_scores.append(accuracy_score(y_test, y_pred))\n",
    "    if ix % 500 == 0 and ix != 0:\n",
    "        ix_time = time.time()\n",
    "        mins, secs = divmod(ix_time - start_loop, 60)\n",
    "        avg_ix_time = (ix_time-start_loop)/(ix+1)\n",
    "        rest_ix = n_trees-ix\n",
    "        rest_mins, rest_secs = divmod(rest_ix * avg_ix_time, 60)\n",
    "        print(f'Done {ix+1:0.0f} out of {n_trees:0.0f} tasks | \\\n",
    "elapsed: {mins:0.0f}m {secs:0.0f}s | remaining: {rest_mins:0.0f}m {rest_secs:0.0f}s')\n",
    "    if ix == n_trees-1:\n",
    "        ix_time = time.time()\n",
    "        mins, secs = divmod(ix_time - start_loop, 60)\n",
    "        print(f'Done {ix+1:0.0f} out of {n_trees:0.0f} tasks | \\\n",
    "elapsed: {mins:0.0f}m {secs:0.0f}s | finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6375"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(np.mean(accuracy_scores), 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**magic** step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = np.empty([n_trees, X_test.shape[0]], dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate predictions for each classifier\n",
    "for ix, tree in enumerate(forest):         \n",
    "    Y_pred[ix] = tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute mode for each y_pred\n",
    "y_pred_majority_votes, n_votes = mode(Y_pred, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.687"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get accuracy of preds on test target\n",
    "round(accuracy_score(y_test, y_pred_majority_votes.reshape([-1])), 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To recap, we trained DIY random forests leveraging Scikit-learn's **DecisionTreeClassifier** class three times using the following changing parameters (keeping `max_leaf_nodes=99`). Curiously, the fastest and smallest tree got the best accuracy so far. \n",
    "\n",
    "```\n",
    "n_trees=1000\n",
    "n_instances=100\n",
    "max_features=\"sqrt\"\n",
    "avg accuracy=0.5371\n",
    "majority vote accuracy=0.6929\n",
    "\n",
    "n_trees = 10000\n",
    "n_instances = 2000\n",
    "max_features=\"sqrt\"\n",
    "avg accuracy=0.593\n",
    "majority vote accuracy=0.6842\n",
    "\n",
    "n_trees = 10000\n",
    "n_instances = 2000\n",
    "max_features=11000\n",
    "avg accuracy=0.6375\n",
    "majority vote accuracy=0.687\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scikit-learn's RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[(source)](https://github.com/scikit-learn/scikit-learn/blob/0fb307bf3/sklearn/ensemble/_forest.py#L883)\n",
    "\n",
    "```\n",
    "class sklearn.ensemble.RandomForestClassifier(n_estimators=100, *, criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto', max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False, class_weight=None, ccp_alpha=0.0, max_samples=None.\n",
    "```\n",
    "\n",
    "Noticeably, when `bootstrap=True`, which is the default, then `max_samples=None` which means the entire instance space is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_clf = RandomForestClassifier(n_estimators=1000, # same value as first DIY forest\n",
    "                                max_samples=100, # ibid.\n",
    "                                max_features=\"sqrt\", # ibid.\n",
    "                                max_leaf_nodes=99, # ibid.\n",
    "                                random_state=42, # ibid.\n",
    "                                n_jobs=-1, \n",
    "                                verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:    8.4s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:   15.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:   19.4s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_features='sqrt', max_leaf_nodes=99, max_samples=100,\n",
       "                       n_estimators=1000, n_jobs=-1, random_state=42,\n",
       "                       verbose=1)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=8)]: Done 784 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=8)]: Done 1000 out of 1000 | elapsed:    3.9s finished\n"
     ]
    }
   ],
   "source": [
    "y_pred = rf_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6993"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(accuracy_score(y_test, y_pred), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    5.1s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:   10.1s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:   17.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:   21.2s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=8)]: Done 784 tasks      | elapsed:    4.9s\n",
      "[Parallel(n_jobs=8)]: Done 1000 out of 1000 | elapsed:    6.2s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   28.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................................. , total=  28.8s\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:    8.2s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:   14.9s\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:   19.1s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=8)]: Done 784 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=8)]: Done 1000 out of 1000 | elapsed:    3.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................................. , total=  23.9s\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done 352 tasks      | elapsed:    3.9s\n",
      "[Parallel(n_jobs=-1)]: Done 852 tasks      | elapsed:    9.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:   11.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=8)]: Done 784 tasks      | elapsed:    2.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................................. , total=  15.3s\n",
      "Accuracy: 0.70 (+/- 0.01)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done 1000 out of 1000 | elapsed:    3.5s finished\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  1.1min finished\n"
     ]
    }
   ],
   "source": [
    "# more robust evaluation\n",
    "scores = cross_val_score(rf_clf, X_train_transformed, y_array, cv=3, verbose=2, scoring='accuracy')\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf = RandomForestClassifier(n_estimators=10000, # same value as second DIY forest\n",
    "                                max_samples=2000, # ibid.\n",
    "                                max_features=\"sqrt\", # ibid.\n",
    "                                max_leaf_nodes=99, # ibid.\n",
    "                                random_state=42, # ibid.\n",
    "                                n_jobs=-1, \n",
    "                                verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:    7.0s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:   13.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed:   20.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1784 tasks      | elapsed:   29.5s\n",
      "[Parallel(n_jobs=-1)]: Done 2434 tasks      | elapsed:   39.8s\n",
      "[Parallel(n_jobs=-1)]: Done 3184 tasks      | elapsed:   51.7s\n",
      "[Parallel(n_jobs=-1)]: Done 4034 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 4984 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 6034 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 7184 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 8434 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 9784 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 10000 out of 10000 | elapsed:  2.7min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_features='sqrt', max_leaf_nodes=99, max_samples=2000,\n",
       "                       n_estimators=10000, n_jobs=-1, random_state=42,\n",
       "                       verbose=1)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=8)]: Done 784 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=8)]: Done 1234 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=8)]: Done 1784 tasks      | elapsed:    4.7s\n",
      "[Parallel(n_jobs=8)]: Done 2434 tasks      | elapsed:    6.4s\n",
      "[Parallel(n_jobs=8)]: Done 3184 tasks      | elapsed:    8.4s\n",
      "[Parallel(n_jobs=8)]: Done 4034 tasks      | elapsed:   10.6s\n",
      "[Parallel(n_jobs=8)]: Done 4984 tasks      | elapsed:   13.1s\n",
      "[Parallel(n_jobs=8)]: Done 6034 tasks      | elapsed:   15.9s\n",
      "[Parallel(n_jobs=8)]: Done 7184 tasks      | elapsed:   18.9s\n",
      "[Parallel(n_jobs=8)]: Done 8434 tasks      | elapsed:   22.2s\n",
      "[Parallel(n_jobs=8)]: Done 9784 tasks      | elapsed:   25.7s\n",
      "[Parallel(n_jobs=8)]: Done 10000 out of 10000 | elapsed:   26.3s finished\n"
     ]
    }
   ],
   "source": [
    "y_pred = rf_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7441"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(accuracy_score(y_test, y_pred), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 352 tasks      | elapsed:    4.8s\n",
      "[Parallel(n_jobs=-1)]: Done 852 tasks      | elapsed:   11.8s\n",
      "[Parallel(n_jobs=-1)]: Done 1552 tasks      | elapsed:   21.9s\n",
      "[Parallel(n_jobs=-1)]: Done 2452 tasks      | elapsed:   34.4s\n",
      "[Parallel(n_jobs=-1)]: Done 3552 tasks      | elapsed:   49.6s\n",
      "[Parallel(n_jobs=-1)]: Done 4852 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 6352 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 8052 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 9952 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 10000 out of 10000 | elapsed:  2.3min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=8)]: Done 784 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=8)]: Done 1234 tasks      | elapsed:    5.2s\n",
      "[Parallel(n_jobs=8)]: Done 1784 tasks      | elapsed:    7.6s\n",
      "[Parallel(n_jobs=8)]: Done 2434 tasks      | elapsed:   10.5s\n",
      "[Parallel(n_jobs=8)]: Done 3184 tasks      | elapsed:   13.8s\n",
      "[Parallel(n_jobs=8)]: Done 4034 tasks      | elapsed:   17.5s\n",
      "[Parallel(n_jobs=8)]: Done 4984 tasks      | elapsed:   21.5s\n",
      "[Parallel(n_jobs=8)]: Done 6034 tasks      | elapsed:   25.9s\n",
      "[Parallel(n_jobs=8)]: Done 7184 tasks      | elapsed:   30.8s\n",
      "[Parallel(n_jobs=8)]: Done 8434 tasks      | elapsed:   36.1s\n",
      "[Parallel(n_jobs=8)]: Done 9784 tasks      | elapsed:   42.0s\n",
      "[Parallel(n_jobs=8)]: Done 10000 out of 10000 | elapsed:   43.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  3.1min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................................. , total= 3.1min\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done 352 tasks      | elapsed:    5.0s\n",
      "[Parallel(n_jobs=-1)]: Done 852 tasks      | elapsed:   12.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1552 tasks      | elapsed:   22.2s\n",
      "[Parallel(n_jobs=-1)]: Done 2452 tasks      | elapsed:   35.3s\n",
      "[Parallel(n_jobs=-1)]: Done 3552 tasks      | elapsed:   50.7s\n",
      "[Parallel(n_jobs=-1)]: Done 4852 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 6352 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 8052 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 9952 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 10000 out of 10000 | elapsed:  2.4min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=8)]: Done 784 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=8)]: Done 1234 tasks      | elapsed:    5.2s\n",
      "[Parallel(n_jobs=8)]: Done 1784 tasks      | elapsed:    7.6s\n",
      "[Parallel(n_jobs=8)]: Done 2434 tasks      | elapsed:   10.4s\n",
      "[Parallel(n_jobs=8)]: Done 3184 tasks      | elapsed:   13.6s\n",
      "[Parallel(n_jobs=8)]: Done 4034 tasks      | elapsed:   17.2s\n",
      "[Parallel(n_jobs=8)]: Done 4984 tasks      | elapsed:   21.5s\n",
      "[Parallel(n_jobs=8)]: Done 6034 tasks      | elapsed:   26.1s\n",
      "[Parallel(n_jobs=8)]: Done 7184 tasks      | elapsed:   31.0s\n",
      "[Parallel(n_jobs=8)]: Done 8434 tasks      | elapsed:   36.3s\n",
      "[Parallel(n_jobs=8)]: Done 9784 tasks      | elapsed:   42.1s\n",
      "[Parallel(n_jobs=8)]: Done 10000 out of 10000 | elapsed:   43.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................................. , total= 3.1min\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done 352 tasks      | elapsed:    4.9s\n",
      "[Parallel(n_jobs=-1)]: Done 852 tasks      | elapsed:   12.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1552 tasks      | elapsed:   21.9s\n",
      "[Parallel(n_jobs=-1)]: Done 2452 tasks      | elapsed:   34.5s\n",
      "[Parallel(n_jobs=-1)]: Done 3552 tasks      | elapsed:   50.4s\n",
      "[Parallel(n_jobs=-1)]: Done 4852 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 6352 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 8052 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 9952 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 10000 out of 10000 | elapsed:  2.4min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=8)]: Done 784 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=8)]: Done 1234 tasks      | elapsed:    5.2s\n",
      "[Parallel(n_jobs=8)]: Done 1784 tasks      | elapsed:    7.6s\n",
      "[Parallel(n_jobs=8)]: Done 2434 tasks      | elapsed:   10.3s\n",
      "[Parallel(n_jobs=8)]: Done 3184 tasks      | elapsed:   13.5s\n",
      "[Parallel(n_jobs=8)]: Done 4034 tasks      | elapsed:   17.1s\n",
      "[Parallel(n_jobs=8)]: Done 4984 tasks      | elapsed:   21.1s\n",
      "[Parallel(n_jobs=8)]: Done 6034 tasks      | elapsed:   25.7s\n",
      "[Parallel(n_jobs=8)]: Done 7184 tasks      | elapsed:   30.8s\n",
      "[Parallel(n_jobs=8)]: Done 8434 tasks      | elapsed:   36.1s\n",
      "[Parallel(n_jobs=8)]: Done 9784 tasks      | elapsed:   41.9s\n",
      "[Parallel(n_jobs=8)]: Done 10000 out of 10000 | elapsed:   42.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................................. , total= 3.2min\n",
      "Accuracy: 0.75 (+/- 0.00)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  9.4min finished\n"
     ]
    }
   ],
   "source": [
    "# more robust evaluation\n",
    "scores = cross_val_score(rf_clf, X_train_transformed, y_array, cv=3, verbose=2, scoring='accuracy')\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the same values as the third DIY forest decreased accuracy to $73\\%$ after cross validation - in other words, we started overfitting. So the second classifier performed best so far with $75\\%$ accuracy. I'm attempting one more semi-random choice below and then doing some light grid search as a last ditch attempt to crack $80\\%$ accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf = RandomForestClassifier(n_estimators=300, # grow few trees...\n",
    "                                max_depth=500, # ... as deep as they go...\n",
    "                                max_features=\"sqrt\", # using default num features (about 224)\n",
    "                                max_samples=5000, # and a reasonable instance space - maybe increase?\n",
    "                                random_state=42,\n",
    "                                n_jobs=-1, \n",
    "                                verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   10.9s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   50.9s\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  1.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=500, max_features='sqrt', max_samples=5000,\n",
       "                       n_estimators=300, n_jobs=-1, random_state=42, verbose=1)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=8)]: Done 300 out of 300 | elapsed:    2.9s finished\n"
     ]
    }
   ],
   "source": [
    "y_pred = rf_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7616"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(accuracy_score(y_test, y_pred), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   17.0s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   56.4s\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  1.5min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=8)]: Done 300 out of 300 | elapsed:    4.9s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.6min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................................. , total= 1.6min\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   10.3s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   48.7s\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  1.3min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=8)]: Done 300 out of 300 | elapsed:    4.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................................. , total= 1.4min\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   10.3s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   48.4s\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  1.3min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    3.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................................. , total= 1.4min\n",
      "Accuracy: 0.76 (+/- 0.00)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done 300 out of 300 | elapsed:    5.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  4.4min finished\n"
     ]
    }
   ],
   "source": [
    "# more robust evaluation\n",
    "scores = cross_val_score(rf_clf, X_train_transformed, y_array, cv=3, verbose=2, scoring='accuracy')\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid search\n",
    "\n",
    "Since random forest take time, I'm just performing a small grid search, still keeping that `max_leaf_nodes=99` parameter constant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {'n_estimators': [500, 1000, 2000],\n",
    "          'max_features':[200, 400, 800],\n",
    "          'max_samples':[1000, 2000, 4000, 8000],\n",
    "          'max_depth':[2, 8, 64, 512]}\n",
    "\n",
    "rf_clf = RandomForestClassifier(random_state=42, max_leaf_nodes=99)\n",
    "\n",
    "grid_search_cv = GridSearchCV(rf_clf, params, n_jobs=-1, verbose=1, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 144 candidates, totalling 432 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  5.9min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed: 37.5min\n",
      "[Parallel(n_jobs=-1)]: Done 432 out of 432 | elapsed: 140.7min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=RandomForestClassifier(max_leaf_nodes=99,\n",
       "                                              random_state=42),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'max_depth': [2, 8, 64, 512],\n",
       "                         'max_features': [200, 400, 800],\n",
       "                         'max_samples': [1000, 2000, 4000, 8000],\n",
       "                         'n_estimators': [500, 1000, 2000]},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 512,\n",
       " 'max_features': 200,\n",
       " 'max_samples': 8000,\n",
       " 'n_estimators': 1000}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7498"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = grid_search_cv.predict(X_test)\n",
    "round(accuracy_score(y_test, y_pred), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max mean test accuracy: 0.7527 \n",
      "Params: {'max_depth': 512, 'max_features': 200, 'max_samples': 8000, 'n_estimators': 1000}\n"
     ]
    }
   ],
   "source": [
    "# all other \"best\" params\n",
    "for i,v in enumerate(grid_search_cv.cv_results_['mean_test_score']):\n",
    "    if v == max(grid_search_cv.cv_results_['mean_test_score']):\n",
    "        print('Max mean test accuracy:', round(v, 4), \\\n",
    "              '\\nParams:', grid_search_cv.cv_results_['params'][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save gridsearch results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load\n",
    "\n",
    "model_dir = os.path.join(\"..\",\"data\",\"4_models\",\"sentiment140\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['..\\\\data\\\\4_models\\\\sentiment140\\\\20201026_RandomForestClassifier_GridSearchCV.joblib']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = os.path.join(model_dir, \"20201026_RandomForestClassifier_GridSearchCV.joblib\")\n",
    "dump(grid_search_cv, file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
