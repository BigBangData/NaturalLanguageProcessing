{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Twitter Setiment Analysis \n",
    "\n",
    "### Part 2: sentiment140 pre-processing for ML\n",
    "\n",
    "The code was originally inspired Gaurav Singhal's guide: [Building a Twitter Setiment Analysis in Python.](https://www.pluralsight.com/guides/building-a-twitter-sentiment-analysis-in-python)\n",
    "\n",
    "The data comes from Marios Michailidis' sentiment140 dataset hosted in [Kaggle.](https://www.kaggle.com/kazanova/sentiment140/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished in 9.34 second(s)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import load_data as ld\n",
    "\n",
    "start = time.perf_counter()\n",
    "\n",
    "df = ld.run_processes()\n",
    "\n",
    "finish = time.perf_counter()\n",
    "print(f'Finished in {round(finish-start, 2)} second(s)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>filtered</th>\n",
       "      <th>stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>is upset that he cant update his facebook by t...</td>\n",
       "      <td>upset cant update his facebook texting might c...</td>\n",
       "      <td>upset cant updat hi facebook text might cri re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "      <td>i dived many times for the ball managed to sav...</td>\n",
       "      <td>i dived many times ball managed save 50 rest g...</td>\n",
       "      <td>i dive mani time ball manag save 50 rest go ou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>my whole body feels itchy like fire</td>\n",
       "      <td>my whole bodi feel itchi like fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "      <td>no its not behaving at all im mad why am i her...</td>\n",
       "      <td>no not behaving all im mad why am i here becau...</td>\n",
       "      <td>no not behav all im mad whi am i here becaus i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kwesidei not the whole crew</td>\n",
       "      <td>not the whole crew</td>\n",
       "      <td>not whole crew</td>\n",
       "      <td>not whole crew</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target                                               text  \\\n",
       "0       0  is upset that he can't update his Facebook by ...   \n",
       "1       0  @Kenichan I dived many times for the ball. Man...   \n",
       "2       0    my whole body feels itchy and like its on fire    \n",
       "3       0  @nationwideclass no, it's not behaving at all....   \n",
       "4       0                      @Kwesidei not the whole crew    \n",
       "\n",
       "                                           tokenized  \\\n",
       "0  is upset that he cant update his facebook by t...   \n",
       "1  i dived many times for the ball managed to sav...   \n",
       "2     my whole body feels itchy and like its on fire   \n",
       "3  no its not behaving at all im mad why am i her...   \n",
       "4                                 not the whole crew   \n",
       "\n",
       "                                            filtered  \\\n",
       "0  upset cant update his facebook texting might c...   \n",
       "1  i dived many times ball managed save 50 rest g...   \n",
       "2                my whole body feels itchy like fire   \n",
       "3  no not behaving all im mad why am i here becau...   \n",
       "4                                     not whole crew   \n",
       "\n",
       "                                             stemmed  \n",
       "0  upset cant updat hi facebook text might cri re...  \n",
       "1  i dive mani time ball manag save 50 rest go ou...  \n",
       "2                 my whole bodi feel itchi like fire  \n",
       "3  no not behav all im mad whi am i here becaus i...  \n",
       "4                                     not whole crew  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>filtered</th>\n",
       "      <th>stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1599994</th>\n",
       "      <td>1</td>\n",
       "      <td>Just woke up. Having no school is the best fee...</td>\n",
       "      <td>just woke up having no school is the best feel...</td>\n",
       "      <td>just woke up having no school best feeling ever</td>\n",
       "      <td>just woke up have no school best feel ever</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599995</th>\n",
       "      <td>1</td>\n",
       "      <td>TheWDB.com - Very cool to hear old Walt interv...</td>\n",
       "      <td>very cool to hear old walt interviews</td>\n",
       "      <td>very cool hear old walt interviews</td>\n",
       "      <td>veri cool hear old walt interview</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599996</th>\n",
       "      <td>1</td>\n",
       "      <td>Are you ready for your MoJo Makeover? Ask me f...</td>\n",
       "      <td>are you ready for your mojo makeover ask me fo...</td>\n",
       "      <td>you ready your mojo makeover ask me details</td>\n",
       "      <td>you readi your mojo makeov ask me detail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599997</th>\n",
       "      <td>1</td>\n",
       "      <td>Happy 38th Birthday to my boo of alll time!!! ...</td>\n",
       "      <td>happy 38th birthday to my boo of alll time tup...</td>\n",
       "      <td>happy 38th birthday my boo alll time tupac ama...</td>\n",
       "      <td>happi 38th birthday my boo alll time tupac ama...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599998</th>\n",
       "      <td>1</td>\n",
       "      <td>happy #charitytuesday @theNSPCC @SparksCharity...</td>\n",
       "      <td>happy charitytuesday</td>\n",
       "      <td>happy charitytuesday</td>\n",
       "      <td>happi charitytuesday</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         target                                               text  \\\n",
       "1599994       1  Just woke up. Having no school is the best fee...   \n",
       "1599995       1  TheWDB.com - Very cool to hear old Walt interv...   \n",
       "1599996       1  Are you ready for your MoJo Makeover? Ask me f...   \n",
       "1599997       1  Happy 38th Birthday to my boo of alll time!!! ...   \n",
       "1599998       1  happy #charitytuesday @theNSPCC @SparksCharity...   \n",
       "\n",
       "                                                 tokenized  \\\n",
       "1599994  just woke up having no school is the best feel...   \n",
       "1599995              very cool to hear old walt interviews   \n",
       "1599996  are you ready for your mojo makeover ask me fo...   \n",
       "1599997  happy 38th birthday to my boo of alll time tup...   \n",
       "1599998                               happy charitytuesday   \n",
       "\n",
       "                                                  filtered  \\\n",
       "1599994    just woke up having no school best feeling ever   \n",
       "1599995                 very cool hear old walt interviews   \n",
       "1599996        you ready your mojo makeover ask me details   \n",
       "1599997  happy 38th birthday my boo alll time tupac ama...   \n",
       "1599998                               happy charitytuesday   \n",
       "\n",
       "                                                   stemmed  \n",
       "1599994         just woke up have no school best feel ever  \n",
       "1599995                  veri cool hear old walt interview  \n",
       "1599996           you readi your mojo makeov ask me detail  \n",
       "1599997  happi 38th birthday my boo alll time tupac ama...  \n",
       "1599998                               happi charitytuesday  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Data for ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### drop NAs created during cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target          0\n",
       "text            0\n",
       "tokenized    3696\n",
       "filtered     3819\n",
       "stemmed      3819\n",
       "dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfm = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target       0\n",
       "text         0\n",
       "tokenized    0\n",
       "filtered     0\n",
       "stemmed      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfm.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1599999, 5), (1596180, 5))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape, dfm.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorize with TF-IDF\n",
    "\n",
    "Also try Bag of Words and N-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(sublinear_tf=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(dfm.iloc[:, 0]).ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vectorizer.fit_transform(np.array(dfm.iloc[:, 2]).ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.775495244897192\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes\n",
    "NB_model = MultinomialNB()\n",
    "NB_model.fit(X_train, y_train)\n",
    "y_predict_nb = NB_model.predict(X_test)\n",
    "print(accuracy_score(y_test, y_predict_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7751099500056384\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "from sklearn import preprocessing\n",
    "\n",
    "LR_model = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "\n",
    "X_train_scaled = preprocessing.scale(X_train, with_mean=False)\n",
    "X_test_scale = preprocessing.scale(X_test, with_mean=False)\n",
    "LR_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_predict_lr = LR_model.predict(X_test_scale)\n",
    "\n",
    "print(accuracy_score(y_test, y_predict_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes is giving nearly 76% accuracy, and Logistic Regression gives nearly 79%. These accuracy figures are recorded without implementing stemming or lemmatization. Using better techniques, you might get better accuracy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vectorizer.fit_transform(np.array(dfm.iloc[:, 3]).ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7747685098171886\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes\n",
    "NB_model = MultinomialNB()\n",
    "NB_model.fit(X_train, y_train)\n",
    "y_predict_nb = NB_model.predict(X_test)\n",
    "print(accuracy_score(y_test, y_predict_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7742391209011515\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "LR_model = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "\n",
    "X_train_scaled = preprocessing.scale(X_train, with_mean=False)\n",
    "X_test_scale = preprocessing.scale(X_test, with_mean=False)\n",
    "LR_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_predict_lr = LR_model.predict(X_test_scale)\n",
    "\n",
    "print(accuracy_score(y_test, y_predict_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vectorizer.fit_transform(np.array(dfm.iloc[:, 4]).ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7701355736821661\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes\n",
    "NB_model = MultinomialNB()\n",
    "NB_model.fit(X_train, y_train)\n",
    "y_predict_nb = NB_model.predict(X_test)\n",
    "print(accuracy_score(y_test, y_predict_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.773697202069942\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "LR_model = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "\n",
    "X_train_scaled = preprocessing.scale(X_train, with_mean=False)\n",
    "X_test_scale = preprocessing.scale(X_test, with_mean=False)\n",
    "LR_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_predict_lr = LR_model.predict(X_test_scale)\n",
    "\n",
    "print(accuracy_score(y_test, y_predict_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vectorizer.fit_transform(np.array(dfm.iloc[:, 1]).ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7747309200716711\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes\n",
    "NB_model = MultinomialNB()\n",
    "NB_model.fit(X_train, y_train)\n",
    "y_predict_nb = NB_model.predict(X_test)\n",
    "print(accuracy_score(y_test, y_predict_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7620788382262652\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "LR_model = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "\n",
    "X_train_scaled = preprocessing.scale(X_train, with_mean=False)\n",
    "X_test_scale = preprocessing.scale(X_test, with_mean=False)\n",
    "LR_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_predict_lr = LR_model.predict(X_test_scale)\n",
    "\n",
    "print(accuracy_score(y_test, y_predict_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use other vectorization techniques, apply feature extraxtion and feature selection, implement other ML models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
