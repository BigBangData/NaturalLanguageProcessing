{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple GridsearchCV with DecisionTreeClassifer \n",
    "\n",
    "End of chapter (6) exercise from Aurelien Geron's famous *Hands-On Machine Learning with Scikit-Learn & Tensorflow*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.9402914 ,  0.12230559],\n",
       "        [ 0.12454026, -0.42477546],\n",
       "        [ 0.26198823,  0.50841438],\n",
       "        ...,\n",
       "        [-0.24177973,  0.20957199],\n",
       "        [ 0.90679645,  0.54958215],\n",
       "        [ 2.08837082, -0.05050728]]),\n",
       " array([1, 0, 0, ..., 1, 0, 1], dtype=int64))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "\n",
    "X, y = make_moons(n_samples=10000, noise=0.4, random_state=42)\n",
    "\n",
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approx. tree depth without restrictions: 13\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# get notion of max depth's theoretical limit\n",
    "print(f'Approx. tree depth without restrictions: {np.ceil(np.log2(len(X_train))):0.0f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 990 candidates, totalling 2970 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  40 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=6)]: Done 2060 tasks      | elapsed:   10.6s\n",
      "[Parallel(n_jobs=6)]: Done 2970 out of 2970 | elapsed:   14.7s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=DecisionTreeClassifier(random_state=42), n_jobs=6,\n",
       "             param_grid={'max_leaf_nodes': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,\n",
       "                                            13, 14, 15, 16, 17, 18, 19, 20, 21,\n",
       "                                            22, 23, 24, 25, 26, 27, 28, 29, 30,\n",
       "                                            31, ...],\n",
       "                         'min_samples_split': [2, 3, 4, 5, 6]},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "params = {'max_leaf_nodes': list(range(2, 200)), \n",
    "          'min_samples_split': [2, 3, 4, 5, 6]}\n",
    "\n",
    "grid_search_cv = GridSearchCV(DecisionTreeClassifier(random_state=42), \n",
    "                              params, n_jobs=6, verbose=1, cv=3)\n",
    "\n",
    "grid_search_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_leaf_nodes=17, random_state=42)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mean_fit_time',\n",
       " 'mean_score_time',\n",
       " 'mean_test_score',\n",
       " 'param_max_leaf_nodes',\n",
       " 'param_min_samples_split',\n",
       " 'params',\n",
       " 'rank_test_score',\n",
       " 'split0_test_score',\n",
       " 'split1_test_score',\n",
       " 'split2_test_score',\n",
       " 'std_fit_time',\n",
       " 'std_score_time',\n",
       " 'std_test_score']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(grid_search_cv.cv_results_.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A. Geron**: By default, `GridSearchCV` trains the best model found on the whole training set (you can change this by setting `refit=False`), so we don't need to do it again. We can simply evaluate the model's accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8695"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = grid_search_cv.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max mean test accuracy: 0.8555 \n",
      "Params: {'max_leaf_nodes': 17, 'min_samples_split': 2}\n",
      "Max mean test accuracy: 0.8555 \n",
      "Params: {'max_leaf_nodes': 17, 'min_samples_split': 3}\n",
      "Max mean test accuracy: 0.8555 \n",
      "Params: {'max_leaf_nodes': 17, 'min_samples_split': 4}\n",
      "Max mean test accuracy: 0.8555 \n",
      "Params: {'max_leaf_nodes': 17, 'min_samples_split': 5}\n",
      "Max mean test accuracy: 0.8555 \n",
      "Params: {'max_leaf_nodes': 17, 'min_samples_split': 6}\n"
     ]
    }
   ],
   "source": [
    "for i,v in enumerate(grid_search_cv.cv_results_['mean_test_score']):\n",
    "    if v == max(grid_search_cv.cv_results_['mean_test_score']):\n",
    "        print('Max mean test accuracy:', round(v,4), \\\n",
    "              '\\nParams:', grid_search_cv.cv_results_['params'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8695"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train with those params in entire training set\n",
    "dtree = DecisionTreeClassifier(random_state=42, min_samples_split=2, # or 3, 4, 5, 6...\n",
    "                               max_leaf_nodes=17)\n",
    "dtree.fit(X_train, y_train)\n",
    "\n",
    "# predict on test set\n",
    "y_preds = dtree.predict(X_test)\n",
    "\n",
    "# print accuracy on test target\n",
    "accuracy_score(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grow a Random Forest\n",
    "\n",
    "With 1000 trees of 100 instances each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "subsets = []\n",
    "\n",
    "rs = ShuffleSplit(n_splits=1000, test_size=len(X_train) - 100, random_state=42)\n",
    "for train_sub_ix, test_sub_ix in rs.split(X_train):\n",
    "    X_sub_train = X_train[train_sub_ix]\n",
    "    y_sub_train = y_train[train_sub_ix]\n",
    "    subsets.append((X_sub_train, y_sub_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.31532549,  0.49432266],\n",
       "        [ 1.07395888, -0.38300687],\n",
       "        [ 1.2336808 , -0.20272754],\n",
       "        [ 1.45327595, -0.49765049],\n",
       "        [ 0.62940312, -0.45805718],\n",
       "        [ 1.31621613, -0.49634063],\n",
       "        [ 0.66160502, -0.52512066],\n",
       "        [ 1.17772151,  0.21289673],\n",
       "        [ 1.27074026,  0.83761848],\n",
       "        [ 0.24077774, -0.40528032]]),\n",
       " array([1, 1, 0, 1, 1, 1, 1, 1, 1, 1], dtype=int64))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subsets[0][0][:10], subsets[0][1][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import clone\n",
    "\n",
    "forest = [clone(grid_search_cv.best_estimator_) for _ in range(1000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DecisionTreeClassifier(max_leaf_nodes=17, random_state=42),\n",
       " DecisionTreeClassifier(max_leaf_nodes=17, random_state=42),\n",
       " DecisionTreeClassifier(max_leaf_nodes=17, random_state=42),\n",
       " DecisionTreeClassifier(max_leaf_nodes=17, random_state=42),\n",
       " DecisionTreeClassifier(max_leaf_nodes=17, random_state=42)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8054499999999999"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_scores = []\n",
    "\n",
    "# train 1000 decision tree classifiers (but... are't they all the same? Why do we need to clone...)\n",
    "for tree, (X_sub_train, y_sub_train) in zip(forest, subsets):\n",
    "    tree.fit(X_sub_train, y_sub_train)\n",
    "    \n",
    "    y_pred = tree.predict(X_test)\n",
    "    accuracy_scores.append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "np.mean(accuracy_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my old code\n",
    "X_rf, y_rf = [], []\n",
    "for i,v in enumerate(rs.split(X_train, y_train)):\n",
    "    X_rf.append(X_train[v[0]])\n",
    "    y_rf.append(y_train[v[0]])\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state=42, max_leaf_nodes=17)\n",
    "\n",
    "accs = []\n",
    "for ix, tree in enumerate(X_rf):\n",
    "    clf.fit(tree, y_rf[ix])\n",
    "    y_pred = clf.predict(X_test)\n",
    "    accs.append(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8054499999999999"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Magic:** \n",
    "\n",
    "- for each test set instance, generate the predictions of the 1000 trees \n",
    "- keep only the most frequent prediction (the *mode*)\n",
    "\n",
    "This procedure gives you the majority-vote predictions over the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = np.empty([1000, len(X_test)], dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 2000)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred.shape # just a 1k by 2k empty matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tree_ix, tree in enumerate(forest):\n",
    "    Y_pred[tree_ix] = tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, ..., 0, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest[0].predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest[1].predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mode\n",
    "\n",
    "y_pred_majority_votes, n_votes = mode(Y_pred, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.872"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred_majority_votes.reshape([-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my old code\n",
    "from scipy import stats\n",
    "\n",
    "y_preds = []\n",
    "for ix, tree in enumerate(X_rf):\n",
    "    clf.fit(tree, y_rf[ix])\n",
    "    y_preds.append(clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds_array = np.vstack(y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "majority_vote = stats.mode(y_preds_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "majority_vote[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.872"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, majority_vote[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
