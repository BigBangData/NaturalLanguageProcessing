{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latent Semantic Analysis (LSA)\n",
    "\n",
    "This notebook is for developing, not implementing a solution.\n",
    "\n",
    "*Current State*\n",
    "- Preprocessing was performed for a Bag-of-upto-Ngrams with TF-IDF representation\n",
    "- This type of representation still suffers from the curse of dimensionality, best accuracies achieved with a Bag-of-upto-Trigram TF-IDF training subset of 120k documents (Tweets) and 100k terms\n",
    "- LSA, in particular, matrix decomposition using SVD, can be used to reduce a document-term matrix to a document-component (or topic) matrix\n",
    "\n",
    "*Results*\n",
    "- SVD did not seem to improve accuracy, speed, or reduce the size of the data\n",
    "- Unclear whether I'm not implementing it correctly or it's just not useful given this type of problem and goal, maybe it is really meant to help interpret the data, not improve accuracy or prediction speed\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import cleanup_module as Cmod\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample 10% of the training data for POC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load minimally prepared X, y train subsets\n",
    "raw_path = os.path.join(\"..\",\"data\",\"1_raw\",\"sentiment140\")\n",
    "X_train = pd.read_csv(os.path.join(raw_path, \"X_train.csv\"))\n",
    "y_train = pd.read_csv(os.path.join(raw_path, \"y_train.csv\"))\n",
    "\n",
    "# sample for dev\n",
    "X, X_rest, y, y_rest = train_test_split(X_train, y_train, test_size=0.9, random_state=42)\n",
    "\n",
    "# create array\n",
    "X_array = np.array(X.iloc[:, 2]).ravel()\n",
    "y_array = y.iloc[:,0].ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((119747,), (119747,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_array.shape, y_array.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Bag-of-upto-Trigrams with 100,000 terms\n",
    "\n",
    "Using `sublinear_tf=True, use_idf=True` as recommended in [docs](https://scikit-learn.org/stable/modules/decomposition.html#lsa): \n",
    "\n",
    "*In particular, sublinear scaling and inverse document frequency should be turned on (`sublinear_tf=True, use_idf=True`) to bring the feature values closer to a Gaussian distribution, compensating for LSAâ€™s erroneous assumptions about textual data.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('counter', Cmod.DocumentToNgramCounterTransformer(n_grams=3)),\n",
    "                 ('bow', Cmod.WordCounterToVectorTransformer(vocabulary_size=100000)),\n",
    "                 ('tfidf', TfidfTransformer(sublinear_tf=True, use_idf=True))]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed: 2 min 1 sec\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "X_train_transformed = pipe.fit_transform(X_array)\n",
    "\n",
    "mins, secs = divmod(time.time() - start_time, 60)\n",
    "print(f'Elapsed: {mins:0.0f} min {secs:0.0f} sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<119747x50001 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 2232287 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_transformed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVD\n",
    "\n",
    "Point of departure: [Analytics Vidhya Tutorial](https://www.analyticsvidhya.com/blog/2018/10/stepwise-guide-topic-modeling-latent-semantic-analysis/). \n",
    "\n",
    "Consulted Prof. Steve Brunton's [YouTube lecture series](https://www.youtube.com/playlist?list=PLMrJAkhIeNNSVjnsviglFoY2nXildDCcv) and [Data-Driven Science and Engineering book](https://www.amazon.com/Data-Driven-Science-Engineering-Learning-Dynamical/dp/1108422098). \n",
    "\n",
    "Using sklearn's **TruncatedSVD** class, \"arpack\" algorithm. The \"randomized\" algorithm takes longer and arrives at the same result as far as I could tell, here are the relevant parts of the docs:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[(source)](https://github.com/scikit-learn/scikit-learn/blob/0fb307bf3/sklearn/decomposition/_truncated_svd.py#L24)\n",
    "```\n",
    "    def fit_transform(self, X, y=None):\n",
    "        \"\"\"Fit LSI model to X and perform dimensionality reduction on X.\n",
    "        \n",
    "        [...]\n",
    "        \n",
    "        if self.algorithm == \"arpack\":\n",
    "            U, Sigma, VT = svds(X, k=self.n_components, tol=self.tol)\n",
    "            # svds doesn't abide by scipy.linalg.svd/randomized_svd\n",
    "            # conventions, so reverse its outputs.\n",
    "            Sigma = Sigma[::-1]\n",
    "            U, VT = svd_flip(U[:, ::-1], VT[::-1])\n",
    "\n",
    "        elif self.algorithm == \"randomized\":\n",
    "            k = self.n_components\n",
    "            n_features = X.shape[1]\n",
    "            if k >= n_features:\n",
    "                raise ValueError(\"n_components must be < n_features;\"\n",
    "                                 \" got %d >= %d\" % (k, n_features))\n",
    "            U, Sigma, VT = randomized_svd(X, self.n_components,\n",
    "                                          n_iter=self.n_iter,\n",
    "                                          random_state=random_state)\n",
    "        else:\n",
    "            raise ValueError(\"unknown algorithm %r\" % self.algorithm)\n",
    "\n",
    "        self.components_ = VT\n",
    "\n",
    "        # Calculate explained variance & explained variance ratio\n",
    "        X_transformed = U * Sigma\n",
    "        \n",
    "        [...]\n",
    "        \n",
    "        self.singular_values_ = Sigma  # Store the singular values.\n",
    "\n",
    "        return X_transformed\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\"Perform dimensionality reduction on X.\n",
    "        [...]\n",
    "        X = check_array(X, accept_sparse=['csr', 'csc'])\n",
    "        check_is_fitted(self)\n",
    "        return safe_sparse_dot(X, self.components_.T)\n",
    "```                                          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I use 1,000 components, which means a 100x reduction from 100k to 1k features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd_model = TruncatedSVD(n_components=1000,\n",
    "                         algorithm='arpack', \n",
    "                         n_iter=100, \n",
    "                         random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed: 8 min 27 sec\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "svd_model.fit(X_train_transformed)\n",
    "\n",
    "mins, secs = divmod(time.time() - start_time, 60)\n",
    "print(f'Elapsed: {mins:0.0f} min {secs:0.0f} sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50001"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd_model.n_features_in_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(svd_model.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50001"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(svd_model.components_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((119747, 50001), (50001, 1000))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at dims for matrix multiplication\n",
    "X_train_transformed.shape, svd_model.components_.T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(119747, 1000)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils.extmath import safe_sparse_dot\n",
    "\n",
    "# transform method in sklearn's docs (see above)\n",
    "svd_model_transf = safe_sparse_dot(X_train_transformed, svd_model.components_.T)\n",
    "\n",
    "# fitting and transforming as above can also be done together\n",
    "# svd_model_transf = svd_model.fit_transform(X_train_transformed)\n",
    "\n",
    "svd_model_transf.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're not done here since the resulting `svd_model_transf` is a numpy array not a sparse matrix - notice the size difference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56, 957976112)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.getsizeof(X_train_transformed), sys.getsizeof(svd_model_transf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "svd_model_csr = csr_matrix(svd_model_transf, shape=(svd_model_transf.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.getsizeof(svd_model_csr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:   57.3s remaining:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7752 (+/- 0.0011)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "log_clf = LogisticRegression(solver=\"liblinear\", random_state=42)\n",
    "score = cross_val_score(log_clf, svd_model_csr, y_array, cv=5, verbose=1, scoring='accuracy', n_jobs=-1)\n",
    "print(f'accuracy: {score.mean():0.4f} (+/- {np.std(score):0.4f})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    3.3s remaining:    5.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    5.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8007 (+/- 0.0017)\n"
     ]
    }
   ],
   "source": [
    "# compare to original X_train_transformed\n",
    "log_clf = LogisticRegression(solver=\"liblinear\", random_state=42)\n",
    "score = cross_val_score(log_clf, X_train_transformed, y_array, cv=5, verbose=1, scoring='accuracy', n_jobs=-1)\n",
    "print(f'accuracy: {score.mean():0.4f} (+/- {np.std(score):0.4f})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting singular values\n",
    "\n",
    "The idea is to help see whether the full 1000 components are needed or we can get away with using a smaller subset - the results below show that despite a slightly faster training time (compared to the full 1000 components not the original data), the hit in accuracy isn't worth dumping those components that have \"low energy\" or seem to explain less of the variance in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAYIklEQVR4nO3de3BcZ33G8e9vb1qtLpZly7JiO1ZC45DEDUkwEC4DgYQhhEsynWYm01JMSZte+ANaBiZApwwzTKGUMi3TwjTlZiCFZoASjwtDMyaBACHBDiSxcYJjJ3Jsy5Zsy7pLe3v7xzl7sdaOZFnS2Xf1fGY055x3z0q/dy0/59W75+wx5xwiIuKfWNQFiIjI/CjARUQ8pQAXEfGUAlxExFMKcBERTyWW8oetXr3a9fb2LuWPFBHx3u7du08457pmti9pgPf29rJr166l/JEiIt4zs76ztWsKRUTEUwpwERFPKcBFRDylABcR8ZQCXETEUwpwERFPKcBFRDzlRYDv3HecLzz0bNRliIjUFS8C/KFnBvnPnx6MugwRkbriRYCbRV2BiEj98SLAAXTfIBGRM3kR4Abozm8iImfyI8A1hyIiUsOLAAfQzZdFRM7kT4BHXYCISJ3xIsDNUIKLiMzgR4CjOXARkZm8CHDQAFxEZCYvAtxMb2KKiMzkR4BHXYCISB3yIsBBUygiIjN5EeDBFErUVYiI1BdPAtxwGoOLiJzBjwCPugARkTrkRYCDplBERGbyI8BNb2KKiMzkRYDrSkwRkVpeBDigIbiIyAxeBLgZOgtFRGQGPwIcvYkpIjKTHwGuKXARkRpeBDhoClxEZCYvAtwwfRqhiMgMcw5wM4ub2a/NbEe43WlmD5jZ/nC5crGK1BSKiEit8xmBvx/YV7V9N7DTOXcZsDPcXjQaf4uInGlOAW5m64G3AV+qar4V2BaubwNuW9jSqn4+OgtFRGSmuY7A/wX4MFCsaut2zvUDhMs1Z3uimd1lZrvMbNfg4OD8qtQciohIjVkD3MzeDgw453bP5wc45+5xzm1xzm3p6uqaz7fQhfQiImeRmMM+rwXeaWa3AGmg3cy+CRw3sx7nXL+Z9QADi1koBPfFNI3GRUSAOYzAnXMfcc6td871AncAP3bOvQvYDmwNd9sK3L9YRZYyW/PgIiIVF3Ie+KeBN5vZfuDN4fai0KcRiojUmssUSplz7iHgoXD9JHDjwpf0Ij9/KX+YiEid8+NKzPIUiiJcRKTEjwAPl4pvEZEKPwJcU+AiIjW8CPASzaCIiFR4EeClc791Vx4RkQovAlxERGp5FeCaQhERqfAiwPUmpohILT8CPDyRUCNwEZEKPwJcI3ARkRpeBHiJzkIREanwIsDLV2Iqv0VEyvwIcE2hiIjU8CLASzQAFxGp8CLAK2ehKMJFREr8CPDSx8lGW4aISF3xIsBFRKSWVwGuGRQRkQovAtw0hyIiUsOPAI+6ABGROuRFgJfoSkwRkQovArxyU+No6xARqSd+BHi4VH6LiFT4EeC6ll5EpIYXAV6iKzFFRCq8CHCdRSgiUsuPAI+6ABGROuRFgJdoBkVEpMKPAA/nUHQeuIhIhRcBXp5CUX6LiJT5EeCaBBcRqeFFgJdoAC4iUuFFgFfuyBNxISIidcSPANcUiohIDS8CvERnoYiIVHgR4OUPs1J+i4iU+RHgupReRKSGHwGui+lFRGrMGuBmljazx8zsCTPba2afCNs7zewBM9sfLlcudrH6NEIRkYq5jMCngTc5514GXAPcbGbXA3cDO51zlwE7w+3FoTvyiIjUmDXAXWAs3EyGXw64FdgWtm8DbluUCtGnEYqInM2c5sDNLG5mvwEGgAecc48C3c65foBwuWbxyhQRkZnmFODOuYJz7hpgPfBKM9s81x9gZneZ2S4z2zU4ODivIku3VNMUiohIxXmdheKcOw08BNwMHDezHoBwOXCO59zjnNvinNvS1dU1ryIrNzVWgouIlMzlLJQuM+sI15uBm4Cnge3A1nC3rcD9i1WkLqUXEamVmMM+PcA2M4sTBP59zrkdZvYIcJ+Z3QkcAm5fxDoBTaGIiFSbNcCdc08C156l/SRw42IUNZOuxBQRqaUrMUVEPOVFgJfoSkwRkQovAlxTKCIitbwI8BINwEVEKrwIcNN5hCIiNbwI8AoNwUVESrwIcN2RR0Sklh8BrhkUEZEaXgR4iQbgIiIVXgR46UIeTaGIiFT4EeDl88CV4CIiJX4EeNQFiIjUIS8CvERTKCIiFV4EuOmmxiIiNbwIcE2iiIjU8iTAA3oTU0SkwosA1xSKiEgtPwI86gJEROqQHwGua+lFRGp4EeAlmkIREanwIsDLn0aoNzFFRMr8CHDNoIiI1PAiwEs0hSIiUuFFgOumxiIitfwI8PLHySrCRURKvAhwnQguIlLLjwAPafwtIlLhRYBXbmqsCBcRKfEiwDOpBABTuWLElYiI1A8vAry1KQjw0alcxJWIiNQPLwK8LV0K8HzElYiI1A8vArw0Ah+bVoCLiJT4EeDhCHxMI3ARkTIvAjwZj5GKxxjPFqIuRUSkbngR4ACJuJEv6CwUEZESbwI8HjPyRZ0HLiJS4k2AJ+Mx8kWNwEVESrwJ8HjMKGgELiJS5k2AJ2NGrqAAFxEpmTXAzWyDmT1oZvvMbK+ZvT9s7zSzB8xsf7hcuZiFJuIxjcBFRKrMZQSeBz7onLsCuB54n5ldCdwN7HTOXQbsDLcXTSJm5HQWiohI2awB7pzrd849Hq6PAvuAdcCtwLZwt23AbYtVJASnEWoELiJScV5z4GbWC1wLPAp0O+f6IQh5YM05nnOXme0ys12Dg4PzLjQei2kOXESkypwD3Mxage8CH3DOjcz1ec65e5xzW5xzW7q6uuZTIwDJuOk0QhGRKnMKcDNLEoT3vc6574XNx82sJ3y8BxhYnBIDOo1QRORMczkLxYAvA/ucc5+remg7sDVc3wrcv/DlVSRjMb2JKSJSJTGHfV4L/AnwlJn9Jmz7KPBp4D4zuxM4BNy+OCUGgkvpFeAiIiWzBrhz7mec+77wNy5sOeeWiBuTOU2hiIiUeHMlZkJz4CIiZ/AnwOOaAxcRqeZNgKcSMbJ5BbiISIk3Ad6ZSXFqIht1GSIidcOfAG9JcXoip7vyiIiEvAnwVa0pAI3CRURC3gT42vY0AEdPT0VciYhIffAmwF+yphWAAwNjEVciIlIfvAnwizszJGLGgUEFuIgIeBTgyXiMjasyCnARkZA3AQ7Qu6qFvpMTUZchIlIXvArwDZ0ZjgxN4pwuqRcR8SrA169sZnQ6z/BkLupSREQi51mAZwA4PDQZcSUiItHzLMCbAXjhlObBRUS8CvANnRqBi4iUeBXgK5qTtKUTHB7SCFxExKsAB9jU3cbuQ0NRlyEiEjnvAvwtV3Wz58gIh3Q+uIgsc94F+Fs39wDwv0/1R1yJiEi0vAvwDZ0ZXrq2jZ37jkddiohIpLwLcIC3XLWWXX1D7O47FXUpIiKR8TLA//z1l5KKx/jBU8eiLkVEJDJeBnhrU4LXb1rNjiePMp0vRF2OiEgkvAxwgHddv5HjI9N87efPR12KiEgkvA3wGy5fw/WXdvL1R/ooFPXphCKy/Hgb4ABbX93LkdOT/PjpgahLERFZcl4H+Juv7KZnRZqvP/J81KWIiCw5rwM8EY/xx6+6mIf3n2Dv0eGoyxERWVJeBzgEb2a2NSX4qt7MFJFlxvsA78ikuOnKbrY/cZSB0amoyxERWTLeBzjAe197Cdl8kS88eCDqUkRElkxDBPhVF7Xzppeu4Ru/7OPBZ3RGiogsDw0R4LGY8a93XMNL17bxvnsf50d7dYm9iDS+hghwgLZ0knvevYWO5iR/8Y3d/OlXH9OcuIg0tIYJcIB1Hc089KE38tFbXsojB0/y3q/9ihNj01GXJSKyKBoqwAFSiRh3vf4l/PsfXce+/lHe8JkH+dQP9zE8mYu6NBGRBdVwAV5y4xXdfPuu67lu40ru+elB/vCLv2Bf/0jUZYmILJhZA9zMvmJmA2a2p6qt08weMLP94XLl4pY5P6/o7eQbd76Kr7znFRwbmeKWzz/M+7/9a/pOjkddmojIBZvLCPxrwM0z2u4GdjrnLgN2htt1642Xr+FnH34Tf/mGl/Cjvce48Z9/wid3/JbBUc2Pi4i/zLnZP4rVzHqBHc65zeH2M8ANzrl+M+sBHnLOXT7b99myZYvbtWvXhVV8gQZGpviHH+xj+xNHyaQSfOCmy7jjlRfT2pSItC4RkXMxs93OuS017fMM8NPOuY6qx4ecc2edRjGzu4C7AC6++OKX9/X1zasDC+3g4Bgf376Xh/efYEVzkr972xXcvmVD1GWJiNSILMCr1cMIvJpzjscPDfH39+9l79ER3nJVNzdd0c3Nm9fSlk5GXZ6ICHDuAJ/vWSjHw6kTwqWX16+bGS/f2Ml3/+o13Pm6S/jV80N86DtP8upP/Zj/+MkBxqfzUZcoInJO8x2B/xNw0jn3aTO7G+h0zn14tu9TbyPwmYpFxy8PnuSehw/y0DODtDYleMfLLuKvb3gJGzozUZcnIsvUvKdQzOxbwA3AauA48HHg+8B9wMXAIeB259yp2Yqo9wCvtrtviHsf7WPHk/1k80XesKmLz97+MrramqIuTUSWmQuaA18oPgV4yaGTE9z7WB/bfvE87ekkn7xtM2++shszi7o0EVkmFOAXaO/RYT543xM8fWyUTd2t3Ly5hxsu7+LaDR0KcxFZVArwBZArFPnvX73A/b85wu6+IYou+ACtt13dwzuuvojN69oV5iKy4BTgC2x4IsfOp4+z48l+Ht4/SK7g2NDZzFs393Dz5rUamYvIglGAL6LTE1l+tPcYP9xzjJ8/e4JcwbGuo5mrLmrn5RtXsqm7jSt62lm7Ih11qSLiIQX4EhmezLH9iaP8fP8J9vYP88KpyfJjv7emlU3drVy2po1N3W1s6m5l46oWUomG/VBIEVkACvCIDE/k+N3AKA/vP8G+/hH2Hx+l79QEpZc9FY9xzYYOrt3Ywe+vW8Hmi1awcVVG0y8iUnauANcnOC2yFZkkr+jt5BW9neW2qVyBA4Nj7D8+xt6jwzz23Cm+8rPnyBWCVG9LJ7jqovYg0MOvS1a1EIsp1EWkQiPwOpHNF/nd8VH2HBnmqSPD7Dk6wr7+EbL5IgDNyTiXdrWE8+ltbFzVwsZVGdavzOiTFEUanEbgdS6ViJVH23eEbblCkWcHxnjqyDBP94/y7OAYvzhwgv/59ZEzntuRSbJhZYaLOzOs72zmklUtXNrVyqVdLaxqSWk6RqRBKcDrWDIe44qedq7oaT+jfXgiR9+pcfpOTnDk9CQvnJrghaFJ9vWP8MBvj5MtFMv7tqUTbOpu49LVLaxdkWbDygzrVjazrqOZizqa9QaqiMcU4B5akUlydaaDq9d31DxWKDqOnp7k4IlxDg6OcXBwnGeOjfLT/YMMjk5TrJoxixl0tTXR3Z5mTVuaNe1NrGlroqutifUrM6zrSNPVlqY9ndAoXqQOKcAbTDxmbOjMsKEzwxs2dZ3xWL5Q5MjpSY6enuLwUDBqPzY8ybGRaQ4PTfD4oSFOjWdrvmcqEaOrNQj2UsAH6+nyeldbE12tTRrRiywhBfgykojHwjc/W4BVZ90nmy9yajxL38lxjo1MMTg6Xfkam6bv5AS7+s4e9BDMx3e3peldnaGrrYnVrcEIv7u9qTzKX9XSRFxn1IhcMAW4nCGViLF2RXrWq0ZzhSInx7IMjFZCfiBc9g9PcnBwnMeeO8XQRK7mufGY0dGcZEUmyYrmJB3NSToyqWA9kzzjsRXNSdrTSdqbk7SlEzQn45rOEQkpwGVekvG5B/2JsWmODU9xfGSagdEpjo9McXoix+nJHMMTOQbHpnl2cIzTEzlGp178LkiJmNGWTpQDvT0dBPzMtrPt096coLUpQSKuaR5pDApwWVTJeIyeFc30rGie0/75QpGRqTzDkzlOT2QZngxCfWQqXJ5l+7kT4+XtsTncBq8lFactDPS2dJL2dKK8XT3ab0klaGlK0JKKB8umOJmqNh0IJGoKcKkriXiMzpYUnS0poOW8n18oOsbCgH/x8M8xMplndDrHibFseBAI9skX53ZxW3MyTms6GNWXwz0VJxMGfCYVPJZpitPWlKA1PChkUgmaU/HgOcng8ZZUgnQypukhOS8KcGko8ZgF8+eZJBvm8XznHJO5AqNTecan84xPFxjPhuvZQtgWjPSDZYGx6TwT03nGs3lOjmfpOzXB+HSeiXD/OR4PMCMM+GDEn0kFwV4K+OZUvOYAUfmrIFhmUnGak3HSyXiwnoqTTsT1MQwNSgEuUsXMwiBcmP8azjmm80VGp/KMTuUYny4wkc0zmSswmS0wni0wmQ0ODhPhQWIimy/vNz5dYGg8y+GhyfLj49P5Of+VUNKcDMK8uSrYS+uZVKIc+JlUbfg3JWM0JeKkkzHSycoBorRd2Ud/QSw1BbjIIjKzMOziC3pD7Gy+GAR8dfCHo/7JXKF8gChvZ6seq2o/MZZlIjvBZLg9kS0wnS/OXsBZ+wrpqqBPJ+M0JWLlA0F1ezo8KNQ+VjlYNFUdPJoSsUpbovJYKh5b1n9dKMBFPJRKxEglUnRkFv57F4qOqfAgMJ0vMpUrhF9FpnMFpvLBemmf0nrwWJHJbLj/Gc8tcGIsH7aHz8kG66VP4ZyvVDxGKhELg720Xgn40kGgsl7ZJ5Wo7JOKx8oHh1S4T/VjyXC71F7ejsdIJoxUPEY8Zkv6V4gCXETOEI9ZeNbN0sTDzAPGdOlgEQZ9thC0TeeL4VeB6VyxfHAJHi+SLVTas6X98sFjI5P5M9qy+cp+1Z8ddKHMKId6KhEjWV4an/qDq3nlJZ2zf5PzoAAXkUgt9QFjpmLRkS0Uqw4EwQEjW6gN+lxpWSi1ObL5ynalvbot2GcxPvZZAS4iy1osZqRjwdw8nt22VlciiIh4SgEuIuIpBbiIiKcU4CIinlKAi4h4SgEuIuIpBbiIiKcU4CIinjLnLuxzCM7rh5kNAn3zfPpq4MQCluMD9Xl5UJ+Xhwvp80bnXNfMxiUN8AthZrucc1uirmMpqc/Lg/q8PCxGnzWFIiLiKQW4iIinfArwe6IuIALq8/KgPi8PC95nb+bARUTkTD6NwEVEpIoCXETEU14EuJndbGbPmNmzZnZ31PUsBDPbYGYPmtk+M9trZu8P2zvN7AEz2x8uV1Y95yPha/CMmb0luuovjJnFzezXZrYj3G7oPptZh5l9x8yeDv+9X70M+vw34e/1HjP7lpmlG63PZvYVMxswsz1VbefdRzN7uZk9FT72eTufm2o65+r6C4gDB4BLgRTwBHBl1HUtQL96gOvC9Tbgd8CVwGeAu8P2u4F/DNevDPveBFwSvibxqPsxz77/LfBfwI5wu6H7DGwD/ixcTwEdjdxnYB3wHNAcbt8HvKfR+gy8HrgO2FPVdt59BB4DXg0Y8EPgrXOtwYcR+CuBZ51zB51zWeDbwK0R13TBnHP9zrnHw/VRYB/BL/6tBP/hCZe3heu3At92zk07554DniV4bbxiZuuBtwFfqmpu2D6bWTvBf/QvAzjnss650zRwn0MJoNnMEkAGOEqD9dk591Pg1Izm8+qjmfUA7c65R1yQ5l+ves6sfAjwdcALVduHw7aGYWa9wLXAo0C3c64fgpAH1oS7Ncrr8C/Ah4HqW4E3cp8vBQaBr4bTRl8ysxYauM/OuSPAZ4FDQD8w7Jz7Pxq4z1XOt4/rwvWZ7XPiQ4CfbT6oYc59NLNW4LvAB5xzIy+261navHodzOztwIBzbvdcn3KWNq/6TDASvQ74onPuWmCc4E/rc/G+z+G8760EUwUXAS1m9q4Xe8pZ2rzq8xycq48X1HcfAvwwsKFqez3Bn2PeM7MkQXjf65z7Xth8PPyzinA5ELY3wuvwWuCdZvY8wVTYm8zsmzR2nw8Dh51zj4bb3yEI9Ebu803Ac865QedcDvge8Boau88l59vHw+H6zPY58SHAfwVcZmaXmFkKuAPYHnFNFyx8p/nLwD7n3OeqHtoObA3XtwL3V7XfYWZNZnYJcBnBmx/ecM59xDm33jnXS/Dv+GPn3Lto7D4fA14ws8vDphuB39LAfSaYOrnezDLh7/mNBO/xNHKfS86rj+E0y6iZXR++Vu+ues7son4nd47v9t5CcJbGAeBjUdezQH16HcGfSk8Cvwm/bgFWATuB/eGys+o5Hwtfg2c4j3eq6/ELuIHKWSgN3WfgGmBX+G/9fWDlMujzJ4CngT3ANwjOvmioPgPfIpjjzxGMpO+cTx+BLeHrdAD4N8Ir5OfypUvpRUQ85cMUioiInIUCXETEUwpwERFPKcBFRDylABcR8ZQCXETEUwpwERFP/T+kXPdOLIui0QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(svd_model.singular_values_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying out first 300 to compare speeds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:   12.7s remaining:   19.1s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   14.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7533 (+/- 0.0009)\n"
     ]
    }
   ],
   "source": [
    "log_clf = LogisticRegression(solver=\"liblinear\", random_state=42)\n",
    "score = cross_val_score(log_clf, svd_model_csr[:,:300], y_array, cv=5, verbose=1, scoring='accuracy', n_jobs=-1)\n",
    "print(f'accuracy: {score.mean():0.4f} (+/- {np.std(score):0.4f})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: avoid Naive Bayes on SVD since it implies strong independence between variables.\n",
    "\n",
    "Quoting the [Analytics Vidhya Tutorial](https://www.analyticsvidhya.com/blog/2018/10/stepwise-guide-topic-modeling-latent-semantic-analysis/) ~\n",
    "\n",
    "\"*Apart from LSA, there are other advanced and efficient topic modeling techniques such as Latent Dirichlet Allocation (LDA) and lda2Vec. We have a wonderful article on LDA which you can check out [here](https://www.analyticsvidhya.com/blog/2016/08/beginners-guide-to-topic-modeling-in-python/). lda2vec is a much more advanced topic modeling which is based on word2vec word embeddings.*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
