{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Representing Text As Numeric Matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorizing \n",
    "\n",
    "We need to use some technique to represent unstructured text as numeric matrices that can be used for machine learning. Each document in a corpus becomes a numeric vector in a matrix.\n",
    "\n",
    "## Bag Of Words\n",
    "\n",
    "One of the simplest and most common ways to represent text numerically is by creating a Document-Frequency Matrix (DFM), also known as a Bag Of Words (BoW) model. A DFM simply captures the frequency of terms, regardless of order. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    " \n",
    "corpus = ['You love me', \n",
    "          'You do not love me',\n",
    "          'You really really love food']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 1, 0, 0, 1],\n",
       "       [1, 0, 1, 1, 1, 0, 1],\n",
       "       [0, 1, 1, 0, 0, 2, 1]], dtype=int64)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>vocabulary ---&gt;</th>\n",
       "      <th>do</th>\n",
       "      <th>food</th>\n",
       "      <th>love</th>\n",
       "      <th>me</th>\n",
       "      <th>not</th>\n",
       "      <th>really</th>\n",
       "      <th>you</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>doc 1 vector</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc 2 vector</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc 3 vector</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "vocabulary --->  do  food  love  me  not  really  you\n",
       "doc 1 vector      0     0     1   1    0       0    1\n",
       "doc 2 vector      1     0     1   1    1       0    1\n",
       "doc 3 vector      0     1     1   0    0       2    1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "df['vocabulary --->'] = vectorizer.get_feature_names()\n",
    "df['doc 1 vector'] = X.toarray()[0]\n",
    "df['doc 2 vector'] = X.toarray()[1]\n",
    "df['doc 3 vector'] = X.toarray()[2]\n",
    "df.set_index('vocabulary --->', inplace=True)\n",
    "df.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF\n",
    "\n",
    "Perhaps the most famous and useful text vectorization method is Term Frequency - Inverse Document Frequency. There are many IR papers on the subject and it is deep. At a high level, TF-IDF balances the frequency (or importance) of a term in a document with its frequency in the entire corpus, generating a score instead of a simple count for each token in a document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>vocabulary ---&gt;</th>\n",
       "      <th>do</th>\n",
       "      <th>food</th>\n",
       "      <th>love</th>\n",
       "      <th>me</th>\n",
       "      <th>not</th>\n",
       "      <th>really</th>\n",
       "      <th>you</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>doc 1 scores</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.522842</td>\n",
       "      <td>0.673255</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.522842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc 2 scores</th>\n",
       "      <td>0.55249</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.326310</td>\n",
       "      <td>0.420183</td>\n",
       "      <td>0.55249</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.326310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc 3 scores</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.41894</td>\n",
       "      <td>0.247433</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.83788</td>\n",
       "      <td>0.247433</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "vocabulary --->       do     food      love        me      not   really  \\\n",
       "doc 1 scores     0.00000  0.00000  0.522842  0.673255  0.00000  0.00000   \n",
       "doc 2 scores     0.55249  0.00000  0.326310  0.420183  0.55249  0.00000   \n",
       "doc 3 scores     0.00000  0.41894  0.247433  0.000000  0.00000  0.83788   \n",
       "\n",
       "vocabulary --->       you  \n",
       "doc 1 scores     0.522842  \n",
       "doc 2 scores     0.326310  \n",
       "doc 3 scores     0.247433  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(norm='l2', use_idf=True, smooth_idf=True, sublinear_tf=False)\n",
    "vector = vectorizer.fit_transform(corpus)\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['vocabulary --->'] = vectorizer.get_feature_names()\n",
    "df['doc 1 scores'] = vector.toarray()[0]\n",
    "df['doc 2 scores'] = vector.toarray()[1]\n",
    "df['doc 3 scores'] = vector.toarray()[2]\n",
    "df.set_index('vocabulary --->', inplace=True)\n",
    "df.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see how the terms **do not** get a higher score than **love** in the second document, compared to the first document. In the third document, **really** gets the highest score since it appears twice and not in any other document. For the TF-IDF algorithm, **really** shows as more informative since it isn't common amongst all documents and is very common in one document. \n",
    "**Food** gets half the score of **really** since it also only appears in the third document but it appears only once. This gives us a bit of intuition of how TF-IDF works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DETAILS**\n",
    "\n",
    "When the `fit()` method is called, it creates a dictionary that stores each term in the corpus and its assigned feature index. This dictionary is the vectorizer's `.vocabulary_`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'you': 6, 'love': 2, 'me': 3, 'do': 0, 'not': 4, 'really': 5, 'food': 1}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method `get_feature_names()` returns the sorted list of feature names sans indices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['do', 'food', 'love', 'me', 'not', 'really', 'you']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As opposed to `Countvectorizer`, `TfidfVectorizer` doesn't simply list token counts as features in a sparse matrix; rather, it assigns **weights** (or scores) using the following forumla, given terms *t* and documents *d*:\n",
    "<center><br>$\\text{tf-idf(t,d)}=\\text{tf(t,d)} \\times \\text{idf(t)}$\n",
    "\n",
    "This formula balances the importance of a term in a document vs its importance in the entire corpus.\n",
    "\n",
    "**Term Frequency (TF)**\n",
    "\n",
    "The number of times a term appears in a document.\n",
    "\n",
    "If the word is common (like \"the\") it appears with high frequency. Linguistics informs us that very frequent terms are uninformative, especially in larger documents. Ideally, we'd like to decrease the weight assigned to these frequent terms. It is also common practice to filter out extremely common terms. There are lists of common terms, called stop words, which should be inspected during any text analytic project for relevancy to that particular project. \n",
    "\n",
    "One problem with implementing TF alone is that rare words in a document may be uninformative in the context of entire corpus, so we want to balance the high score assigned to them in a document with another weight assigned via their frequency in the entire set of documents.\n",
    "\n",
    "\n",
    "**Inverse Document Frequency (IDF)**\n",
    "\n",
    "In `sklearn`  the IDF term differs from the \"texbook\" definition and is calculated in the following manner (see the [User Guide](https://scikit-learn.org/stable/modules/feature_extraction.html#tfidf-term-weighting) for details):\n",
    "<center><br>$\\text{idf}(t) = \\log{\\frac{1 + n}{1+\\text{df}(t)}} + 1$\n",
    "    \n",
    "where $n$ is the total number of documents in the document set, and $\\text{df}(t)$ is the number of documents in the document set that contain term. The addition of a document and the extra \"plus ones\" avoid division by 0 but also makes it so we do not completely discard extremely common terms. Taking the $\\log$ helps us balance the multiplication since counts alone would weight the IDF term too heavily compared to the TF term.\n",
    "\n",
    "The resulting TF-IDF vectors are then normalized by the Euclidean norm. Perhaps the first departure from default parameters would be to try out `sublinear_tf=True` to replace $\\text{tf}$ with $1 + \\log(\\text{tf})$.\n",
    "    \n",
    "---\n",
    "    \n",
    "As an example, let's \"hand-roll\" the TF-IDF vector for the 3rd document and compare it to the output of the `TfidfVectorizer()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You love me\n",
      "You do not love me\n",
      "You really really love food\n"
     ]
    }
   ],
   "source": [
    "# our corpus\n",
    "docs = [print(doc) for doc in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['do', 'food', 'love', 'me', 'not', 'really', 'you']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# our sorted vocabulary\n",
    "['do', 'food', 'love', 'me', 'not', 'really', 'you']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 1.693147, 1.0, 0.0, 0.0, 3.386294, 1.0]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "n = 3 # num docs\n",
    "doc3_tfs = [0, 1, 1, 0, 0, 2, 1] # doc3 term freqs\n",
    "term_dfs = [1, 1, 3, 2, 1, 1, 3] # term document freqs\n",
    "\n",
    "tfidf_vec = []\n",
    "for ix, tf in enumerate(doc3_tfs):\n",
    "    df = term_dfs[ix]\n",
    "    frac = (n+1) / (df+1)\n",
    "    idf = np.log(frac) + 1\n",
    "    tfidf_vec.append(tf*idf)\n",
    "\n",
    "# raw tf-idfs\n",
    "[round(i, 6) for i in tfidf_vec] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying $v_{norm} = \\frac{v}{||v||_2} = \\frac{v}{\\sqrt{v{_1}^2 +\n",
    "v{_2}^2 + \\dots + v{_n}^2}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_L2norm(vec):\n",
    "    squares = [x**2 for x in vec]\n",
    "    den = np.sqrt(np.sum(squares))\n",
    "    L2norm = [x/den for x in vec]\n",
    "    return L2norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.41894, 0.247433, 0.0, 0.0, 0.83788, 0.247433]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# L2-normalized tf-idfs\n",
    "tfidf_vec_norm = return_L2norm(tfidf_vec)\n",
    "[round(i, 6) for i in tfidf_vec_norm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>vocabulary ---&gt;</th>\n",
       "      <th>do</th>\n",
       "      <th>food</th>\n",
       "      <th>love</th>\n",
       "      <th>me</th>\n",
       "      <th>not</th>\n",
       "      <th>really</th>\n",
       "      <th>you</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>doc 3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.41894</td>\n",
       "      <td>0.247433</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.83788</td>\n",
       "      <td>0.247433</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "vocabulary --->   do     food      love   me  not   really       you\n",
       "doc 3            0.0  0.41894  0.247433  0.0  0.0  0.83788  0.247433"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# comparing to TfidfVectorizer \n",
    "vectorizer = TfidfVectorizer(norm='l2', use_idf=True, smooth_idf=True, sublinear_tf=False) # explicit defaults\n",
    "vector = vectorizer.fit_transform(corpus)\n",
    "df = pd.DataFrame()\n",
    "df['vocabulary --->'] = vectorizer.get_feature_names()\n",
    "df['doc 3'] = vector.toarray()[2]\n",
    "df.set_index('vocabulary --->', inplace=True)\n",
    "df.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-Grams\n",
    "\n",
    "Unigram BoW and TF-IDF models do not take into account the order of terms. N-Gram models capture the order of N-consecutive terms, such as bigrams (2 terms), trigrams (3 terms), and so forth. We can add N-Gram features to our BoW or TF-IDF models to capture term order and increase accuracy.\n",
    "\n",
    "- NB: the gain in accuracy might not be worth the trade-off in performance, since adding N-Gram features will quickly explode our feature space. We could also apply a number of dimension reduction techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Youlove loveme',\n",
       " 'Youdo donot notlove loveme',\n",
       " 'Youreally reallyreally reallylove lovefood']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import ngrams\n",
    "\n",
    "generators = []\n",
    "for doc in corpus:\n",
    "    generators.append(ngrams(doc.split(' '), n=2))\n",
    "\n",
    "bigram_corpus = []\n",
    "for generator in generators:\n",
    "    bigrams = []\n",
    "    for ix, val in enumerate(generator):\n",
    "        bigram = ''.join([val[0], val[1]])\n",
    "        bigrams.append(bigram)\n",
    "    \n",
    "    bigram_corpus.append(' '.join(bigrams))\n",
    "\n",
    "bigram_corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BoW Bigram features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>vocabulary ---&gt;</th>\n",
       "      <th>donot</th>\n",
       "      <th>lovefood</th>\n",
       "      <th>loveme</th>\n",
       "      <th>notlove</th>\n",
       "      <th>reallylove</th>\n",
       "      <th>reallyreally</th>\n",
       "      <th>youdo</th>\n",
       "      <th>youlove</th>\n",
       "      <th>youreally</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>doc 1 vector</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc 2 vector</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc 3 vector</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "vocabulary --->  donot  lovefood  loveme  notlove  reallylove  reallyreally  \\\n",
       "doc 1 vector         0         0       1        0           0             0   \n",
       "doc 2 vector         1         0       1        1           0             0   \n",
       "doc 3 vector         0         1       0        0           1             1   \n",
       "\n",
       "vocabulary --->  youdo  youlove  youreally  \n",
       "doc 1 vector         0        1          0  \n",
       "doc 2 vector         1        0          0  \n",
       "doc 3 vector         0        0          1  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(bigram_corpus)\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['vocabulary --->'] = vectorizer.get_feature_names()\n",
    "df['doc 1 vector'] = X.toarray()[0]\n",
    "df['doc 2 vector'] = X.toarray()[1]\n",
    "df['doc 3 vector'] = X.toarray()[2]\n",
    "df.set_index('vocabulary --->', inplace=True)\n",
    "df.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TF-IDF Bigram features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>vocabulary ---&gt;</th>\n",
       "      <th>donot</th>\n",
       "      <th>lovefood</th>\n",
       "      <th>loveme</th>\n",
       "      <th>notlove</th>\n",
       "      <th>reallylove</th>\n",
       "      <th>reallyreally</th>\n",
       "      <th>youdo</th>\n",
       "      <th>youlove</th>\n",
       "      <th>youreally</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>doc 1 vector</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.605349</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.795961</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc 2 vector</th>\n",
       "      <td>0.528635</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.402040</td>\n",
       "      <td>0.528635</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.528635</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc 3 vector</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "vocabulary --->     donot  lovefood    loveme   notlove  reallylove  \\\n",
       "doc 1 vector     0.000000       0.0  0.605349  0.000000         0.0   \n",
       "doc 2 vector     0.528635       0.0  0.402040  0.528635         0.0   \n",
       "doc 3 vector     0.000000       0.5  0.000000  0.000000         0.5   \n",
       "\n",
       "vocabulary --->  reallyreally     youdo   youlove  youreally  \n",
       "doc 1 vector              0.0  0.000000  0.795961        0.0  \n",
       "doc 2 vector              0.0  0.528635  0.000000        0.0  \n",
       "doc 3 vector              0.5  0.000000  0.000000        0.5  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(bigram_corpus)\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['vocabulary --->'] = vectorizer.get_feature_names()\n",
    "df['doc 1 vector'] = X.toarray()[0]\n",
    "df['doc 2 vector'] = X.toarray()[1]\n",
    "df['doc 3 vector'] = X.toarray()[2]\n",
    "df.set_index('vocabulary --->', inplace=True)\n",
    "df.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how **reallyreally** and **reallylove** are less important in the TF-IDF bigram feature space than **youlove**, **loveme**, and even **donot** and **youdo**, as it should be. As expected, TF-IDF bigrams capture more of the semantic essence of the documents than unigrams where **really** was the most important feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "TODO: Word Embedding\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
