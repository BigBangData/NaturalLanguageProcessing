{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Twitter Sentiment Analysis \n",
    "\n",
    "---\n",
    "\n",
    "### Pre-process cleaned data for machine learning (ML)\n",
    "\n",
    "While cleanup involved simply reformatting a Tweet's text by standardizing it and reducing the feature space (less punctuation, lower casing, tokenizing, lemmatizing), pre-processing for ML will in\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import time\n",
    "\n",
    "import loading_module as lm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = lm.load_clean_data('X_train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1199999, 3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>text</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cattycourtnee78</td>\n",
       "      <td>Yep... Still working night shift. It's proving...</td>\n",
       "      <td>yep still working night shift proving endless job</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Leeleetoo</td>\n",
       "      <td>so tired</td>\n",
       "      <td>so tired</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rohdesign</td>\n",
       "      <td>My favorite part of the Jimmy Fallon show: The...</td>\n",
       "      <td>my favorite part jimmy fallon show root crew t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>irishsamom</td>\n",
       "      <td>@kris38 I don't need any encouragement.  It is...</td>\n",
       "      <td>USERNAME i dont need any encouragement my favo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mister_peterman</td>\n",
       "      <td>Oh man what? No central line today! Goddamnit!...</td>\n",
       "      <td>oh man what no central line today goddamnit i ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          username                                               text  \\\n",
       "0  cattycourtnee78  Yep... Still working night shift. It's proving...   \n",
       "0        Leeleetoo                                          so tired    \n",
       "0        rohdesign  My favorite part of the Jimmy Fallon show: The...   \n",
       "0       irishsamom  @kris38 I don't need any encouragement.  It is...   \n",
       "0  mister_peterman  Oh man what? No central line today! Goddamnit!...   \n",
       "\n",
       "                                          lemmatized  \n",
       "0  yep still working night shift proving endless job  \n",
       "0                                           so tired  \n",
       "0  my favorite part jimmy fallon show root crew t...  \n",
       "0  USERNAME i dont need any encouragement my favo...  \n",
       "0  oh man what no central line today goddamnit i ...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head() # NEED TO FIX INDEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>text</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>BayBay_</td>\n",
       "      <td>@nasty... i mean, @sdwndr &amp;amp; @elrazzle neve...</td>\n",
       "      <td>USERNAME i mean USERNAME USERNAME never invite...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>nabsworth</td>\n",
       "      <td>@AkashaTheKitty but your &amp;quot;today&amp;quot; is ...</td>\n",
       "      <td>USERNAME but your today different mine my toda...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>t_kawai</td>\n",
       "      <td>@antonea Absolutely! I gave ya 5 stars on it t...</td>\n",
       "      <td>USERNAME absolutely i gave ya 5 star too</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>nadiadesiva</td>\n",
       "      <td>gain a lot of weight.. i'm okay</td>\n",
       "      <td>gain lot weight im okay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>Szabo2004</td>\n",
       "      <td>is getting ready to go to my brother's high sc...</td>\n",
       "      <td>getting ready go my brother high school gradua...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          username                                               text  \\\n",
       "49999      BayBay_  @nasty... i mean, @sdwndr &amp; @elrazzle neve...   \n",
       "49999    nabsworth  @AkashaTheKitty but your &quot;today&quot; is ...   \n",
       "49999      t_kawai  @antonea Absolutely! I gave ya 5 stars on it t...   \n",
       "49999  nadiadesiva                   gain a lot of weight.. i'm okay    \n",
       "49999    Szabo2004  is getting ready to go to my brother's high sc...   \n",
       "\n",
       "                                              lemmatized  \n",
       "49999  USERNAME i mean USERNAME USERNAME never invite...  \n",
       "49999  USERNAME but your today different mine my toda...  \n",
       "49999           USERNAME absolutely i gave ya 5 star too  \n",
       "49999                            gain lot weight im okay  \n",
       "49999  getting ready go my brother high school gradua...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Cleaned Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import ML pre-processing modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute NAs created during cleanup\n",
    "\n",
    "We do not want to drop since the fact they ended up as empty strings is possibly informative - for ex. possibly more positive Tweets? (see TODO at the end)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target         0\n",
       "text           0\n",
       "tokenized     55\n",
       "filtered      74\n",
       "stemmed       74\n",
       "lemmatized    74\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfm = df.dropna() # drop for now\n",
    "dfm.index = range(1,len(dfm) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.000046'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'{round((len(df)-len(dfm))/len(df), 6):.6f}' # prop is very low"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deduplicate based on tokenized text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.022"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dupes = dfm[dfm['tokenized'].duplicated(keep='first')]\n",
    "\n",
    "round(len(dupes)/len(dfm), 3) # 2.2 % duplicated after tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>781332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>783871</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          text\n",
       "target        \n",
       "0       781332\n",
       "1       783871"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfm = dfm.drop(dupes.index)\n",
    "\n",
    "# check target distribution\n",
    "dfm[['target','text']].groupby('target').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorize with Bag of Words (BoW) and Term Frequency - Inverse Document Frequency (TF-IDF) methods\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target\n",
    "y = np.array(dfm.iloc[:, 0]).ravel() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1565203"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int64),\n",
       " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int64))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0:10], y[len(y)-10:len(y)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lemmatized column (as array)\n",
    "X_lemm_array = np.array(dfm.iloc[:, 5]).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate vectorizers\n",
    "bow_vectorizer = CountVectorizer() # simple BoW \n",
    "tfidf_vectorizer = TfidfVectorizer(sublinear_tf=True) # log(tf) version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished in 41.98 second(s)\n"
     ]
    }
   ],
   "source": [
    "# create a document-frequency matrix (dfm), aka Bag of Words\n",
    "start = time.perf_counter()\n",
    "X_lemm_bow_dfm = bow_vectorizer.fit_transform(X_lemm_array)\n",
    "end_timer(start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_lemm_bow_dfm[1:10,1:20].toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished in 100.43 second(s)\n"
     ]
    }
   ],
   "source": [
    "start = time.perf_counter()\n",
    "X_lemm_tfidf_dfm = tfidf_vectorizer.fit_transform(X_lemm)\n",
    "end_timer(start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set test data aside"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import scipy.sparse as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirpath = os.path.join(\"..\",\"data\",\"3_processed\",\"sentiment140\")\n",
    "filenames = ['X_text_bow'\n",
    "            ,'X_tokn_bow'\n",
    "            ,'X_filt_bow'\n",
    "            ,'X_stem_bow'\n",
    "            ,'X_lemm_bow'\n",
    "            ,'X_text_tfidf'\n",
    "            ,'X_tokn_tfidf'\n",
    "            ,'X_filt_tfidf'\n",
    "            ,'X_stem_tfidf'\n",
    "            ,'X_lemm_tfidf'\n",
    "            ,'X_text_log_tfidf'\n",
    "            ,'X_tokn_log_tfidf'\n",
    "            ,'X_filt_log_tfidf'\n",
    "            ,'X_stem_log_tfidf'\n",
    "            ,'X_lemm_log_tfidf']\n",
    "\n",
    "filepaths = [os.path.join(dirpath, ''.join([filename, '.npz'])) for filename in filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished in 117.94 second(s)\n"
     ]
    }
   ],
   "source": [
    "start = time.perf_counter()\n",
    "sp.save_npz(filepaths[0], X_text_bow)\n",
    "sp.save_npz(filepaths[1], X_tokn_bow)\n",
    "sp.save_npz(filepaths[2], X_filt_bow)\n",
    "sp.save_npz(filepaths[3], X_stem_bow)\n",
    "sp.save_npz(filepaths[4], X_lemm_bow)\n",
    "sp.save_npz(filepaths[5], X_text_tfidf)\n",
    "sp.save_npz(filepaths[6], X_tokn_tfidf)\n",
    "sp.save_npz(filepaths[7], X_filt_tfidf)\n",
    "sp.save_npz(filepaths[8], X_stem_tfidf)\n",
    "sp.save_npz(filepaths[9], X_lemm_tfidf)\n",
    "sp.save_npz(filepaths[10], X_text_log_tfidf)\n",
    "sp.save_npz(filepaths[11], X_tokn_log_tfidf)\n",
    "sp.save_npz(filepaths[12], X_filt_log_tfidf)\n",
    "sp.save_npz(filepaths[13], X_stem_log_tfidf)\n",
    "sp.save_npz(filepaths[14], X_lemm_log_tfidf)\n",
    "end_timer(start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save y target vector\n",
    "np.save(os.path.join(dirpath, 'y'), y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
