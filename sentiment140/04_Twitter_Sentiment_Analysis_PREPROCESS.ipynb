{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Twitter Sentiment Analysis \n",
    "\n",
    "### Part 2: Pre-process cleaned data for machine learning (ML)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished in 11.39 second(s)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import load_data as ld\n",
    "\n",
    "start = time.perf_counter()\n",
    "\n",
    "df = ld.run_processes()\n",
    "\n",
    "def end_timer(start):\n",
    "    end = time.perf_counter()\n",
    "    print(f'Finished in {round(end-start, 2)} second(s)')\n",
    "\n",
    "end_timer(start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>filtered</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>is upset that he cant update his facebook by t...</td>\n",
       "      <td>upset cant update his facebook texting might c...</td>\n",
       "      <td>upset cant updat hi facebook text might cri re...</td>\n",
       "      <td>upset cant update his facebook texting might c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "      <td>kenichan i dived many times for the ball manag...</td>\n",
       "      <td>kenichan i dived many times ball managed save ...</td>\n",
       "      <td>kenichan i dive mani time ball manag save 50 r...</td>\n",
       "      <td>kenichan i dived many time ball managed save 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>my whole body feels itchy like fire</td>\n",
       "      <td>my whole bodi feel itchi like fire</td>\n",
       "      <td>my whole body feel itchy like fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "      <td>nationwideclass no its not behaving at all im ...</td>\n",
       "      <td>nationwideclass no not behaving all im mad why...</td>\n",
       "      <td>nationwideclass no not behav all im mad whi am...</td>\n",
       "      <td>nationwideclass no not behaving all im mad why...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kwesidei not the whole crew</td>\n",
       "      <td>kwesidei not the whole crew</td>\n",
       "      <td>kwesidei not whole crew</td>\n",
       "      <td>kwesidei not whole crew</td>\n",
       "      <td>kwesidei not whole crew</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target                                               text  \\\n",
       "0       0  is upset that he can't update his Facebook by ...   \n",
       "1       0  @Kenichan I dived many times for the ball. Man...   \n",
       "2       0    my whole body feels itchy and like its on fire    \n",
       "3       0  @nationwideclass no, it's not behaving at all....   \n",
       "4       0                      @Kwesidei not the whole crew    \n",
       "\n",
       "                                           tokenized  \\\n",
       "0  is upset that he cant update his facebook by t...   \n",
       "1  kenichan i dived many times for the ball manag...   \n",
       "2     my whole body feels itchy and like its on fire   \n",
       "3  nationwideclass no its not behaving at all im ...   \n",
       "4                        kwesidei not the whole crew   \n",
       "\n",
       "                                            filtered  \\\n",
       "0  upset cant update his facebook texting might c...   \n",
       "1  kenichan i dived many times ball managed save ...   \n",
       "2                my whole body feels itchy like fire   \n",
       "3  nationwideclass no not behaving all im mad why...   \n",
       "4                            kwesidei not whole crew   \n",
       "\n",
       "                                             stemmed  \\\n",
       "0  upset cant updat hi facebook text might cri re...   \n",
       "1  kenichan i dive mani time ball manag save 50 r...   \n",
       "2                 my whole bodi feel itchi like fire   \n",
       "3  nationwideclass no not behav all im mad whi am...   \n",
       "4                            kwesidei not whole crew   \n",
       "\n",
       "                                          lemmatized  \n",
       "0  upset cant update his facebook texting might c...  \n",
       "1  kenichan i dived many time ball managed save 5...  \n",
       "2                 my whole body feel itchy like fire  \n",
       "3  nationwideclass no not behaving all im mad why...  \n",
       "4                            kwesidei not whole crew  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import ML pre-processing modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute NAs created during cleanup\n",
    "\n",
    "We do not want to drop since the fact they ended up as empty strings is possibly informative - for ex. possibly more positive Tweets? (see TODO at the end)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target         0\n",
       "text           0\n",
       "tokenized     55\n",
       "filtered      74\n",
       "stemmed       74\n",
       "lemmatized    74\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfm = df.dropna() # drop for now\n",
    "dfm.index = range(1,len(dfm) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.000046'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'{round((len(df)-len(dfm))/len(df), 6):.6f}' # prop is very low"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deduplicate based on tokenized text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.022"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dupes = dfm[dfm['tokenized'].duplicated(keep='first')]\n",
    "\n",
    "round(len(dupes)/len(dfm), 3) # 2.2 % duplicated after tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>781332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>783871</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          text\n",
       "target        \n",
       "0       781332\n",
       "1       783871"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfm = dfm.drop(dupes.index)\n",
    "\n",
    "# check target distribution\n",
    "dfm[['target','text']].groupby('target').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorize with Bag of Words (BoW) and Term Frequency - Inverse Document Frequency (TF-IDF) methods\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target\n",
    "y = np.array(dfm.iloc[:, 0]).ravel() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1565203"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int64),\n",
       " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int64))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0:10], y[len(y)-10:len(y)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lemmatized column (as array)\n",
    "X_lemm_array = np.array(dfm.iloc[:, 5]).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate vectorizers\n",
    "bow_vectorizer = CountVectorizer() # simple BoW \n",
    "tfidf_vectorizer = TfidfVectorizer(sublinear_tf=True) # log(tf) version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished in 41.98 second(s)\n"
     ]
    }
   ],
   "source": [
    "# create a document-frequency matrix (dfm), aka Bag of Words\n",
    "start = time.perf_counter()\n",
    "X_lemm_bow_dfm = bow_vectorizer.fit_transform(X_lemm_array)\n",
    "end_timer(start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_lemm_bow_dfm[1:10,1:20].toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished in 100.43 second(s)\n"
     ]
    }
   ],
   "source": [
    "start = time.perf_counter()\n",
    "X_lemm_tfidf_dfm = tfidf_vectorizer.fit_transform(X_lemm)\n",
    "end_timer(start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set test data aside"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import scipy.sparse as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirpath = os.path.join(\"..\",\"data\",\"3_processed\",\"sentiment140\")\n",
    "filenames = ['X_text_bow'\n",
    "            ,'X_tokn_bow'\n",
    "            ,'X_filt_bow'\n",
    "            ,'X_stem_bow'\n",
    "            ,'X_lemm_bow'\n",
    "            ,'X_text_tfidf'\n",
    "            ,'X_tokn_tfidf'\n",
    "            ,'X_filt_tfidf'\n",
    "            ,'X_stem_tfidf'\n",
    "            ,'X_lemm_tfidf'\n",
    "            ,'X_text_log_tfidf'\n",
    "            ,'X_tokn_log_tfidf'\n",
    "            ,'X_filt_log_tfidf'\n",
    "            ,'X_stem_log_tfidf'\n",
    "            ,'X_lemm_log_tfidf']\n",
    "\n",
    "filepaths = [os.path.join(dirpath, ''.join([filename, '.npz'])) for filename in filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished in 117.94 second(s)\n"
     ]
    }
   ],
   "source": [
    "start = time.perf_counter()\n",
    "sp.save_npz(filepaths[0], X_text_bow)\n",
    "sp.save_npz(filepaths[1], X_tokn_bow)\n",
    "sp.save_npz(filepaths[2], X_filt_bow)\n",
    "sp.save_npz(filepaths[3], X_stem_bow)\n",
    "sp.save_npz(filepaths[4], X_lemm_bow)\n",
    "sp.save_npz(filepaths[5], X_text_tfidf)\n",
    "sp.save_npz(filepaths[6], X_tokn_tfidf)\n",
    "sp.save_npz(filepaths[7], X_filt_tfidf)\n",
    "sp.save_npz(filepaths[8], X_stem_tfidf)\n",
    "sp.save_npz(filepaths[9], X_lemm_tfidf)\n",
    "sp.save_npz(filepaths[10], X_text_log_tfidf)\n",
    "sp.save_npz(filepaths[11], X_tokn_log_tfidf)\n",
    "sp.save_npz(filepaths[12], X_filt_log_tfidf)\n",
    "sp.save_npz(filepaths[13], X_stem_log_tfidf)\n",
    "sp.save_npz(filepaths[14], X_lemm_log_tfidf)\n",
    "end_timer(start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save y target vector\n",
    "np.save(os.path.join(dirpath, 'y'), y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
