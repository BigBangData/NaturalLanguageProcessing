{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Twitter Sentiment Analysis \n",
    "\n",
    "---\n",
    "\n",
    "### Pre-process cleaned data for machine learning \n",
    "\n",
    "While cleanup involved simply reformatting a Tweet's text by standardizing it and reducing the feature space (less punctuation, lower casing, tokenizing, lemmatizing), pre-processing for machine learning is more involved, it mainly consists of further data cleanup steps such as imputing NAs, but also some feature engineering and most importantly, creating a `document-frequency matrix (DFM) - INCLUDE LINK TO NOTEBOOK` for our tokens since most machine-learning algorithms do not accept text input.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### Load cleaned data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed Time: 0 minute(s) and 5 second(s)\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "import loading_module as lm\n",
    "\n",
    "start_time = time.time()\n",
    "df = lm.load_clean_data('X_train')\n",
    "mins, secs = divmod(time.time() - start_time, 60)\n",
    "print(f'Elapsed Time: {mins:0.0f} minute(s) and {secs:0.0f} second(s)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1199999, 3)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>text</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>irishsamom</td>\n",
       "      <td>@kris38 I don't need any encouragement.  It is...</td>\n",
       "      <td>USERNAME i dont need any encouragement my favo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wiseleo</td>\n",
       "      <td>@kongchang Thanks. As long as you were enterta...</td>\n",
       "      <td>USERNAME thanks long you entertained thats all...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C_alvino</td>\n",
       "      <td>Broke a pair of sandals I bought at Old Navy. ...</td>\n",
       "      <td>broke pair sandal i bought old navy i guess th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>willysandi</td>\n",
       "      <td>i am so sleepy but there's still lots of assig...</td>\n",
       "      <td>i am so sleepy but there still lot assignment ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pace</td>\n",
       "      <td>Wish I was in Bournemouth today  - how's it lo...</td>\n",
       "      <td>wish i bournemouth today hows looking down the...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     username                                               text  \\\n",
       "0  irishsamom  @kris38 I don't need any encouragement.  It is...   \n",
       "0     wiseleo  @kongchang Thanks. As long as you were enterta...   \n",
       "0    C_alvino  Broke a pair of sandals I bought at Old Navy. ...   \n",
       "0  willysandi  i am so sleepy but there's still lots of assig...   \n",
       "0        Pace  Wish I was in Bournemouth today  - how's it lo...   \n",
       "\n",
       "                                          lemmatized  \n",
       "0  USERNAME i dont need any encouragement my favo...  \n",
       "0  USERNAME thanks long you entertained thats all...  \n",
       "0  broke pair sandal i bought old navy i guess th...  \n",
       "0  i am so sleepy but there still lot assignment ...  \n",
       "0  wish i bournemouth today hows looking down the...  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load original train indices and subset\n",
    "raw_path = os.path.join(\"..\",\"data\",\"1_raw\",\"sentiment140\")  \n",
    "train_ix = np.load(os.path.join(raw_path, \"train_ix.npy\"))\n",
    "df.index = list(train_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>text</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>66270</th>\n",
       "      <td>irishsamom</td>\n",
       "      <td>@kris38 I don't need any encouragement.  It is...</td>\n",
       "      <td>USERNAME i dont need any encouragement my favo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428045</th>\n",
       "      <td>wiseleo</td>\n",
       "      <td>@kongchang Thanks. As long as you were enterta...</td>\n",
       "      <td>USERNAME thanks long you entertained thats all...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1307927</th>\n",
       "      <td>C_alvino</td>\n",
       "      <td>Broke a pair of sandals I bought at Old Navy. ...</td>\n",
       "      <td>broke pair sandal i bought old navy i guess th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1112400</th>\n",
       "      <td>willysandi</td>\n",
       "      <td>i am so sleepy but there's still lots of assig...</td>\n",
       "      <td>i am so sleepy but there still lot assignment ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>840793</th>\n",
       "      <td>Pace</td>\n",
       "      <td>Wish I was in Bournemouth today  - how's it lo...</td>\n",
       "      <td>wish i bournemouth today hows looking down the...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           username                                               text  \\\n",
       "66270    irishsamom  @kris38 I don't need any encouragement.  It is...   \n",
       "428045      wiseleo  @kongchang Thanks. As long as you were enterta...   \n",
       "1307927    C_alvino  Broke a pair of sandals I bought at Old Navy. ...   \n",
       "1112400  willysandi  i am so sleepy but there's still lots of assig...   \n",
       "840793         Pace  Wish I was in Bournemouth today  - how's it lo...   \n",
       "\n",
       "                                                lemmatized  \n",
       "66270    USERNAME i dont need any encouragement my favo...  \n",
       "428045   USERNAME thanks long you entertained thats all...  \n",
       "1307927  broke pair sandal i bought old navy i guess th...  \n",
       "1112400  i am so sleepy but there still lot assignment ...  \n",
       "840793   wish i bournemouth today hows looking down the...  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>text</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>259178</th>\n",
       "      <td>AngusGibson</td>\n",
       "      <td>@annspade I be struggling to sleep, myself, 'c...</td>\n",
       "      <td>USERNAME i struggling sleep myself cept 430am ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1414414</th>\n",
       "      <td>braidead</td>\n",
       "      <td>@yerhuber try to listen to @monkmusic songs i ...</td>\n",
       "      <td>USERNAME try listen USERNAME song i think youl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131932</th>\n",
       "      <td>nabsworth</td>\n",
       "      <td>@AkashaTheKitty but your &amp;quot;today&amp;quot; is ...</td>\n",
       "      <td>USERNAME but your today different mine my toda...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671155</th>\n",
       "      <td>Altrntvgurl</td>\n",
       "      <td>Good morning twitter</td>\n",
       "      <td>good morning twitter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121958</th>\n",
       "      <td>t_kawai</td>\n",
       "      <td>@antonea Absolutely! I gave ya 5 stars on it t...</td>\n",
       "      <td>USERNAME absolutely i gave ya 5 star too</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            username                                               text  \\\n",
       "259178   AngusGibson  @annspade I be struggling to sleep, myself, 'c...   \n",
       "1414414     braidead  @yerhuber try to listen to @monkmusic songs i ...   \n",
       "131932     nabsworth  @AkashaTheKitty but your &quot;today&quot; is ...   \n",
       "671155   Altrntvgurl                              Good morning twitter    \n",
       "121958       t_kawai  @antonea Absolutely! I gave ya 5 stars on it t...   \n",
       "\n",
       "                                                lemmatized  \n",
       "259178   USERNAME i struggling sleep myself cept 430am ...  \n",
       "1414414  USERNAME try listen USERNAME song i think youl...  \n",
       "131932   USERNAME but your today different mine my toda...  \n",
       "671155                                good morning twitter  \n",
       "121958            USERNAME absolutely i gave ya 5 star too  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import ML pre-processing modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute NAs created during cleanup\n",
    "\n",
    "We do not want to drop since the fact they ended up as empty strings is possibly informative - but we do want to impute them with some value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "username       0\n",
       "text           0\n",
       "lemmatized    56\n",
       "dtype: int64"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>text</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>602804</th>\n",
       "      <td>SSNOB</td>\n",
       "      <td>ÃÂÃÂ° ÃÂÃÂ¶! ÃÂ£ tut.by Ã?ÃÂµÃÂÃÂ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1519405</th>\n",
       "      <td>Nathan_Irvine</td>\n",
       "      <td>www.incrediblyhungover.com/me</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299658</th>\n",
       "      <td>cassiebland</td>\n",
       "      <td>thebasementlive.com</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38437</th>\n",
       "      <td>samanthablews</td>\n",
       "      <td>facebook.com/samantha.hatch</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>771099</th>\n",
       "      <td>kate4samh</td>\n",
       "      <td>is sad......www.whatkatedidnext.wordpress.com</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1421447</th>\n",
       "      <td>mgpyone</td>\n",
       "      <td>faceyourmanga.com Ã¡ÂÂÃ¡ÂÂ±Ã¡ÂÂÃ¡ÂÂ¬Ã¡Â...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296741</th>\n",
       "      <td>ChickWithAName</td>\n",
       "      <td>. . . . . and it's on!</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1374484</th>\n",
       "      <td>SkydiveSummer</td>\n",
       "      <td>myspace.com/skydivesummer</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>725197</th>\n",
       "      <td>sangofsorrow</td>\n",
       "      <td>He is...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788998</th>\n",
       "      <td>Galiiit</td>\n",
       "      <td>youtube.com/user/galitfob</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               username                                               text  \\\n",
       "602804            SSNOB  ÃÂÃÂ° ÃÂÃÂ¶! ÃÂ£ tut.by Ã?ÃÂµÃÂÃÂ...   \n",
       "1519405   Nathan_Irvine                     www.incrediblyhungover.com/me    \n",
       "299658      cassiebland                               thebasementlive.com    \n",
       "38437     samanthablews                       facebook.com/samantha.hatch    \n",
       "771099        kate4samh      is sad......www.whatkatedidnext.wordpress.com   \n",
       "1421447         mgpyone  faceyourmanga.com Ã¡ÂÂÃ¡ÂÂ±Ã¡ÂÂÃ¡ÂÂ¬Ã¡Â...   \n",
       "296741   ChickWithAName                            . . . . . and it's on!    \n",
       "1374484   SkydiveSummer                         myspace.com/skydivesummer    \n",
       "725197     sangofsorrow                                       He is...       \n",
       "788998          Galiiit                         youtube.com/user/galitfob    \n",
       "\n",
       "        lemmatized  \n",
       "602804         NaN  \n",
       "1519405        NaN  \n",
       "299658         NaN  \n",
       "38437          NaN  \n",
       "771099         NaN  \n",
       "1421447        NaN  \n",
       "296741         NaN  \n",
       "1374484        NaN  \n",
       "725197         NaN  \n",
       "788998         NaN  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NA_ix = df.loc[df['lemmatized'].isnull(), ].index\n",
    "df.loc[list(NA_ix), ].head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "raw_path = os.path.join(\"..\",\"data\",\"1_raw\",\"sentiment140\")\n",
    "filename = \"y_train.csv\"\n",
    "filepath = os.path.join(raw_path, filename)\n",
    "y_train = pd.read_csv(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        count\n",
       "target       \n",
       "0          29\n",
       "1          27"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.index = list(train_ix)\n",
    "y_train[\"count\"] = 'ct'\n",
    "\n",
    "y_train.loc[list(NA_ix), ].groupby(\"target\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lemmatized'].loc[list(NA_ix), ] = 'EMPTY'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "username      0\n",
       "text          0\n",
       "lemmatized    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>text</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>464093</th>\n",
       "      <td>egiltve</td>\n",
       "      <td>www.quality-rx.com/?fid=3498</td>\n",
       "      <td>EMPTY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1247878</th>\n",
       "      <td>ukactivism</td>\n",
       "      <td>www.twitteractivism.com</td>\n",
       "      <td>EMPTY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766913</th>\n",
       "      <td>willyouatme</td>\n",
       "      <td>www.WillYouAtMe.com?</td>\n",
       "      <td>EMPTY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23386</th>\n",
       "      <td>iloveyouduh98</td>\n",
       "      <td>...............myspace.com/laceylynnwilliams98</td>\n",
       "      <td>EMPTY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446636</th>\n",
       "      <td>radjah</td>\n",
       "      <td>juick.com: ?????????? ?????? - ????? ?????  ht...</td>\n",
       "      <td>EMPTY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              username                                               text  \\\n",
       "464093         egiltve                     www.quality-rx.com/?fid=3498     \n",
       "1247878     ukactivism                           www.twitteractivism.com    \n",
       "766913     willyouatme                              www.WillYouAtMe.com?    \n",
       "23386    iloveyouduh98   ...............myspace.com/laceylynnwilliams98     \n",
       "446636          radjah  juick.com: ?????????? ?????? - ????? ?????  ht...   \n",
       "\n",
       "        lemmatized  \n",
       "464093       EMPTY  \n",
       "1247878      EMPTY  \n",
       "766913       EMPTY  \n",
       "23386        EMPTY  \n",
       "446636       EMPTY  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[list(NA_ix), ].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deduplicate based on lemmatized text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.86% duplicated Tweets\n"
     ]
    }
   ],
   "source": [
    "dupes = df[df['lemmatized'].duplicated(keep='first')]\n",
    "dec = len(dupes)/len(df)\n",
    "print(f'{100*dec:0.2f}% duplicated Tweets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(dupes.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1141626, 3)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape # wait a second though... y_train needed to be paired with!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorize with Bag of Words (BoW) and Term Frequency - Inverse Document Frequency (TF-IDF) methods\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target\n",
    "y = np.array(dfm.iloc[:, 0]).ravel() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1565203"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int64),\n",
       " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int64))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0:10], y[len(y)-10:len(y)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lemmatized column (as array)\n",
    "X_lemm_array = np.array(dfm.iloc[:, 5]).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate vectorizers\n",
    "bow_vectorizer = CountVectorizer() # simple BoW \n",
    "tfidf_vectorizer = TfidfVectorizer(sublinear_tf=True) # log(tf) version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished in 41.98 second(s)\n"
     ]
    }
   ],
   "source": [
    "# create a document-frequency matrix (dfm), aka Bag of Words\n",
    "start = time.perf_counter()\n",
    "X_lemm_bow_dfm = bow_vectorizer.fit_transform(X_lemm_array)\n",
    "end_timer(start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_lemm_bow_dfm[1:10,1:20].toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished in 100.43 second(s)\n"
     ]
    }
   ],
   "source": [
    "start = time.perf_counter()\n",
    "X_lemm_tfidf_dfm = tfidf_vectorizer.fit_transform(X_lemm)\n",
    "end_timer(start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save pre-processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import scipy.sparse as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirpath = os.path.join(\"..\",\"data\",\"3_processed\",\"sentiment140\")\n",
    "filenames = ['X_text_bow'\n",
    "            ,'X_tokn_bow'\n",
    "            ,'X_filt_bow'\n",
    "            ,'X_stem_bow'\n",
    "            ,'X_lemm_bow'\n",
    "            ,'X_text_tfidf'\n",
    "            ,'X_tokn_tfidf'\n",
    "            ,'X_filt_tfidf'\n",
    "            ,'X_stem_tfidf'\n",
    "            ,'X_lemm_tfidf'\n",
    "            ,'X_text_log_tfidf'\n",
    "            ,'X_tokn_log_tfidf'\n",
    "            ,'X_filt_log_tfidf'\n",
    "            ,'X_stem_log_tfidf'\n",
    "            ,'X_lemm_log_tfidf']\n",
    "\n",
    "filepaths = [os.path.join(dirpath, ''.join([filename, '.npz'])) for filename in filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished in 117.94 second(s)\n"
     ]
    }
   ],
   "source": [
    "start = time.perf_counter()\n",
    "sp.save_npz(filepaths[0], X_text_bow)\n",
    "sp.save_npz(filepaths[1], X_tokn_bow)\n",
    "sp.save_npz(filepaths[2], X_filt_bow)\n",
    "sp.save_npz(filepaths[3], X_stem_bow)\n",
    "sp.save_npz(filepaths[4], X_lemm_bow)\n",
    "sp.save_npz(filepaths[5], X_text_tfidf)\n",
    "sp.save_npz(filepaths[6], X_tokn_tfidf)\n",
    "sp.save_npz(filepaths[7], X_filt_tfidf)\n",
    "sp.save_npz(filepaths[8], X_stem_tfidf)\n",
    "sp.save_npz(filepaths[9], X_lemm_tfidf)\n",
    "sp.save_npz(filepaths[10], X_text_log_tfidf)\n",
    "sp.save_npz(filepaths[11], X_tokn_log_tfidf)\n",
    "sp.save_npz(filepaths[12], X_filt_log_tfidf)\n",
    "sp.save_npz(filepaths[13], X_stem_log_tfidf)\n",
    "sp.save_npz(filepaths[14], X_lemm_log_tfidf)\n",
    "end_timer(start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save y target vector == we already have this!\n",
    "np.save(os.path.join(dirpath, 'y'), y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
