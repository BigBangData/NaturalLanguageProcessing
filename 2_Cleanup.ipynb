{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checklist**\n",
    "\n",
    "- check for dupes in ingestion? \n",
    "    - not needed, no dupes, and text dupes should be checked after cleaning\n",
    "- use textBlob as yet another way to perform basic sentiment analysis?\n",
    "    - yes, TODO, but maybe not during cleanup\n",
    "- create an incremental cleanup module?\n",
    "    - overkill, just reprocess everything bc of dupes, \n",
    "      script takes 8 secs for 20k tweets, that's ~6 min for a million if linear\n",
    "- improve script?\n",
    "    - add logs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "\n",
    "import string\n",
    "import datetime\n",
    "import urlextract\n",
    "import pandas as pd\n",
    "\n",
    "from html import unescape\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_todays_data():\n",
    "    filepath = os.path.join(\"data\",\"raw\",\"tweets\")\n",
    "    today_prefix = datetime.datetime.now().strftime(\"%Y%m%d\")\n",
    "    dfm = []\n",
    "    for f in os.listdir(filepath):\n",
    "        if re.match(today_prefix, f):\n",
    "            dfm.append(pd.read_csv(os.path.join(filepath, f)))\n",
    "    df = pd.concat(dfm)\n",
    "    df = df.reset_index(drop=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_todays_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22400, 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "#def load_data():\n",
    "#    filepath = os.path.join(\"data\",\"raw\",\"tweets\") \n",
    "#\n",
    "#    dfm = []\n",
    "#    for f in os.listdir(filepath):\n",
    "#        dfm.append(pd.read_csv(os.path.join(filepath,f)))\n",
    "#        \n",
    "#    df = pd.concat(dfm)\n",
    "#    df = df.reset_index(drop=True)\n",
    "#    \n",
    "#    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test for duplicated IDs\n",
    "ids = df[\"ID\"]\n",
    "df[ids.isin(ids[ids.duplicated()])].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5603, 5)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test for duplicated Text\n",
    "txt = df[\"Text\"]\n",
    "df[txt.isin(txt[txt.duplicated()])].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>johntykishore9</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DeadPoolzNutz</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bot_Otters</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>elitejohnsonn</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fgarrazo</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                ID\n",
       "User              \n",
       "johntykishore9   5\n",
       "DeadPoolzNutz    5\n",
       "Bot_Otters       5\n",
       "elitejohnsonn    4\n",
       "fgarrazo         4"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at users with more than 1 tweet?\n",
    "grouped = df[['User', 'ID']].groupby('User').count().sort_values('ID', ascending=False)\n",
    "\n",
    "grouped[grouped['ID']>1].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding Retweet Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_retweet(col):\n",
    "\n",
    "    for i in range(len(col)):\n",
    "        if re.match(r'^RT', col) is not None:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0      \n",
    "        \n",
    "def map_is_retweet(col):\n",
    "   \n",
    "    bool_map = map(lambda x: is_retweet(x), col)       \n",
    "    return(list(bool_map)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Retweet'] = map_is_retweet(df['Text'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup_tweet(tweet):\n",
    "    \"\"\"Cleans up a tweet with the following steps:\n",
    "        1. make lower case\n",
    "        2. remove URLs\n",
    "        3. unescape HTML entities\n",
    "        4. remove user references (including username) or hashtags, etc.\n",
    "        5. remove punctuation\n",
    "        6. remove emojis\n",
    "        7. discard non-ascii decodable text after utf-8 encoding\n",
    "        8. tokenize\n",
    "        9. filter stop words from tokens\n",
    "        10. stem filtered tokens\n",
    "        \n",
    "    The function returns a 3-tuple with cleaned versions 8 through 10.\n",
    "    \"\"\"\n",
    "    # 1\n",
    "    tweet = tweet.lower()\n",
    "\n",
    "    # 2\n",
    "    # URL_pattern = r'\\w+:\\/{2}[\\d\\w-]+(\\.[\\d\\w-]+)*(?:(?:\\/[^\\s/]*))*'\n",
    "    # tweet = re.sub(URL_pattern, '', tweet, flags=re.MULTILINE)\n",
    "    # better, albeit slower, version\n",
    "    urls = list(set(url_extractor.find_urls(tweet)))\n",
    "    if len(urls) > 0:\n",
    "        for url in urls:\n",
    "            tweet = tweet.replace(url, \"\")\n",
    "    # 3\n",
    "    tweet = unescape(tweet)\n",
    "    \n",
    "    # 4\n",
    "    pattern = r'\\@\\w+|\\#|\\¥|\\â|\\«|\\»|\\Ñ|\\Ð|\\¼|\\½|\\¾|\\!|\\?|\\¿\\\n",
    "                |\\x82|\\x83|\\x84|\\x85|\\x86|\\x87|\\x88|\\x89|\\\n",
    "                |\\x8a|\\x8b|\\x8c|\\x8d|\\x8e|\\°|\\µ|\\´|\\º|\\¹|\\³'\n",
    "    tweet = re.sub(pattern, '', tweet)\n",
    "\n",
    "    # 5\n",
    "    tweet = tweet.translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "    # 6\n",
    "    tweet = re.sub(r'[^\\x00-\\x7F]+', '', tweet).strip()\n",
    "\n",
    "    # 7\n",
    "    def is_ascii(text):\n",
    "        try:\n",
    "            text.encode(encoding='utf-8').decode('ascii')\n",
    "        except UnicodeDecodeError:\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "    \n",
    "    if is_ascii(tweet) == False:\n",
    "        return \" \"\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    # 8 tokenized only (remove retweet prefix)\n",
    "    tweet_tokens = word_tokenize(tweet)\n",
    "    retweet = ['rt']\n",
    "    tweet_tokens = [token for token in tweet_tokens if not token in retweet]\n",
    "    \n",
    "    # 9 tokenized + filtered\n",
    "    # NLTK's set(stopwords.words('english')) removes too many words\n",
    "    # using list of 25 semantically non-selective words (Reuters-RCV1 dataset)\n",
    "    stop_words = ['a','an','and','are','as','at','be','by','for','from',\n",
    "                  'has','he','in','is','it','its','of','on','that','the',\n",
    "                  'to','was','were','will','with'] \n",
    "    filtered_tokens = [token for token in tweet_tokens if not token in stop_words]\n",
    "\n",
    "    # 10 tokenized + filtered + stemmed\n",
    "    ps = PorterStemmer()\n",
    "    filtered_stemmed_tokens = [ps.stem(token) for token in filtered_tokens]\n",
    "        \n",
    "    v8 = \" \".join(tweet_tokens)\n",
    "    v9 = \" \".join(filtered_tokens)\n",
    "    v10 = \" \".join(filtered_stemmed_tokens)  \n",
    "    \n",
    "    return (v8, v9, v10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_extractor = urlextract.URLExtract()\n",
    "tuples = [cleanup_tweet(tweet) for tweet in df.loc[:,'Text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, 'tokenized'], df.loc[:, 'filtered'], df.loc[:, 'stemmed'] = \\\n",
    "[x[0] for x in tuples], [x[1] for x in tuples], [x[2] for x in tuples], "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>User</th>\n",
       "      <th>Text</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Retweet</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>filtered</th>\n",
       "      <th>stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1304836132090400768</td>\n",
       "      <td>2020-09-12 17:35:51</td>\n",
       "      <td>lorenabarbasso</td>\n",
       "      <td>RT @archivekarla: one year of liar mv 🤥✨ https...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>one year of liar mv</td>\n",
       "      <td>one year liar mv</td>\n",
       "      <td>one year liar mv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1304836131117129729</td>\n",
       "      <td>2020-09-12 17:35:50</td>\n",
       "      <td>zakisamo_</td>\n",
       "      <td>I guess I just miss being babied 🥺</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>i guess i just miss being babied</td>\n",
       "      <td>i guess i just miss being babied</td>\n",
       "      <td>i guess i just miss be babi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1304836130857201664</td>\n",
       "      <td>2020-09-12 17:35:50</td>\n",
       "      <td>BroskeyTha</td>\n",
       "      <td>The Godfather has spoken... masambe grootman 😤...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>the godfather has spoken masambe grootman</td>\n",
       "      <td>godfather spoken masambe grootman</td>\n",
       "      <td>godfath spoken masamb grootman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1304836130475569152</td>\n",
       "      <td>2020-09-12 17:35:50</td>\n",
       "      <td>smolbeanseungmo</td>\n",
       "      <td>@4hyuckno @bottbabyjeno becauseee you guys see...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>becauseee you guys seemed busy</td>\n",
       "      <td>becauseee you guys seemed busy</td>\n",
       "      <td>becausee you guy seem busi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1304836130420989958</td>\n",
       "      <td>2020-09-12 17:35:50</td>\n",
       "      <td>Mansoor18214871</td>\n",
       "      <td>RT @Mansoor18214871: A phenomenal dancer.\\nOur...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>a phenomenal dancer our sush we love you miss ...</td>\n",
       "      <td>phenomenal dancer our sush we love you miss yo...</td>\n",
       "      <td>phenomen dancer our sush we love you miss you ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    ID            Timestamp             User  \\\n",
       "0  1304836132090400768  2020-09-12 17:35:51   lorenabarbasso   \n",
       "1  1304836131117129729  2020-09-12 17:35:50        zakisamo_   \n",
       "2  1304836130857201664  2020-09-12 17:35:50       BroskeyTha   \n",
       "3  1304836130475569152  2020-09-12 17:35:50  smolbeanseungmo   \n",
       "4  1304836130420989958  2020-09-12 17:35:50  Mansoor18214871   \n",
       "\n",
       "                                                Text  Polarity  Retweet  \\\n",
       "0  RT @archivekarla: one year of liar mv 🤥✨ https...        -1        1   \n",
       "1                 I guess I just miss being babied 🥺        -1        0   \n",
       "2  The Godfather has spoken... masambe grootman 😤...        -1        0   \n",
       "3  @4hyuckno @bottbabyjeno becauseee you guys see...        -1        0   \n",
       "4  RT @Mansoor18214871: A phenomenal dancer.\\nOur...        -1        1   \n",
       "\n",
       "                                           tokenized  \\\n",
       "0                                one year of liar mv   \n",
       "1                   i guess i just miss being babied   \n",
       "2          the godfather has spoken masambe grootman   \n",
       "3                     becauseee you guys seemed busy   \n",
       "4  a phenomenal dancer our sush we love you miss ...   \n",
       "\n",
       "                                            filtered  \\\n",
       "0                                   one year liar mv   \n",
       "1                   i guess i just miss being babied   \n",
       "2                  godfather spoken masambe grootman   \n",
       "3                     becauseee you guys seemed busy   \n",
       "4  phenomenal dancer our sush we love you miss yo...   \n",
       "\n",
       "                                             stemmed  \n",
       "0                                   one year liar mv  \n",
       "1                        i guess i just miss be babi  \n",
       "2                     godfath spoken masamb grootman  \n",
       "3                         becausee you guy seem busi  \n",
       "4  phenomen dancer our sush we love you miss you ...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>User</th>\n",
       "      <th>Text</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Retweet</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>filtered</th>\n",
       "      <th>stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22395</th>\n",
       "      <td>1305001402981179392</td>\n",
       "      <td>2020-09-13 04:32:34</td>\n",
       "      <td>tinybangtanarmy</td>\n",
       "      <td>RT @taesoothe: BTS with DNA was the first idol...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>bts with dna was the first idol group in histo...</td>\n",
       "      <td>bts dna first idol group history debuted hot10...</td>\n",
       "      <td>bt dna first idol group histori debut hot100 f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22396</th>\n",
       "      <td>1305001402851155968</td>\n",
       "      <td>2020-09-13 04:32:34</td>\n",
       "      <td>JagadeeshNTR14</td>\n",
       "      <td>RT @worldNTRfans: Painting @tarak9999 🥰😘\\n\\nAr...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>painting artist pavan komarambheemntr</td>\n",
       "      <td>painting artist pavan komarambheemntr</td>\n",
       "      <td>paint artist pavan komarambheemntr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22397</th>\n",
       "      <td>1305001402800971776</td>\n",
       "      <td>2020-09-13 04:32:34</td>\n",
       "      <td>figu236016351</td>\n",
       "      <td>RT @LayariaNetwork: Cool 😂😂 https://t.co/Wp9KK...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>cool</td>\n",
       "      <td>cool</td>\n",
       "      <td>cool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22398</th>\n",
       "      <td>1305001402771537921</td>\n",
       "      <td>2020-09-13 04:32:34</td>\n",
       "      <td>HareeshThala</td>\n",
       "      <td>RT @ArJunMohanan13: Smashed 160K Tweets 💥❤️\\n\\...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>smashed 160k tweets moving to 200k 1yrofajithf...</td>\n",
       "      <td>smashed 160k tweets moving 200k 1yrofajithfans...</td>\n",
       "      <td>smash 160k tweet move 200k 1yrofajithfanspride...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22399</th>\n",
       "      <td>1305001402578530309</td>\n",
       "      <td>2020-09-13 04:32:34</td>\n",
       "      <td>KeishaAngeril</td>\n",
       "      <td>@taeddy_bear__ I'm just saying it if it's a Pr...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>im just saying it if its a problem sorry</td>\n",
       "      <td>im just saying if problem sorry</td>\n",
       "      <td>im just say if problem sorri</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        ID            Timestamp             User  \\\n",
       "22395  1305001402981179392  2020-09-13 04:32:34  tinybangtanarmy   \n",
       "22396  1305001402851155968  2020-09-13 04:32:34   JagadeeshNTR14   \n",
       "22397  1305001402800971776  2020-09-13 04:32:34    figu236016351   \n",
       "22398  1305001402771537921  2020-09-13 04:32:34     HareeshThala   \n",
       "22399  1305001402578530309  2020-09-13 04:32:34    KeishaAngeril   \n",
       "\n",
       "                                                    Text  Polarity  Retweet  \\\n",
       "22395  RT @taesoothe: BTS with DNA was the first idol...         1        1   \n",
       "22396  RT @worldNTRfans: Painting @tarak9999 🥰😘\\n\\nAr...         1        1   \n",
       "22397  RT @LayariaNetwork: Cool 😂😂 https://t.co/Wp9KK...         1        1   \n",
       "22398  RT @ArJunMohanan13: Smashed 160K Tweets 💥❤️\\n\\...         1        1   \n",
       "22399  @taeddy_bear__ I'm just saying it if it's a Pr...         1        0   \n",
       "\n",
       "                                               tokenized  \\\n",
       "22395  bts with dna was the first idol group in histo...   \n",
       "22396              painting artist pavan komarambheemntr   \n",
       "22397                                               cool   \n",
       "22398  smashed 160k tweets moving to 200k 1yrofajithf...   \n",
       "22399           im just saying it if its a problem sorry   \n",
       "\n",
       "                                                filtered  \\\n",
       "22395  bts dna first idol group history debuted hot10...   \n",
       "22396              painting artist pavan komarambheemntr   \n",
       "22397                                               cool   \n",
       "22398  smashed 160k tweets moving 200k 1yrofajithfans...   \n",
       "22399                    im just saying if problem sorry   \n",
       "\n",
       "                                                 stemmed  \n",
       "22395  bt dna first idol group histori debut hot100 f...  \n",
       "22396                 paint artist pavan komarambheemntr  \n",
       "22397                                               cool  \n",
       "22398  smash 160k tweet move 200k 1yrofajithfanspride...  \n",
       "22399                       im just say if problem sorri  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dupes = df[df['Text'].duplicated(keep='first')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20004464285714285"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dupes.shape[0]/df.shape[0] # % dupes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dupes[dupes['Retweet']==1].shape[0]/dupes.shape[0] # % of dupes that are retweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create a subset with cols of interest\n",
    "#sub_df = df[['ID','Retweet','Text','Polarity']].copy()\n",
    "#\n",
    "## dedupe (text duplicates)\n",
    "#dupes = sub_df[sub_df['Text'].duplicated(keep='first')]\n",
    "#\n",
    "#final_df = sub_df[~sub_df.ID.isin(list(dupes['ID']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
