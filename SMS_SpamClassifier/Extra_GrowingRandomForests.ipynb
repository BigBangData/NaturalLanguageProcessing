{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Study of Decision Trees and Random Forests\n",
    "\n",
    "End of Chapter 6 exercises 7 and 8 from Aurelien Geron's [Hands-On Machine Learning with Scikit-Learn & Tensorflow.](https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/) My code is mixed with Geron's code from his solution in this [GitHub Jupyter Notebook.](https://github.com/ageron/handson-ml2/blob/master/06_decision_trees.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.9402914 ,  0.12230559],\n",
       "        [ 0.12454026, -0.42477546],\n",
       "        [ 0.26198823,  0.50841438],\n",
       "        ...,\n",
       "        [-0.24177973,  0.20957199],\n",
       "        [ 0.90679645,  0.54958215],\n",
       "        [ 2.08837082, -0.05050728]]),\n",
       " array([1, 0, 0, ..., 1, 0, 1], dtype=int64))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "\n",
    "X, y = make_moons(n_samples=10000, noise=0.4, random_state=42)\n",
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approx. tree depth without restrictions: 13\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# get notion of max depth's theoretical limit\n",
    "print(f'Approx. tree depth without restrictions: {np.ceil(np.log2(len(X_train))):0.0f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 990 candidates, totalling 2970 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  40 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=6)]: Done 2060 tasks      | elapsed:   11.1s\n",
      "[Parallel(n_jobs=6)]: Done 2970 out of 2970 | elapsed:   15.3s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=DecisionTreeClassifier(random_state=42), n_jobs=6,\n",
       "             param_grid={'max_leaf_nodes': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,\n",
       "                                            13, 14, 15, 16, 17, 18, 19, 20, 21,\n",
       "                                            22, 23, 24, 25, 26, 27, 28, 29, 30,\n",
       "                                            31, ...],\n",
       "                         'min_samples_split': [2, 3, 4, 5, 6]},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "params = {'max_leaf_nodes': list(range(2, 200)), \n",
    "          'min_samples_split': [2, 3, 4, 5, 6]}\n",
    "\n",
    "grid_search_cv = GridSearchCV(DecisionTreeClassifier(random_state=42), \n",
    "                              params, n_jobs=6, verbose=1, cv=3)\n",
    "\n",
    "grid_search_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_leaf_nodes': 17, 'min_samples_split': 2}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mean_fit_time',\n",
       " 'mean_score_time',\n",
       " 'mean_test_score',\n",
       " 'param_max_leaf_nodes',\n",
       " 'param_min_samples_split',\n",
       " 'params',\n",
       " 'rank_test_score',\n",
       " 'split0_test_score',\n",
       " 'split1_test_score',\n",
       " 'split2_test_score',\n",
       " 'std_fit_time',\n",
       " 'std_score_time',\n",
       " 'std_test_score']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(grid_search_cv.cv_results_.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A. Geron**: By default, `GridSearchCV` trains the best model found on the whole training set (you can change this by setting `refit=False`), so we don't need to do it again. We can simply evaluate the model's accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8695"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = grid_search_cv.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max mean test accuracy: 0.8555 \n",
      "Params: {'max_leaf_nodes': 17, 'min_samples_split': 2}\n",
      "Max mean test accuracy: 0.8555 \n",
      "Params: {'max_leaf_nodes': 17, 'min_samples_split': 3}\n",
      "Max mean test accuracy: 0.8555 \n",
      "Params: {'max_leaf_nodes': 17, 'min_samples_split': 4}\n",
      "Max mean test accuracy: 0.8555 \n",
      "Params: {'max_leaf_nodes': 17, 'min_samples_split': 5}\n",
      "Max mean test accuracy: 0.8555 \n",
      "Params: {'max_leaf_nodes': 17, 'min_samples_split': 6}\n"
     ]
    }
   ],
   "source": [
    "# all other \"best\" params\n",
    "for i,v in enumerate(grid_search_cv.cv_results_['mean_test_score']):\n",
    "    if v == max(grid_search_cv.cv_results_['mean_test_score']):\n",
    "        print('Max mean test accuracy:', round(v,4), \\\n",
    "              '\\nParams:', grid_search_cv.cv_results_['params'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8695"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# my old code since I didn't know cv_results_ trained the best model\n",
    "dtree = DecisionTreeClassifier(random_state=42, min_samples_split=2, max_leaf_nodes=17)\n",
    "dtree.fit(X_train, y_train)\n",
    "\n",
    "# predict on test set\n",
    "y_preds = dtree.predict(X_test)\n",
    "\n",
    "# print accuracy on test target\n",
    "accuracy_score(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grow a Random Forest\n",
    "\n",
    "With 1000 trees of 100 instances each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "n_trees = 1000\n",
    "n_instances = 100\n",
    "\n",
    "subsets = []\n",
    "\n",
    "rs = ShuffleSplit(n_splits=n_trees, test_size=len(X_train) - n_instances, random_state=42)\n",
    "for train_sub_ix, test_sub_ix in rs.split(X_train):\n",
    "    X_sub_train = X_train[train_sub_ix]\n",
    "    y_sub_train = y_train[train_sub_ix]\n",
    "    subsets.append((X_sub_train, y_sub_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.31532549,  0.49432266],\n",
       "        [ 1.07395888, -0.38300687],\n",
       "        [ 1.2336808 , -0.20272754],\n",
       "        [ 1.45327595, -0.49765049],\n",
       "        [ 0.62940312, -0.45805718],\n",
       "        [ 1.31621613, -0.49634063],\n",
       "        [ 0.66160502, -0.52512066],\n",
       "        [ 1.17772151,  0.21289673],\n",
       "        [ 1.27074026,  0.83761848],\n",
       "        [ 0.24077774, -0.40528032]]),\n",
       " array([1, 1, 0, 1, 1, 1, 1, 1, 1, 1], dtype=int64))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subsets[0][0][:10], subsets[0][1][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geron's solution is to clone 1000 estimators\n",
    "from sklearn.base import clone\n",
    "\n",
    "forest = [clone(grid_search_cv.best_estimator_) for _ in range(1000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DecisionTreeClassifier(max_leaf_nodes=17, random_state=42),\n",
       " DecisionTreeClassifier(max_leaf_nodes=17, random_state=42),\n",
       " DecisionTreeClassifier(max_leaf_nodes=17, random_state=42),\n",
       " DecisionTreeClassifier(max_leaf_nodes=17, random_state=42),\n",
       " DecisionTreeClassifier(max_leaf_nodes=17, random_state=42)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(max_leaf_nodes=17, random_state=42)\n",
      "[[-0.31532549  0.49432266]\n",
      " [ 1.07395888 -0.38300687]\n",
      " [ 1.2336808  -0.20272754]\n",
      " [ 1.45327595 -0.49765049]\n",
      " [ 0.62940312 -0.45805718]]\n",
      "[1 1 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "# understanding the zipped structure\n",
    "for i, (tree, (X, y)) in enumerate(zip(forest, subsets)):\n",
    "    if i == 0:\n",
    "        print(tree), print(X[:5]), print(y[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8054"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_scores = []\n",
    "\n",
    "# train 1000 decision tree classifiers (tree = classifier)\n",
    "for tree, (X_sub_train, y_sub_train) in zip(forest, subsets):\n",
    "    tree.fit(X_sub_train, y_sub_train)\n",
    "    \n",
    "    y_pred = tree.predict(X_test)\n",
    "    accuracy_scores.append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "round(np.mean(accuracy_scores), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my old code: use single classifier (clf = classifier)\n",
    "X_rf, y_rf = [], []\n",
    "for i, v in enumerate(rs.split(X_train, y_train)):\n",
    "    X_rf.append(X_train[v[0]])\n",
    "    y_rf.append(y_train[v[0]])\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state=42, max_leaf_nodes=17)\n",
    "\n",
    "accs = []\n",
    "for ix, tree in enumerate(X_rf):\n",
    "    clf.fit(tree, y_rf[ix])\n",
    "    y_pred = clf.predict(X_test)\n",
    "    accs.append(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8054"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(np.mean(accs), 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Magic:** \n",
    "\n",
    "- for each test set instance, generate the predictions of the 1000 trees \n",
    "- keep only the most frequent prediction (the *mode*)\n",
    "\n",
    "This procedure gives you the majority-vote predictions over the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = np.empty([1000, len(X_test)], dtype=np.uint8) # a 1000 x 2000 matrix of 0s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each classifier (tree), generate predictions, fill in matrix of predictions\n",
    "for tree_ix, tree in enumerate(forest):\n",
    "    Y_pred[tree_ix] = tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, ..., 0, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for example, in the first iteration of the for loop, we get this y_pred vector\n",
    "forest[0].predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now compute most frequent prediction for a given column (vertically)\n",
    "from scipy.stats import mode\n",
    "\n",
    "y_pred_majority_votes, n_votes = mode(Y_pred, axis=0) # mode returns a tuple of vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[951, 912, 963, ..., 919, 994, 602]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the 2nd vector in the tuple is the # of votes\n",
    "# this could be used as probs\n",
    "n_votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0, ..., 0, 0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# results from majority votes\n",
    "y_pred_majority_votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.872"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy of preds on test set\n",
    "accuracy_score(y_test, y_pred_majority_votes.reshape([-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my old code\n",
    "from scipy import stats\n",
    "\n",
    "y_preds = []\n",
    "for ix, tree in enumerate(X_rf):\n",
    "    clf.fit(tree, y_rf[ix])\n",
    "    y_preds.append(clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0, 1, 0, ..., 0, 0, 1], dtype=int64),\n",
       " array([1, 1, 1, ..., 0, 0, 0], dtype=int64),\n",
       " array([1, 1, 0, ..., 0, 0, 1], dtype=int64),\n",
       " array([1, 1, 0, ..., 0, 0, 1], dtype=int64),\n",
       " array([0, 1, 0, ..., 0, 0, 0], dtype=int64)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds[:5] # unfortunate list format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, ..., 0, 0, 1],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 0, ..., 0, 0, 1],\n",
       "       [1, 1, 0, ..., 0, 0, 1],\n",
       "       [0, 1, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds_array = np.vstack(y_preds) # stack vertically\n",
    "y_preds_array[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "majority_vote, n_votes = stats.mode(y_preds_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.872"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reshaped by subscripting instead\n",
    "accuracy_score(y_test, majority_vote[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
