{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation 1\n",
    "\n",
    "---\n",
    "\n",
    "__This Notebook__\n",
    "\n",
    "[Quickly test multiple models](https://towardsdatascience.com/quickly-test-multiple-models-a98477476f0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Revised on: 2021-02-23\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import joblib \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier, \\\n",
    "    RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "import custom.evaluate_models as E\n",
    "\n",
    "# set print options, print revision date\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "pd.options.display.max_colwidth = 999\n",
    "dt_object = datetime.fromtimestamp(time.time())\n",
    "day, T = str(dt_object).split('.')[0].split(' ')\n",
    "print('Revised on: ' + day)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_raw(data):\n",
    "    raw_path = os.path.join(\"data\",\"1_raw\")\n",
    "    filename = ''.join([data, \".csv\"])\n",
    "    out_dfm = pd.read_csv(os.path.join(raw_path, filename))\n",
    "    out_arr = np.array(out_dfm.iloc[:,0].ravel())\n",
    "    return out_arr\n",
    "\n",
    "X_train_raw = load_raw(\"X_train\")\n",
    "X_test_raw = load_raw(\"X_test\")\n",
    "y_train_array = load_raw(\"y_train\")\n",
    "y_test_array = load_raw(\"y_test\") \n",
    "\n",
    "def make_int(y_array):\n",
    "    y = y_array.copy()\n",
    "    y[y=='ham'] = 0\n",
    "    y[y=='spam'] = 1\n",
    "    y = y.astype('int')\n",
    "    return y\n",
    "\n",
    "y_train = make_int(y_train_array)\n",
    "y_test = make_int(y_test_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_X(filename):\n",
    "    proc_dir = os.path.join(\"data\", \"2_processed\")\n",
    "    filename = ''.join([filename, '.npz'])\n",
    "    X = sp.load_npz(os.path.join(proc_dir, filename))\n",
    "    return X\n",
    "\n",
    "X_train_processed = load_X('X_train_processed')\n",
    "X_test_processed = load_X('X_test_processed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate Candidate Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# previously chosen\n",
    "ada_clf =  AdaBoostClassifier(\n",
    "    random_state=42 , n_estimators=10, \n",
    "    learning_rate=0.001)\n",
    "\n",
    "rnd_clf1 = RandomForestClassifier(\n",
    "    random_state=42, n_estimators=100, max_features=150, \n",
    "    max_depth=8, min_samples_split=3, n_jobs=1) \n",
    "\n",
    "rnd_clf2 = RandomForestClassifier(\n",
    "    random_state=42, n_estimators=100, max_features=300, \n",
    "    max_depth=8, min_samples_split=3, n_jobs=1)\n",
    "    \n",
    "gboost_1a = GradientBoostingClassifier(\n",
    "    random_state=42, n_estimators=50, max_features=None, \n",
    "    max_depth=1, min_samples_split=2)\n",
    "\n",
    "gboost_2a = GradientBoostingClassifier(\n",
    "    random_state=42, n_estimators=100, max_features=300, \n",
    "    max_depth=8, min_samples_split=5)\n",
    "\n",
    "gboost_2c = GradientBoostingClassifier(\n",
    "    random_state=42, n_estimators=50, max_features=300, \n",
    "    max_depth=3, min_samples_split=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# new models\n",
    "knn_clf = KNeighborsClassifier()\n",
    "gauss_nb = GaussianNB()\n",
    "multi_nb = MultinomialNB()\n",
    "xgboost = XGBClassifier(eval_metric='logloss',use_label_encoder=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "def run_exps(X_train: pd.DataFrame , y_train: pd.DataFrame, \n",
    "             X_test: pd.DataFrame, y_test: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Lightweight script to test many models and find winners\n",
    "    :param X_train: training split\n",
    "    :param y_train: training target vector\n",
    "    :param X_test: test split\n",
    "    :param y_test: test target vector\n",
    "    :return: DataFrame of predictions\n",
    "    \"\"\"\n",
    "    \n",
    "    models = [\n",
    "         # ('AdaBoost', ada_clf)\n",
    "        #, ('KNN', knn_clf) # recall for spam is bad: meaning... very little spam gets classified?\n",
    "        # , ('GaussianNB', gauss_nb) # needs dense arrays\n",
    "       #  ('MultinomNB', multi_nb) # needs positive data\n",
    "         ('XGboost', xgboost)\n",
    "    ]\n",
    "    \n",
    "    dfs, results, names = [], [], []\n",
    "    scoring = ['accuracy', 'precision_weighted', \n",
    "               'recall_weighted', 'f1_weighted', \n",
    "               'roc_auc']\n",
    "    target_names = ['ham', 'spam']\n",
    "    for name, model in models:\n",
    "        start_ = time.time()\n",
    "        kfold = model_selection.KFold(n_splits=5, \n",
    "                                      shuffle=True, \n",
    "                                      random_state=42)\n",
    "        \n",
    "        cv_results = model_selection.cross_validate(model, \n",
    "                                                    X_train, \n",
    "                                                    y_train, \n",
    "                                                    cv=kfold, \n",
    "                                                    scoring=scoring)\n",
    "        clf = model.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        \n",
    "        print(name)\n",
    "        print(classification_report(y_test, \n",
    "                                    y_pred,\n",
    "                                    digits=3,\n",
    "                                    target_names=target_names))\n",
    "            \n",
    "        # collect results\n",
    "        results.append(cv_results)\n",
    "        names.append(name)\n",
    "        \n",
    "        df = pd.DataFrame(cv_results)\n",
    "        df['model'] = name\n",
    "        dfs.append(df)\n",
    "                \n",
    "    final = pd.concat(dfs, ignore_index=True)\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGboost\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham      0.995     0.993     0.994      1442\n",
      "        spam      0.957     0.970     0.963       230\n",
      "\n",
      "    accuracy                          0.990      1672\n",
      "   macro avg      0.976     0.981     0.979      1672\n",
      "weighted avg      0.990     0.990     0.990      1672\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_splits = run_exps(X_train_processed, y_train, X_test_processed, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_precision_weighted</th>\n",
       "      <th>test_recall_weighted</th>\n",
       "      <th>test_f1_weighted</th>\n",
       "      <th>test_roc_auc</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.411941</td>\n",
       "      <td>0.763245</td>\n",
       "      <td>0.994872</td>\n",
       "      <td>0.994935</td>\n",
       "      <td>0.994872</td>\n",
       "      <td>0.994890</td>\n",
       "      <td>0.993751</td>\n",
       "      <td>XGboost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.054469</td>\n",
       "      <td>0.739355</td>\n",
       "      <td>0.985897</td>\n",
       "      <td>0.985850</td>\n",
       "      <td>0.985897</td>\n",
       "      <td>0.985870</td>\n",
       "      <td>0.998318</td>\n",
       "      <td>XGboost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.761108</td>\n",
       "      <td>0.753396</td>\n",
       "      <td>0.993590</td>\n",
       "      <td>0.993572</td>\n",
       "      <td>0.993590</td>\n",
       "      <td>0.993547</td>\n",
       "      <td>0.999718</td>\n",
       "      <td>XGboost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.340670</td>\n",
       "      <td>0.768135</td>\n",
       "      <td>0.996154</td>\n",
       "      <td>0.996146</td>\n",
       "      <td>0.996154</td>\n",
       "      <td>0.996146</td>\n",
       "      <td>0.999932</td>\n",
       "      <td>XGboost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.275149</td>\n",
       "      <td>0.750562</td>\n",
       "      <td>0.994872</td>\n",
       "      <td>0.994853</td>\n",
       "      <td>0.994872</td>\n",
       "      <td>0.994846</td>\n",
       "      <td>0.999619</td>\n",
       "      <td>XGboost</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
       "0  10.411941    0.763245       0.994872                 0.994935   \n",
       "1  11.054469    0.739355       0.985897                 0.985850   \n",
       "2   6.761108    0.753396       0.993590                 0.993572   \n",
       "3  11.340670    0.768135       0.996154                 0.996146   \n",
       "4  10.275149    0.750562       0.994872                 0.994853   \n",
       "\n",
       "   test_recall_weighted  test_f1_weighted  test_roc_auc    model  \n",
       "0              0.994872          0.994890      0.993751  XGboost  \n",
       "1              0.985897          0.985870      0.998318  XGboost  \n",
       "2              0.993590          0.993547      0.999718  XGboost  \n",
       "3              0.996154          0.996146      0.999932  XGboost  \n",
       "4              0.994872          0.994846      0.999619  XGboost  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_classifier(clf, sets):\n",
    "    X_train, y_train, X_test, y_test = sets\n",
    "    E.fit_clf(clf, X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    E.eval_clf(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "sets = X_train_processed, y_train, X_test_processed, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed: 0m 0s\n",
      "          pred_neg  pred_pos\n",
      "cond_neg      1442         0\n",
      "cond_pos       137        93\n",
      "acc: 0.9181\n",
      "tpr: 0.4043\n",
      "tnr: 1.0000\n"
     ]
    }
   ],
   "source": [
    "eval_classifier(knn_clf, sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed: 0m 15s\n",
      "          pred_neg  pred_pos\n",
      "cond_neg      1432        10\n",
      "cond_pos         7       223\n",
      "acc: 0.9898\n",
      "tpr: 0.9696\n",
      "tnr: 0.9931\n"
     ]
    }
   ],
   "source": [
    "eval_classifier(xgboost, sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstraps = []\n",
    "for model in list(set(final.model.values)):\n",
    "    model_df = final.loc[final.model == model]\n",
    "    bootstrap = model_df.sample(n=30, replace=True)\n",
    "    bootstraps.append(bootstrap)\n",
    "        \n",
    "bootstrap_df = pd.concat(bootstraps, ignore_index=True)\n",
    "results_long = pd.melt(bootstrap_df,id_vars=['model'],var_name='metrics', value_name='values')\n",
    "time_metrics = ['fit_time','score_time'] # fit time metrics\n",
    "\n",
    "## PERFORMANCE METRICS\n",
    "results_long_nofit = results_long.loc[~results_long['metrics'].isin(time_metrics)] # get df without fit times\n",
    "results_long_nofit = results_long_nofit.sort_values(by='values')\n",
    "\n",
    "## TIME METRICS\n",
    "results_long_fit = results_long.loc[results_long['metrics'].isin(time_metrics)] # df with fit times\n",
    "results_long_fit = results_long_fit.sort_values(by='values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "#plt.figure(figsize=(20, 12))\n",
    "#sns.set(font_scale=2.5)\n",
    "#g = sns.boxplot(x=\"model\", y=\"values\", hue=\"metrics\", data=results_long_nofit, palette=\"Set3\")\n",
    "#plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "#plt.title('Comparison of Model by Classification Metric')\n",
    "#plt.savefig('./benchmark_models_performance.png',dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
