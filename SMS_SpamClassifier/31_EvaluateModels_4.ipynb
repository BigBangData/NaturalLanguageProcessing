{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation 4\n",
    "\n",
    "---\n",
    "\n",
    "__This Notebook__\n",
    "\n",
    "Uses a more efficient approach to evaluate classifiers, as demonstrated by Cole Brendel in his article: [Quickly Compare Multiple Models](https://towardsdatascience.com/quickly-test-multiple-models-a98477476f0).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Revised on: 2021-03-06\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import joblib \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datetime import datetime\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, \\\n",
    "    RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import classification_report, \\\n",
    "    confusion_matrix\n",
    "\n",
    "# custom\n",
    "import custom.evaluate_models as E\n",
    "\n",
    "# set options\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "pd.options.display.max_colwidth = 999\n",
    "dt_object = datetime.fromtimestamp(time.time())\n",
    "day, T = str(dt_object).split('.')[0].split(' ')\n",
    "print('Revised on: ' + day)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_raw(data):\n",
    "    raw_path = os.path.join(\"data\",\"1_raw\")\n",
    "    filename = ''.join([data, \".csv\"])\n",
    "    out_dfm = pd.read_csv(os.path.join(raw_path, filename))\n",
    "    out_arr = np.array(out_dfm.iloc[:,0].ravel())\n",
    "    return out_arr\n",
    "\n",
    "X_train_raw = load_raw(\"X_train\")\n",
    "X_test_raw = load_raw(\"X_test\")\n",
    "y_train_array = load_raw(\"y_train\")\n",
    "y_test_array = load_raw(\"y_test\") \n",
    "\n",
    "def make_int(y_array):\n",
    "    y = y_array.copy()\n",
    "    y[y=='ham'] = 0\n",
    "    y[y=='spam'] = 1\n",
    "    y = y.astype('int')\n",
    "    return y\n",
    "\n",
    "y_train = make_int(y_train_array)\n",
    "y_test = make_int(y_test_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_X(filename):\n",
    "    proc_dir = os.path.join(\"data\", \"2_processed\")\n",
    "    filename = ''.join([filename, '.npz'])\n",
    "    X = sp.load_npz(os.path.join(proc_dir, filename))\n",
    "    return X\n",
    "\n",
    "X_train_processed = load_X('X_train_processed')\n",
    "X_test_processed = load_X('X_test_processed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate Candidate Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    (\n",
    "        'KNN', KNeighborsClassifier(\n",
    "        n_neighbors=3 # default (5) had bad spam recall\n",
    "    )),\n",
    "    (\n",
    "        'XGboost', XGBClassifier(\n",
    "        seed=42, eval_metric='error', # try logloss?\n",
    "        use_label_encoder=False\n",
    "    )),\n",
    "    (\n",
    "        'AdaBoost', AdaBoostClassifier(\n",
    "        random_state=42 , n_estimators=10, \n",
    "        learning_rate=0.001\n",
    "    )),\n",
    "    (\n",
    "        'RandomForest1', RandomForestClassifier(\n",
    "        random_state=42, n_estimators=100, max_features=150, \n",
    "        max_depth=8, min_samples_split=3, n_jobs=1\n",
    "    )),           \n",
    "    (\n",
    "        'RandomForest2', RandomForestClassifier(\n",
    "        random_state=42, n_estimators=100, max_features=300, \n",
    "        max_depth=8, min_samples_split=3, n_jobs=1\n",
    "    )),\n",
    "    (\n",
    "        'GBoost1a', GradientBoostingClassifier(\n",
    "        random_state=42, n_estimators=50, max_features=None, \n",
    "        max_depth=1, min_samples_split=2\n",
    "    )),\n",
    "    (\n",
    "        'Gboost2a', GradientBoostingClassifier(\n",
    "        random_state=42, n_estimators=100, max_features=300, \n",
    "        max_depth=8, min_samples_split=5\n",
    "    )),\n",
    "    (\n",
    "        'Gboost2c', GradientBoostingClassifier(\n",
    "        random_state=42, n_estimators=50, max_features=300, \n",
    "        max_depth=3, min_samples_split=5\n",
    "    ))    \n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code below adapted from Cole Brendel in [Quickly Compare Multiple Models](https://towardsdatascience.com/quickly-test-multiple-models-a98477476f0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_exps(models: list(), \n",
    "             X_train: pd.DataFrame , \n",
    "             y_train: pd.DataFrame, \n",
    "             X_test: pd.DataFrame, \n",
    "             y_test: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Lightweight script to test many models and find winners\n",
    "    :param X_train: training split\n",
    "    :param y_train: training target vector\n",
    "    :param X_test: test split\n",
    "    :param y_test: test target vector\n",
    "    :return: DataFrame of predictions\n",
    "    \"\"\"    \n",
    "    \n",
    "    dfs, results, names = [], [], []\n",
    "    \n",
    "    scoring = ['accuracy', 'precision_weighted', \n",
    "               'recall_weighted', 'f1_weighted', \n",
    "               'roc_auc']\n",
    "    \n",
    "    target_names = ['ham', 'spam']\n",
    "    \n",
    "    for name, model in models:\n",
    "        start_ = time.time()\n",
    "        kfold = model_selection.KFold(n_splits=5, \n",
    "                                      shuffle=True, \n",
    "                                      random_state=42)\n",
    "        \n",
    "        cv_results = model_selection.cross_validate(model, \n",
    "                                                    X_train, \n",
    "                                                    y_train, \n",
    "                                                    cv=kfold, \n",
    "                                                    scoring=scoring)\n",
    "        clf = model.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        \n",
    "        print(name)\n",
    "        print(classification_report(y_test, \n",
    "                                    y_pred,\n",
    "                                    digits=3,\n",
    "                                    target_names=target_names))\n",
    "            \n",
    "        # collect results\n",
    "        results.append(cv_results)\n",
    "        names.append(name)\n",
    "        \n",
    "        df = pd.DataFrame(cv_results)\n",
    "        df['model'] = name\n",
    "        dfs.append(df)\n",
    "                \n",
    "    final = pd.concat(dfs, ignore_index=True)\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham      0.929     1.000     0.963      1442\n",
      "        spam      1.000     0.517     0.682       230\n",
      "\n",
      "    accuracy                          0.934      1672\n",
      "   macro avg      0.964     0.759     0.822      1672\n",
      "weighted avg      0.938     0.934     0.924      1672\n",
      "\n",
      "XGboost\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham      0.995     0.993     0.994      1442\n",
      "        spam      0.957     0.970     0.963       230\n",
      "\n",
      "    accuracy                          0.990      1672\n",
      "   macro avg      0.976     0.981     0.979      1672\n",
      "weighted avg      0.990     0.990     0.990      1672\n",
      "\n",
      "AdaBoost\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham      0.994     0.993     0.994      1442\n",
      "        spam      0.957     0.965     0.961       230\n",
      "\n",
      "    accuracy                          0.989      1672\n",
      "   macro avg      0.976     0.979     0.977      1672\n",
      "weighted avg      0.989     0.989     0.989      1672\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_splits = run_exps(models, X_train_processed, y_train, X_test_processed, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funny how XGBoost performed well pretty much out of the box. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_precision_weighted</th>\n",
       "      <th>test_recall_weighted</th>\n",
       "      <th>test_f1_weighted</th>\n",
       "      <th>test_roc_auc</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.047264</td>\n",
       "      <td>13.943518</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.927776</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.911401</td>\n",
       "      <td>0.824853</td>\n",
       "      <td>KNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.041493</td>\n",
       "      <td>13.266284</td>\n",
       "      <td>0.920513</td>\n",
       "      <td>0.927236</td>\n",
       "      <td>0.920513</td>\n",
       "      <td>0.906472</td>\n",
       "      <td>0.797741</td>\n",
       "      <td>KNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.042892</td>\n",
       "      <td>12.187585</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.927200</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.908714</td>\n",
       "      <td>0.810261</td>\n",
       "      <td>KNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.016919</td>\n",
       "      <td>5.203025</td>\n",
       "      <td>0.917949</td>\n",
       "      <td>0.925093</td>\n",
       "      <td>0.917949</td>\n",
       "      <td>0.902767</td>\n",
       "      <td>0.787678</td>\n",
       "      <td>KNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.015626</td>\n",
       "      <td>5.172785</td>\n",
       "      <td>0.944872</td>\n",
       "      <td>0.946737</td>\n",
       "      <td>0.944872</td>\n",
       "      <td>0.937167</td>\n",
       "      <td>0.859672</td>\n",
       "      <td>KNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.580916</td>\n",
       "      <td>0.406632</td>\n",
       "      <td>0.994872</td>\n",
       "      <td>0.994935</td>\n",
       "      <td>0.994872</td>\n",
       "      <td>0.994890</td>\n",
       "      <td>0.993751</td>\n",
       "      <td>XGboost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5.590989</td>\n",
       "      <td>0.405059</td>\n",
       "      <td>0.985897</td>\n",
       "      <td>0.985850</td>\n",
       "      <td>0.985897</td>\n",
       "      <td>0.985870</td>\n",
       "      <td>0.998318</td>\n",
       "      <td>XGboost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.435742</td>\n",
       "      <td>0.397466</td>\n",
       "      <td>0.993590</td>\n",
       "      <td>0.993572</td>\n",
       "      <td>0.993590</td>\n",
       "      <td>0.993547</td>\n",
       "      <td>0.999718</td>\n",
       "      <td>XGboost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6.801255</td>\n",
       "      <td>0.461302</td>\n",
       "      <td>0.996154</td>\n",
       "      <td>0.996146</td>\n",
       "      <td>0.996154</td>\n",
       "      <td>0.996146</td>\n",
       "      <td>0.999932</td>\n",
       "      <td>XGboost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6.839387</td>\n",
       "      <td>0.463065</td>\n",
       "      <td>0.994872</td>\n",
       "      <td>0.994853</td>\n",
       "      <td>0.994872</td>\n",
       "      <td>0.994846</td>\n",
       "      <td>0.999619</td>\n",
       "      <td>XGboost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.647820</td>\n",
       "      <td>0.062489</td>\n",
       "      <td>0.997436</td>\n",
       "      <td>0.997436</td>\n",
       "      <td>0.997436</td>\n",
       "      <td>0.997436</td>\n",
       "      <td>0.994826</td>\n",
       "      <td>AdaBoost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2.606784</td>\n",
       "      <td>0.078102</td>\n",
       "      <td>0.984615</td>\n",
       "      <td>0.984615</td>\n",
       "      <td>0.984615</td>\n",
       "      <td>0.984615</td>\n",
       "      <td>0.968006</td>\n",
       "      <td>AdaBoost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2.594735</td>\n",
       "      <td>0.062485</td>\n",
       "      <td>0.993590</td>\n",
       "      <td>0.993572</td>\n",
       "      <td>0.993590</td>\n",
       "      <td>0.993547</td>\n",
       "      <td>0.979064</td>\n",
       "      <td>AdaBoost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2.599894</td>\n",
       "      <td>0.062488</td>\n",
       "      <td>0.994872</td>\n",
       "      <td>0.994859</td>\n",
       "      <td>0.994872</td>\n",
       "      <td>0.994852</td>\n",
       "      <td>0.985493</td>\n",
       "      <td>AdaBoost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2.593684</td>\n",
       "      <td>0.062493</td>\n",
       "      <td>0.993590</td>\n",
       "      <td>0.993566</td>\n",
       "      <td>0.993590</td>\n",
       "      <td>0.993540</td>\n",
       "      <td>0.976290</td>\n",
       "      <td>AdaBoost</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
       "0   0.047264   13.943518       0.923077                 0.927776   \n",
       "1   0.041493   13.266284       0.920513                 0.927236   \n",
       "2   0.042892   12.187585       0.923077                 0.927200   \n",
       "3   0.016919    5.203025       0.917949                 0.925093   \n",
       "4   0.015626    5.172785       0.944872                 0.946737   \n",
       "5   5.580916    0.406632       0.994872                 0.994935   \n",
       "6   5.590989    0.405059       0.985897                 0.985850   \n",
       "7   3.435742    0.397466       0.993590                 0.993572   \n",
       "8   6.801255    0.461302       0.996154                 0.996146   \n",
       "9   6.839387    0.463065       0.994872                 0.994853   \n",
       "10  2.647820    0.062489       0.997436                 0.997436   \n",
       "11  2.606784    0.078102       0.984615                 0.984615   \n",
       "12  2.594735    0.062485       0.993590                 0.993572   \n",
       "13  2.599894    0.062488       0.994872                 0.994859   \n",
       "14  2.593684    0.062493       0.993590                 0.993566   \n",
       "\n",
       "    test_recall_weighted  test_f1_weighted  test_roc_auc     model  \n",
       "0               0.923077          0.911401      0.824853       KNN  \n",
       "1               0.920513          0.906472      0.797741       KNN  \n",
       "2               0.923077          0.908714      0.810261       KNN  \n",
       "3               0.917949          0.902767      0.787678       KNN  \n",
       "4               0.944872          0.937167      0.859672       KNN  \n",
       "5               0.994872          0.994890      0.993751   XGboost  \n",
       "6               0.985897          0.985870      0.998318   XGboost  \n",
       "7               0.993590          0.993547      0.999718   XGboost  \n",
       "8               0.996154          0.996146      0.999932   XGboost  \n",
       "9               0.994872          0.994846      0.999619   XGboost  \n",
       "10              0.997436          0.997436      0.994826  AdaBoost  \n",
       "11              0.984615          0.984615      0.968006  AdaBoost  \n",
       "12              0.993590          0.993547      0.979064  AdaBoost  \n",
       "13              0.994872          0.994852      0.985493  AdaBoost  \n",
       "14              0.993590          0.993540      0.976290  AdaBoost  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, KNN is lightning fast, and XGBoost is the slowest, but not too much... although that's highly dependent on amount of data and use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bootstraps = []\n",
    "#for model in list(set(final.model.values)):\n",
    "#    model_df = final.loc[final.model == model]\n",
    "#    bootstrap = model_df.sample(n=30, replace=True)\n",
    "#    bootstraps.append(bootstrap)\n",
    "#        \n",
    "#bootstrap_df = pd.concat(bootstraps, ignore_index=True)\n",
    "#results_long = pd.melt(bootstrap_df,id_vars=['model'],var_name='metrics', value_name='values')\n",
    "#time_metrics = ['fit_time','score_time'] # fit time metrics\n",
    "#\n",
    "### PERFORMANCE METRICS\n",
    "#results_long_nofit = results_long.loc[~results_long['metrics'].isin(time_metrics)] # get df without fit times\n",
    "#results_long_nofit = results_long_nofit.sort_values(by='values')\n",
    "#\n",
    "### TIME METRICS\n",
    "#results_long_fit = results_long.loc[results_long['metrics'].isin(time_metrics)] # df with fit times\n",
    "#results_long_fit = results_long_fit.sort_values(by='values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "#plt.figure(figsize=(20, 12))\n",
    "#sns.set(font_scale=2.5)\n",
    "#g = sns.boxplot(x=\"model\", y=\"values\", hue=\"metrics\", data=results_long_nofit, palette=\"Set3\")\n",
    "#plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "#plt.title('Comparison of Model by Classification Metric')\n",
    "#plt.savefig('./benchmark_models_performance.png',dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
