{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation 1\n",
    "\n",
    "---\n",
    "\n",
    "__This Notebook__\n",
    "\n",
    "[Quickly test multiple models](https://towardsdatascience.com/quickly-test-multiple-models-a98477476f0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Revised on: 2021-02-23\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import joblib \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier, \\\n",
    "    RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "import custom.evaluate_models as E\n",
    "\n",
    "# set print options, print revision date\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "pd.options.display.max_colwidth = 999\n",
    "dt_object = datetime.fromtimestamp(time.time())\n",
    "day, T = str(dt_object).split('.')[0].split(' ')\n",
    "print('Revised on: ' + day)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_raw(data):\n",
    "    raw_path = os.path.join(\"data\",\"1_raw\")\n",
    "    filename = ''.join([data, \".csv\"])\n",
    "    out_dfm = pd.read_csv(os.path.join(raw_path, filename))\n",
    "    out_arr = np.array(out_dfm.iloc[:,0].ravel())\n",
    "    return out_arr\n",
    "\n",
    "X_train_raw = load_raw(\"X_train\")\n",
    "X_test_raw = load_raw(\"X_test\")\n",
    "y_train_array = load_raw(\"y_train\")\n",
    "y_test_array = load_raw(\"y_test\") \n",
    "\n",
    "def make_int(y_array):\n",
    "    y = y_array.copy()\n",
    "    y[y=='ham'] = 0\n",
    "    y[y=='spam'] = 1\n",
    "    y = y.astype('int')\n",
    "    return y\n",
    "\n",
    "y_train = make_int(y_train_array)\n",
    "y_test = make_int(y_test_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_X(filename):\n",
    "    proc_dir = os.path.join(\"data\", \"2_processed\")\n",
    "    filename = ''.join([filename, '.npz'])\n",
    "    X = sp.load_npz(os.path.join(proc_dir, filename))\n",
    "    return X\n",
    "\n",
    "X_train_processed = load_X('X_train_processed')\n",
    "X_test_processed = load_X('X_test_processed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate Candidate Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# previously chosen\n",
    "ada_clf =  AdaBoostClassifier(\n",
    "    random_state=42 , n_estimators=10, \n",
    "    learning_rate=0.001)\n",
    "\n",
    "rnd_clf1 = RandomForestClassifier(\n",
    "    random_state=42, n_estimators=100, max_features=150, \n",
    "    max_depth=8, min_samples_split=3, n_jobs=1) \n",
    "\n",
    "rnd_clf2 = RandomForestClassifier(\n",
    "    random_state=42, n_estimators=100, max_features=300, \n",
    "    max_depth=8, min_samples_split=3, n_jobs=1)\n",
    "    \n",
    "gboost_1a = GradientBoostingClassifier(\n",
    "    random_state=42, n_estimators=50, max_features=None, \n",
    "    max_depth=1, min_samples_split=2)\n",
    "\n",
    "gboost_2a = GradientBoostingClassifier(\n",
    "    random_state=42, n_estimators=100, max_features=300, \n",
    "    max_depth=8, min_samples_split=5)\n",
    "\n",
    "gboost_2c = GradientBoostingClassifier(\n",
    "    random_state=42, n_estimators=50, max_features=300, \n",
    "    max_depth=3, min_samples_split=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier, RadiusNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# new models\n",
    "#radn_clf = RadiusNeighborsClassifier()\n",
    "#gauss_nb = GaussianNB()\n",
    "#multi_nb = MultinomialNB()\n",
    "#, ('RadN', radn_clf) \n",
    "# UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels\n",
    "# with no predicted samples. Use `zero_division` parameter to control this behavior\n",
    "#, ('GaussianNB', gauss_nb) # needs dense arrays\n",
    "#, ('MultinomNB', multi_nb) # needs positive data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    ('KNN', KNeighborsClassifier(\n",
    "        n_neighbors=3 # default=5 had terrible spam recall\n",
    "    )),\n",
    "    ('AdaBoost', AdaBoostClassifier(\n",
    "        random_state=42, \n",
    "        n_estimators=10,    \n",
    "        learning_rate=0.001\n",
    "    )),\n",
    "    ('XGboost', XGBClassifier(\n",
    "        seed=42,\n",
    "        eval_metric='error', # try logloss\n",
    "        use_label_encoder=False\n",
    "    ))\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "def run_exps(models: list(), X_train: pd.DataFrame , y_train: pd.DataFrame, \n",
    "             X_test: pd.DataFrame, y_test: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Lightweight script to test many models and find winners\n",
    "    :param X_train: training split\n",
    "    :param y_train: training target vector\n",
    "    :param X_test: test split\n",
    "    :param y_test: test target vector\n",
    "    :return: DataFrame of predictions\n",
    "    \"\"\"    \n",
    "    dfs, results, names = [], [], []\n",
    "    scoring = ['accuracy', 'precision_weighted', \n",
    "               'recall_weighted', 'f1_weighted', 'roc_auc']\n",
    "    target_names = ['ham', 'spam']\n",
    "    \n",
    "    for name, model in models:\n",
    "        start_ = time.time()\n",
    "        kfold = model_selection.KFold(n_splits=5, \n",
    "                                      shuffle=True, \n",
    "                                      random_state=42)\n",
    "        \n",
    "        cv_results = model_selection.cross_validate(model, \n",
    "                                                    X_train, \n",
    "                                                    y_train, \n",
    "                                                    cv=kfold, \n",
    "                                                    scoring=scoring)\n",
    "        clf = model.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        \n",
    "        print(name)\n",
    "        print(classification_report(y_test, \n",
    "                                    y_pred,\n",
    "                                    digits=3,\n",
    "                                    target_names=target_names))\n",
    "            \n",
    "        # collect results\n",
    "        results.append(cv_results)\n",
    "        names.append(name)\n",
    "        \n",
    "        df = pd.DataFrame(cv_results)\n",
    "        df['model'] = name\n",
    "        dfs.append(df)\n",
    "                \n",
    "    final = pd.concat(dfs, ignore_index=True)\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham      0.929     1.000     0.963      1442\n",
      "        spam      1.000     0.517     0.682       230\n",
      "\n",
      "    accuracy                          0.934      1672\n",
      "   macro avg      0.964     0.759     0.822      1672\n",
      "weighted avg      0.938     0.934     0.924      1672\n",
      "\n",
      "AdaBoost\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham      0.994     0.993     0.994      1442\n",
      "        spam      0.957     0.965     0.961       230\n",
      "\n",
      "    accuracy                          0.989      1672\n",
      "   macro avg      0.976     0.979     0.977      1672\n",
      "weighted avg      0.989     0.989     0.989      1672\n",
      "\n",
      "XGboost\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham      0.995     0.993     0.994      1442\n",
      "        spam      0.957     0.970     0.963       230\n",
      "\n",
      "    accuracy                          0.990      1672\n",
      "   macro avg      0.976     0.981     0.979      1672\n",
      "weighted avg      0.990     0.990     0.990      1672\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_splits = run_exps(models, X_train_processed, y_train, X_test_processed, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_precision_weighted</th>\n",
       "      <th>test_recall_weighted</th>\n",
       "      <th>test_f1_weighted</th>\n",
       "      <th>test_roc_auc</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.021942</td>\n",
       "      <td>5.275063</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.927776</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.911401</td>\n",
       "      <td>0.824853</td>\n",
       "      <td>KNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.031277</td>\n",
       "      <td>5.323851</td>\n",
       "      <td>0.920513</td>\n",
       "      <td>0.927236</td>\n",
       "      <td>0.920513</td>\n",
       "      <td>0.906472</td>\n",
       "      <td>0.797741</td>\n",
       "      <td>KNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.014986</td>\n",
       "      <td>5.215429</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.927200</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.908714</td>\n",
       "      <td>0.810261</td>\n",
       "      <td>KNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.015626</td>\n",
       "      <td>5.260679</td>\n",
       "      <td>0.917949</td>\n",
       "      <td>0.925093</td>\n",
       "      <td>0.917949</td>\n",
       "      <td>0.902767</td>\n",
       "      <td>0.787678</td>\n",
       "      <td>KNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.036560</td>\n",
       "      <td>5.221972</td>\n",
       "      <td>0.944872</td>\n",
       "      <td>0.946737</td>\n",
       "      <td>0.944872</td>\n",
       "      <td>0.937167</td>\n",
       "      <td>0.859672</td>\n",
       "      <td>KNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.717947</td>\n",
       "      <td>0.066220</td>\n",
       "      <td>0.997436</td>\n",
       "      <td>0.997436</td>\n",
       "      <td>0.997436</td>\n",
       "      <td>0.997436</td>\n",
       "      <td>0.994826</td>\n",
       "      <td>AdaBoost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.910082</td>\n",
       "      <td>0.066490</td>\n",
       "      <td>0.984615</td>\n",
       "      <td>0.984615</td>\n",
       "      <td>0.984615</td>\n",
       "      <td>0.984615</td>\n",
       "      <td>0.968006</td>\n",
       "      <td>AdaBoost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.698767</td>\n",
       "      <td>0.078107</td>\n",
       "      <td>0.993590</td>\n",
       "      <td>0.993572</td>\n",
       "      <td>0.993590</td>\n",
       "      <td>0.993547</td>\n",
       "      <td>0.979064</td>\n",
       "      <td>AdaBoost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.963183</td>\n",
       "      <td>0.062483</td>\n",
       "      <td>0.994872</td>\n",
       "      <td>0.994859</td>\n",
       "      <td>0.994872</td>\n",
       "      <td>0.994852</td>\n",
       "      <td>0.985493</td>\n",
       "      <td>AdaBoost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.771800</td>\n",
       "      <td>0.068849</td>\n",
       "      <td>0.993590</td>\n",
       "      <td>0.993566</td>\n",
       "      <td>0.993590</td>\n",
       "      <td>0.993540</td>\n",
       "      <td>0.976290</td>\n",
       "      <td>AdaBoost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>6.194208</td>\n",
       "      <td>0.447743</td>\n",
       "      <td>0.994872</td>\n",
       "      <td>0.994935</td>\n",
       "      <td>0.994872</td>\n",
       "      <td>0.994890</td>\n",
       "      <td>0.993751</td>\n",
       "      <td>XGboost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6.599838</td>\n",
       "      <td>0.447527</td>\n",
       "      <td>0.985897</td>\n",
       "      <td>0.985850</td>\n",
       "      <td>0.985897</td>\n",
       "      <td>0.985870</td>\n",
       "      <td>0.998318</td>\n",
       "      <td>XGboost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4.008701</td>\n",
       "      <td>0.424207</td>\n",
       "      <td>0.993590</td>\n",
       "      <td>0.993572</td>\n",
       "      <td>0.993590</td>\n",
       "      <td>0.993547</td>\n",
       "      <td>0.999718</td>\n",
       "      <td>XGboost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>7.245331</td>\n",
       "      <td>0.426849</td>\n",
       "      <td>0.996154</td>\n",
       "      <td>0.996146</td>\n",
       "      <td>0.996154</td>\n",
       "      <td>0.996146</td>\n",
       "      <td>0.999932</td>\n",
       "      <td>XGboost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>7.072383</td>\n",
       "      <td>0.453021</td>\n",
       "      <td>0.994872</td>\n",
       "      <td>0.994853</td>\n",
       "      <td>0.994872</td>\n",
       "      <td>0.994846</td>\n",
       "      <td>0.999619</td>\n",
       "      <td>XGboost</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
       "0   0.021942    5.275063       0.923077                 0.927776   \n",
       "1   0.031277    5.323851       0.920513                 0.927236   \n",
       "2   0.014986    5.215429       0.923077                 0.927200   \n",
       "3   0.015626    5.260679       0.917949                 0.925093   \n",
       "4   0.036560    5.221972       0.944872                 0.946737   \n",
       "5   2.717947    0.066220       0.997436                 0.997436   \n",
       "6   2.910082    0.066490       0.984615                 0.984615   \n",
       "7   2.698767    0.078107       0.993590                 0.993572   \n",
       "8   2.963183    0.062483       0.994872                 0.994859   \n",
       "9   2.771800    0.068849       0.993590                 0.993566   \n",
       "10  6.194208    0.447743       0.994872                 0.994935   \n",
       "11  6.599838    0.447527       0.985897                 0.985850   \n",
       "12  4.008701    0.424207       0.993590                 0.993572   \n",
       "13  7.245331    0.426849       0.996154                 0.996146   \n",
       "14  7.072383    0.453021       0.994872                 0.994853   \n",
       "\n",
       "    test_recall_weighted  test_f1_weighted  test_roc_auc     model  \n",
       "0               0.923077          0.911401      0.824853       KNN  \n",
       "1               0.920513          0.906472      0.797741       KNN  \n",
       "2               0.923077          0.908714      0.810261       KNN  \n",
       "3               0.917949          0.902767      0.787678       KNN  \n",
       "4               0.944872          0.937167      0.859672       KNN  \n",
       "5               0.997436          0.997436      0.994826  AdaBoost  \n",
       "6               0.984615          0.984615      0.968006  AdaBoost  \n",
       "7               0.993590          0.993547      0.979064  AdaBoost  \n",
       "8               0.994872          0.994852      0.985493  AdaBoost  \n",
       "9               0.993590          0.993540      0.976290  AdaBoost  \n",
       "10              0.994872          0.994890      0.993751   XGboost  \n",
       "11              0.985897          0.985870      0.998318   XGboost  \n",
       "12              0.993590          0.993547      0.999718   XGboost  \n",
       "13              0.996154          0.996146      0.999932   XGboost  \n",
       "14              0.994872          0.994846      0.999619   XGboost  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_classifier(clf, sets):\n",
    "    X_train, y_train, X_test, y_test = sets\n",
    "    E.fit_clf(clf, X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    E.eval_clf(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sets = X_train_processed, y_train, X_test_processed, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('KNN', KNeighborsClassifier(n_neighbors=3))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eval_classifier(models[0], sets) # nope..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eval_classifier(ada_clf, sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eval_classifier(xgboost, sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bootstraps = []\n",
    "#for model in list(set(final.model.values)):\n",
    "#    model_df = final.loc[final.model == model]\n",
    "#    bootstrap = model_df.sample(n=30, replace=True)\n",
    "#    bootstraps.append(bootstrap)\n",
    "#        \n",
    "#bootstrap_df = pd.concat(bootstraps, ignore_index=True)\n",
    "#results_long = pd.melt(bootstrap_df,id_vars=['model'],var_name='metrics', value_name='values')\n",
    "#time_metrics = ['fit_time','score_time'] # fit time metrics\n",
    "#\n",
    "### PERFORMANCE METRICS\n",
    "#results_long_nofit = results_long.loc[~results_long['metrics'].isin(time_metrics)] # get df without fit times\n",
    "#results_long_nofit = results_long_nofit.sort_values(by='values')\n",
    "#\n",
    "### TIME METRICS\n",
    "#results_long_fit = results_long.loc[results_long['metrics'].isin(time_metrics)] # df with fit times\n",
    "#results_long_fit = results_long_fit.sort_values(by='values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "#plt.figure(figsize=(20, 12))\n",
    "#sns.set(font_scale=2.5)\n",
    "#g = sns.boxplot(x=\"model\", y=\"values\", hue=\"metrics\", data=results_long_nofit, palette=\"Set3\")\n",
    "#plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "#plt.title('Comparison of Model by Classification Metric')\n",
    "#plt.savefig('./benchmark_models_performance.png',dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
