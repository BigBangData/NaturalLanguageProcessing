{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-process Test Set\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Revised on: 2021-02-17\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "dt_object = datetime.fromtimestamp(time.time())\n",
    "day, T = str(dt_object).split('.')[0].split(' ')\n",
    "print('Revised on: ' + day)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urlextract\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "def load_data(data):\n",
    "    raw_path = os.path.join(\"data\",\"1_raw\")\n",
    "    filename = ''.join([data, \".csv\"])\n",
    "    out_dfm = pd.read_csv(os.path.join(raw_path, filename))\n",
    "    out_arr = np.array(out_dfm.iloc[:,0].ravel())\n",
    "    return out_arr\n",
    "\n",
    "X_train = load_data(\"X_train\") \n",
    "y_train = load_data(\"y_train\") \n",
    "X_test = load_data(\"X_test\") \n",
    "y_test = load_data(\"y_test\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_int(y_array):\n",
    "    y = y_array.copy()\n",
    "    y[y=='ham'] = 0\n",
    "    y[y=='spam'] = 1\n",
    "    y = y.astype('int')\n",
    "    return y\n",
    "\n",
    "y_test_int = make_int(y_test)\n",
    "y_train_int = make_int(y_train)\n",
    "\n",
    "# load contractions map for custom cleanup\n",
    "with open(\"contractions_map.json\") as f:\n",
    "    contractions_map = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BoW and Tfidf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import custom.clean_preprocess as cp\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "pipe = Pipeline([('counter', cp.DocumentToNgramCounterTransformer(n_grams=3)),\n",
    "                 ('bot', cp.WordCounterToVectorTransformer(vocabulary_size=2000)), # train vocab\n",
    "                 ('tfidf', TfidfTransformer(sublinear_tf=True))]) # train IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_counter = pipe['counter'].fit_transform(X_train) \n",
    "X_train_transformer = pipe['bot'].fit(X_train_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NUM', 'i', 'you', 'u', 'me', 'not', 'my', 'your', 'am', 'have', 'call']\n"
     ]
    }
   ],
   "source": [
    "first_11_vocab = [w for (ct, w) in enumerate(X_train_transformer.vocabulary_) if ct < 11]\n",
    "print(first_11_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train bag of trigrams\n",
    "X_train_bot = X_train_transformer.transform(X_train_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test counter\n",
    "X_test_counter = pipe['counter'].fit_transform(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test bag of trigrams using train transformer to keep vocab\n",
    "X_test_bot = X_train_transformer.transform(X_test_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<3900x2001 sparse matrix of type '<class 'numpy.intc'>'\n",
       " \twith 59102 stored elements in Compressed Sparse Row format>,\n",
       " <1672x2001 sparse matrix of type '<class 'numpy.intc'>'\n",
       " \twith 24657 stored elements in Compressed Sparse Row format>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_bot, X_test_bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unknown</th>\n",
       "      <th>NUM</th>\n",
       "      <th>i</th>\n",
       "      <th>you</th>\n",
       "      <th>u</th>\n",
       "      <th>me</th>\n",
       "      <th>not</th>\n",
       "      <th>my</th>\n",
       "      <th>your</th>\n",
       "      <th>am</th>\n",
       "      <th>have</th>\n",
       "      <th>call</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   unknown  NUM  i  you  u  me  not  my  your  am  have  call\n",
       "0       16    0  0    0  0   0    0   0     0   0     0     0\n",
       "1       60    7  0    0  1   1    1   0     0   0     0     1\n",
       "2       24    0  0    1  0   0    0   0     1   0     0     0\n",
       "3       13    0  0    0  0   0    0   0     0   0     0     0\n",
       "4       21    1  0    0  0   0    0   0     0   0     0     0\n",
       "5       23    0  0    0  0   0    0   1     1   0     0     0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train BoT\n",
    "pd.DataFrame(X_train_bot[0:6, 0:12].toarray() \n",
    "            , columns=['unknown'] + first_11_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not heard from U4 a while. Call 4 rude chat private line 01223585334 to cum. Wan 2C pics of me gettin shagged then text PIX to 8552. 2End send STOP 8552 SAM xxx\n"
     ]
    }
   ],
   "source": [
    "print(X_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'NUM': 7, 'not': 1, 'heard': 1, 'u': 1, 'while': 1, 'call': 1, 'rude': 1, 'chat': 1, 'private': 1, 'line': 1, 'cum': 1, 'wan': 1, 'c': 1, 'pic': 1, 'me': 1, 'gettin': 1, 'shagged': 1, 'then': 1, 'text': 1, 'pix': 1, 'end': 1, 'send': 1, 'stop': 1, 'sam': 1, 'xxx': 1, 'not_heard': 1, 'heard_from': 1, 'from_u': 1, 'u_NUM': 1, 'NUM_a': 1, 'a_while': 1, 'while_call': 1, 'call_NUM': 1, 'NUM_rude': 1, 'rude_chat': 1, 'chat_private': 1, 'private_line': 1, 'line_NUM': 1, 'NUM_to': 1, 'to_cum': 1, 'cum_wan': 1, 'wan_NUM': 1, 'NUM_c': 1, 'c_pics': 1, 'pics_of': 1, 'of_me': 1, 'me_gettin': 1, 'gettin_shagged': 1, 'shagged_then': 1, 'then_text': 1, 'text_pix': 1, 'pix_to': 1, 'to_NUM': 1, 'NUM_NUM': 1, 'NUM_end': 1, 'end_send': 1, 'send_stop': 1, 'stop_NUM': 1, 'NUM_sam': 1, 'sam_xxx': 1, 'not_heard_from': 1, 'heard_from_u': 1, 'from_u_NUM': 1, 'u_NUM_a': 1, 'NUM_a_while': 1, 'a_while_call': 1, 'while_call_NUM': 1, 'call_NUM_rude': 1, 'NUM_rude_chat': 1, 'rude_chat_private': 1, 'chat_private_line': 1, 'private_line_NUM': 1, 'line_NUM_to': 1, 'NUM_to_cum': 1, 'to_cum_wan': 1, 'cum_wan_NUM': 1, 'wan_NUM_c': 1, 'NUM_c_pics': 1, 'c_pics_of': 1, 'pics_of_me': 1, 'of_me_gettin': 1, 'me_gettin_shagged': 1, 'gettin_shagged_then': 1, 'shagged_then_text': 1, 'then_text_pix': 1, 'text_pix_to': 1, 'pix_to_NUM': 1, 'to_NUM_NUM': 1, 'NUM_NUM_end': 1, 'NUM_end_send': 1, 'end_send_stop': 1, 'send_stop_NUM': 1, 'stop_NUM_sam': 1, 'NUM_sam_xxx': 1})\n"
     ]
    }
   ],
   "source": [
    "print(X_train_counter[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unknown</th>\n",
       "      <th>NUM</th>\n",
       "      <th>i</th>\n",
       "      <th>you</th>\n",
       "      <th>u</th>\n",
       "      <th>me</th>\n",
       "      <th>not</th>\n",
       "      <th>my</th>\n",
       "      <th>your</th>\n",
       "      <th>am</th>\n",
       "      <th>have</th>\n",
       "      <th>call</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   unknown  NUM  i  you  u  me  not  my  your  am  have  call\n",
       "0       30    0  1    2  0   0    0   1     0   0     0     0\n",
       "1       26    0  1    1  0   0    0   0     0   0     0     0\n",
       "2       15    0  0    0  0   0    0   0     0   0     0     0\n",
       "3       83    0  1    3  0   2    2   2     2   0     1     0\n",
       "4        6    0  0    0  0   0    0   0     0   0     0     0\n",
       "5        8    0  0    0  0   0    0   0     0   0     0     0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test BoT\n",
    "pd.DataFrame(X_test_bot[0:6, 0:12].toarray() \n",
    "            , columns=['unknown'] + first_11_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Any chance you might have had with me evaporated as soon as you violated my privacy by stealing my phone number from your employer's paperwork. Not cool at all. Please do not contact me again or I will report you to your supervisor.\n"
     ]
    }
   ],
   "source": [
    "print(X_test[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'you': 3, 'me': 2, 'my': 2, 'your': 2, 'not': 2, 'any': 1, 'chance': 1, 'might': 1, 'have': 1, 'had': 1, 'evaporated': 1, 'soon': 1, 'violated': 1, 'privacy': 1, 'stealing': 1, 'phone': 1, 'number': 1, 'employer': 1, 'paperwork': 1, 'cool': 1, 'all': 1, 'please': 1, 'do': 1, 'contact': 1, 'again': 1, 'or': 1, 'i': 1, 'report': 1, 'supervisor': 1, 'any_chance': 1, 'chance_you': 1, 'you_might': 1, 'might_have': 1, 'have_had': 1, 'had_with': 1, 'with_me': 1, 'me_evaporated': 1, 'evaporated_as': 1, 'as_soon': 1, 'soon_as': 1, 'as_you': 1, 'you_violated': 1, 'violated_my': 1, 'my_privacy': 1, 'privacy_by': 1, 'by_stealing': 1, 'stealing_my': 1, 'my_phone': 1, 'phone_number': 1, 'number_from': 1, 'from_your': 1, 'your_employers': 1, 'employers_paperwork': 1, 'paperwork_not': 1, 'not_cool': 1, 'cool_at': 1, 'at_all': 1, 'all_please': 1, 'please_do': 1, 'do_not': 1, 'not_contact': 1, 'contact_me': 1, 'me_again': 1, 'again_or': 1, 'or_i': 1, 'i_will': 1, 'will_report': 1, 'report_you': 1, 'you_to': 1, 'to_your': 1, 'your_supervisor': 1, 'any_chance_you': 1, 'chance_you_might': 1, 'you_might_have': 1, 'might_have_had': 1, 'have_had_with': 1, 'had_with_me': 1, 'with_me_evaporated': 1, 'me_evaporated_as': 1, 'evaporated_as_soon': 1, 'as_soon_as': 1, 'soon_as_you': 1, 'as_you_violated': 1, 'you_violated_my': 1, 'violated_my_privacy': 1, 'my_privacy_by': 1, 'privacy_by_stealing': 1, 'by_stealing_my': 1, 'stealing_my_phone': 1, 'my_phone_number': 1, 'phone_number_from': 1, 'number_from_your': 1, 'from_your_employers': 1, 'your_employers_paperwork': 1, 'employers_paperwork_not': 1, 'paperwork_not_cool': 1, 'not_cool_at': 1, 'cool_at_all': 1, 'at_all_please': 1, 'all_please_do': 1, 'please_do_not': 1, 'do_not_contact': 1, 'not_contact_me': 1, 'contact_me_again': 1, 'me_again_or': 1, 'again_or_i': 1, 'or_i_will': 1, 'i_will_report': 1, 'will_report_you': 1, 'report_you_to': 1, 'you_to_your': 1, 'to_your_supervisor': 1})\n"
     ]
    }
   ],
   "source": [
    "print(X_test_counter[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tfidf_wrong = pipe['tfidf'].fit_transform(X_bot) # WRONGEDY WRONG WRONG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Minute 8 in [Pre-processing our test data](https://www.youtube.com/watch?v=XWUi7RivDJY&list=PLTJTBoU5HOCR5Vkah2Z-AU76ZYsZjGFK6&index=11), here lies the problem:\n",
    "\n",
    "- The test data contains new n-grams... this is bad, we need the same n-grams from the training data (same features)\n",
    "- Each column has to be in the same order and have the same meaning, be the same \"word\", in R:\n",
    "\n",
    "\n",
    "```\n",
    "# Ensure the test dfm has the same n-grams as the training dfm.\n",
    "#\n",
    "# NOTE - In production we should expect that new text messages will \n",
    "#        contain n-grams that did not exist in the original training\n",
    "#        data. As such, we need to strip those n-grams out.\n",
    "#\n",
    "test.tokens.dfm <- dfm_select(test.tokens.dfm, pattern = train.tokens.dfm,\n",
    "                              selection = \"keep\")\n",
    "test.tokens.matrix <- as.matrix(test.tokens.dfm)\n",
    "test.tokens.dfm\n",
    "```\n",
    "\n",
    "- While I did select 2000 ngrams above, they are different 2000 ngrams than the training data. I should, potentially, choose a much higher vocabulary to try to accommodate for the fact that training and test data have diverging vocabularies, in an attempt to rescue as much vocabulary in the trainin as I can in the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse.linalg import svds\n",
    "from sklearn.utils.extmath import svd_flip\n",
    "\n",
    "def perform_SVD(X, n_components=300): \n",
    "    \n",
    "    X_array = X.asfptype()\n",
    "    U, Sigma, VT = svds(X_array.T, \n",
    "                        k=n_components)\n",
    "    # reverse outputs\n",
    "    Sigma = Sigma[::-1]\n",
    "    U, VT = svd_flip(U[:, ::-1], VT[::-1])\n",
    "    \n",
    "    # return V\n",
    "    return VT.T\n",
    "\n",
    "# SVD with 800 components\n",
    "X_tfidf_svd = perform_SVD(X_tfidf_wrong, # YUP. WRONG.\n",
    "                          n_components=800) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosine Similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse as sp\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "X_tfidf_svd_allcos = cosine_similarity(X_tfidf_svd)\n",
    "\n",
    "test_df = pd.DataFrame({'sms':X_test, 'target':y_test}) # change\n",
    "\n",
    "# get spam indexes\n",
    "spam_ix = test_df.loc[test_df['target']=='spam'].index # change\n",
    "\n",
    "# calculate average spam similarity on SVD\n",
    "mean_spam_sims = []\n",
    "\n",
    "for ix in range(X_tfidf_svd_allcos.shape[0]):\n",
    "    mean_spam_sims.append(np.mean(X_tfidf_svd_allcos[ix, spam_ix]))\n",
    "\n",
    "X_tfidf_svd_spamcos = sp.hstack((csr_matrix(mean_spam_sims).T, X_tfidf_svd)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
