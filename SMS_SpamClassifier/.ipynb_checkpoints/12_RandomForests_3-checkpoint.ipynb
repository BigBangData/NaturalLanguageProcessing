{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forests 3\n",
    "\n",
    "---\n",
    "\n",
    "__This Notebook__:\n",
    "\n",
    "- the command line script failed often, so I only got the X_bot (first representation) that way\n",
    "- this notebook performs 5 grid searches for the rest of the non-tfidf models:\n",
    "\n",
    "    1. X_bot_feat\n",
    "    2. X_bot_svd\n",
    "    3. X_bot_svd_cos\n",
    "    4. X_bot_svd_feat\n",
    "    5. X_bot_svd_feat_cos\n",
    "    \n",
    "    \n",
    "- I also altered the `gridsearch_wrapper` function to take in the models so as to be able to make partial runs, and added functionality to save gridsearches as they complete, so that if the wrapper fails or I kill it manually I don't lose the completed searches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Revised on: 2021-01-05\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "\n",
    "from datetime import datetime\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import make_scorer, recall_score, accuracy_score, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "dt_object = datetime.fromtimestamp(time.time())\n",
    "day, T = str(dt_object).split('.')[0].split(' ')\n",
    "print('Revised on: ' + day)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load target\n",
    "raw_path = os.path.join(\"data\",\"1_raw\")\n",
    "filename = \"y_train.csv\"\n",
    "y = pd.read_csv(os.path.join(raw_path, filename))\n",
    "y = np.array(y.iloc[:,0].ravel())\n",
    "y[y=='ham'] = 0\n",
    "y[y=='spam'] = 1\n",
    "y = y.astype('int')\n",
    "\n",
    "# load 12 matrices\n",
    "proc_dir = os.path.join(\"data\",\"2_processed\")\n",
    "Xnames = [x for x in os.listdir(proc_dir) if re.search('.npz', x)]\n",
    "Xs = []\n",
    "for ix, X in enumerate(Xnames):\n",
    "    path_ = os.path.join(proc_dir, Xnames[ix])\n",
    "    Xs.append(sp.load_npz(path_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 X_bot\n",
      "2 X_bot_feat\n",
      "3 X_bot_svd\n",
      "4 X_bot_svd_cos\n",
      "5 X_bot_svd_feat\n",
      "6 X_bot_svd_feat_cos\n",
      "7 X_bot_tfidf\n",
      "8 X_bot_tfidf_feat\n",
      "9 X_bot_tfidf_svd\n",
      "10 X_bot_tfidf_svd_cos\n",
      "11 X_bot_tfidf_svd_feat\n",
      "12 X_bot_tfidf_svd_feat_cos\n"
     ]
    }
   ],
   "source": [
    "# 12 representations\n",
    "for ix, Xname in enumerate(Xnames):\n",
    "    Xname = Xname.split('.')[0]\n",
    "    print(ix+1, Xname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid search random forest models\n",
    "\n",
    "Using sklearn's GridSearchCV with 10-fold cross validation on a shallow param grid, varying representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_eval_metrics(y_val, y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_val, y_pred).ravel()\n",
    "    acc = (tp + tn) / (tp + tn + fp + fn)\n",
    "    tpr = tp / (tp + fn)\n",
    "    tnr = tn / (tn + fp)\n",
    "    print(f'accuracy: {acc:0.4f}')\n",
    "    print(f'sensitivity: {tpr:0.4f}')\n",
    "    print(f'specificity: {tnr:0.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gridsearch_wrapper(Xs, Xnames, test=False, k=10):\n",
    "    \"\"\"\n",
    "    Performs grid searches and collects them in a list.\n",
    "    Args:\n",
    "        Xs: the numeric matrices\n",
    "        Xnames: their names\n",
    "        test: faster, shallower searches for testing\n",
    "        k: the number of CV folds\n",
    "    \"\"\"\n",
    "    \n",
    "    start_time = time.time()\n",
    "    model_dir = os.path.join(\"data\", \"3_modeling\")\n",
    "    \n",
    "    # instantiate list of dicts to gather results\n",
    "    gridsearches = []\n",
    "    for ix, X_name in enumerate(Xnames):\n",
    "\n",
    "        X_ = Xs[ix].toarray()\n",
    "        X_name = X_name.split('.')[0]\n",
    "\n",
    "        # split into training and validation sets\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X_, y, stratify=y)\n",
    "\n",
    "        # setup testing param grid\n",
    "        test_param_grid = {\n",
    "            'min_samples_split': [5, 10, 20], \n",
    "            'n_estimators' : [50, 100],\n",
    "            'max_depth': [10, 20],\n",
    "            'max_features': [50, 100, 200]\n",
    "        }\n",
    "\n",
    "        # setup param grid for final not-too-deep search\n",
    "        param_grid = {\n",
    "            'min_samples_split': [5, 10, 15],\n",
    "            'n_estimators' : [100, 200],\n",
    "            'max_depth': [5, 10, 20],\n",
    "            'max_features': [50, 100, 250, 500]\n",
    "        }\n",
    "\n",
    "        # setup scorers\n",
    "        scorers = {\n",
    "            'acc': make_scorer(accuracy_score),\n",
    "            'tpr': make_scorer(recall_score, pos_label=1), # sensitivity, recall\n",
    "            'tnr': make_scorer(recall_score, pos_label=0) # specificity, selectivity\n",
    "        }\n",
    "\n",
    "        # instantiate estimator\n",
    "        clf = RandomForestClassifier(n_jobs=-1, random_state=42)\n",
    "\n",
    "        # instantiate k-fold gridsearch\n",
    "        cv_folds = StratifiedKFold(n_splits=k)\n",
    "    \n",
    "        if test == True:\n",
    "            grid_search_clf = GridSearchCV(clf, test_param_grid, # test grid\n",
    "                                           scoring=scorers, \n",
    "                                           refit='tpr', cv=cv_folds, \n",
    "                                           return_train_score=True, n_jobs=-1)\n",
    "        else:\n",
    "            grid_search_clf = GridSearchCV(clf, param_grid,\n",
    "                                           scoring=scorers, \n",
    "                                           refit='tpr', cv=cv_folds, \n",
    "                                           return_train_score=True, n_jobs=-1)           \n",
    "\n",
    "        # train models\n",
    "        print(f'\\nTraining {ix+1}: {X_name}...')\n",
    "        start_gs = time.time()\n",
    "        grid_search_clf.fit(X_train, y_train)\n",
    "        elapsed_secs = time.time() - start_gs\n",
    "        print(f'Elapsed: {elapsed_secs:0.0f} s')\n",
    "\n",
    "        # predict\n",
    "        y_pred = grid_search_clf.predict(X_val)\n",
    "        print(f'Best params: {grid_search_clf.best_params_}')\n",
    "\n",
    "        # confusion matrix on validation set\n",
    "        print(f'Confusion matrix on validation set:')\n",
    "        print(pd.DataFrame(confusion_matrix(y_val, y_pred),\n",
    "                           columns=['pred_neg', 'pred_pos'],\n",
    "                           index=['neg', 'pos']))\n",
    "        # eval metrics\n",
    "        print('Evaluation metrics:')\n",
    "        print_eval_metrics(y_val, y_pred)\n",
    "\n",
    "        data = {'representation':X_name,\n",
    "                'gridsearch_res':grid_search_clf}\n",
    "        \n",
    "        # save gridsearch\n",
    "        filename = ''.join([str(ix+1), \"_\", Xname, \"_rf_gridsearch.joblib\"])\n",
    "        file_path = os.path.join(model_dir, filename)                                                    \n",
    "        joblib.dump(data, file_path)\n",
    "        \n",
    "        # gather results into a list of dicts\n",
    "        gridsearches.append(data)\n",
    "        \n",
    "    mins, secs = divmod(time.time() - start_time, 60)\n",
    "    print(f'\\nTot elapsed: {mins:0.0f} m {secs:0.0f} s')\n",
    "    return gridsearches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training 1: X_bot_feat...\n",
      "Elapsed: 1469 s\n",
      "Best params: {'max_depth': 20, 'max_features': 500, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Confusion matrix on validation set:\n",
      "     pred_neg  pred_pos\n",
      "neg       841         5\n",
      "pos        13       116\n",
      "Evaluation metrics:\n",
      "accuracy: 0.9815\n",
      "sensitivity: 0.8992\n",
      "specificity: 0.9941\n",
      "\n",
      "Training 2: X_bot_svd...\n",
      "Elapsed: 3872 s\n",
      "Best params: {'max_depth': 20, 'max_features': 100, 'min_samples_split': 10, 'n_estimators': 200}\n",
      "Confusion matrix on validation set:\n",
      "     pred_neg  pred_pos\n",
      "neg       837         9\n",
      "pos        16       113\n",
      "Evaluation metrics:\n",
      "accuracy: 0.9744\n",
      "sensitivity: 0.8760\n",
      "specificity: 0.9894\n",
      "\n",
      "Training 3: X_bot_svd_cos...\n",
      "Elapsed: 3605 s\n",
      "Best params: {'max_depth': 20, 'max_features': 50, 'min_samples_split': 10, 'n_estimators': 200}\n",
      "Confusion matrix on validation set:\n",
      "     pred_neg  pred_pos\n",
      "neg       840         6\n",
      "pos        19       110\n",
      "Evaluation metrics:\n",
      "accuracy: 0.9744\n",
      "sensitivity: 0.8527\n",
      "specificity: 0.9929\n",
      "\n",
      "Training 4: X_bot_svd_feat...\n",
      "Elapsed: 3648 s\n",
      "Best params: {'max_depth': 20, 'max_features': 100, 'min_samples_split': 10, 'n_estimators': 200}\n",
      "Confusion matrix on validation set:\n",
      "     pred_neg  pred_pos\n",
      "neg       839         7\n",
      "pos        17       112\n",
      "Evaluation metrics:\n",
      "accuracy: 0.9754\n",
      "sensitivity: 0.8682\n",
      "specificity: 0.9917\n",
      "\n",
      "Training 5: X_bot_svd_feat_cos...\n",
      "Elapsed: 3545 s\n",
      "Best params: {'max_depth': 20, 'max_features': 100, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Confusion matrix on validation set:\n",
      "     pred_neg  pred_pos\n",
      "neg       842         4\n",
      "pos        20       109\n",
      "Evaluation metrics:\n",
      "accuracy: 0.9754\n",
      "sensitivity: 0.8450\n",
      "specificity: 0.9953\n",
      "\n",
      "Tot elapsed: 269 m 0 s\n"
     ]
    }
   ],
   "source": [
    "results = gridsearch_wrapper(Xs=Xs[1:6], Xnames=Xnames[1:6], test=False, k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Persist results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'representation': 'X_bot_feat',\n",
       "  'gridsearch_res': GridSearchCV(cv=StratifiedKFold(n_splits=10, random_state=None, shuffle=False),\n",
       "               estimator=RandomForestClassifier(n_jobs=-1, random_state=42),\n",
       "               n_jobs=-1,\n",
       "               param_grid={'max_depth': [5, 10, 20],\n",
       "                           'max_features': [50, 100, 250, 500],\n",
       "                           'min_samples_split': [5, 10, 15],\n",
       "                           'n_estimators': [100, 200]},\n",
       "               refit='tpr', return_train_score=True,\n",
       "               scoring={'acc': make_scorer(accuracy_score),\n",
       "                        'tnr': make_scorer(recall_score, pos_label=0),\n",
       "                        'tpr': make_scorer(recall_score, pos_label=1)})},\n",
       " {'representation': 'X_bot_svd',\n",
       "  'gridsearch_res': GridSearchCV(cv=StratifiedKFold(n_splits=10, random_state=None, shuffle=False),\n",
       "               estimator=RandomForestClassifier(n_jobs=-1, random_state=42),\n",
       "               n_jobs=-1,\n",
       "               param_grid={'max_depth': [5, 10, 20],\n",
       "                           'max_features': [50, 100, 250, 500],\n",
       "                           'min_samples_split': [5, 10, 15],\n",
       "                           'n_estimators': [100, 200]},\n",
       "               refit='tpr', return_train_score=True,\n",
       "               scoring={'acc': make_scorer(accuracy_score),\n",
       "                        'tnr': make_scorer(recall_score, pos_label=0),\n",
       "                        'tpr': make_scorer(recall_score, pos_label=1)})},\n",
       " {'representation': 'X_bot_svd_cos',\n",
       "  'gridsearch_res': GridSearchCV(cv=StratifiedKFold(n_splits=10, random_state=None, shuffle=False),\n",
       "               estimator=RandomForestClassifier(n_jobs=-1, random_state=42),\n",
       "               n_jobs=-1,\n",
       "               param_grid={'max_depth': [5, 10, 20],\n",
       "                           'max_features': [50, 100, 250, 500],\n",
       "                           'min_samples_split': [5, 10, 15],\n",
       "                           'n_estimators': [100, 200]},\n",
       "               refit='tpr', return_train_score=True,\n",
       "               scoring={'acc': make_scorer(accuracy_score),\n",
       "                        'tnr': make_scorer(recall_score, pos_label=0),\n",
       "                        'tpr': make_scorer(recall_score, pos_label=1)})},\n",
       " {'representation': 'X_bot_svd_feat',\n",
       "  'gridsearch_res': GridSearchCV(cv=StratifiedKFold(n_splits=10, random_state=None, shuffle=False),\n",
       "               estimator=RandomForestClassifier(n_jobs=-1, random_state=42),\n",
       "               n_jobs=-1,\n",
       "               param_grid={'max_depth': [5, 10, 20],\n",
       "                           'max_features': [50, 100, 250, 500],\n",
       "                           'min_samples_split': [5, 10, 15],\n",
       "                           'n_estimators': [100, 200]},\n",
       "               refit='tpr', return_train_score=True,\n",
       "               scoring={'acc': make_scorer(accuracy_score),\n",
       "                        'tnr': make_scorer(recall_score, pos_label=0),\n",
       "                        'tpr': make_scorer(recall_score, pos_label=1)})},\n",
       " {'representation': 'X_bot_svd_feat_cos',\n",
       "  'gridsearch_res': GridSearchCV(cv=StratifiedKFold(n_splits=10, random_state=None, shuffle=False),\n",
       "               estimator=RandomForestClassifier(n_jobs=-1, random_state=42),\n",
       "               n_jobs=-1,\n",
       "               param_grid={'max_depth': [5, 10, 20],\n",
       "                           'max_features': [50, 100, 250, 500],\n",
       "                           'min_samples_split': [5, 10, 15],\n",
       "                           'n_estimators': [100, 200]},\n",
       "               refit='tpr', return_train_score=True,\n",
       "               scoring={'acc': make_scorer(accuracy_score),\n",
       "                        'tnr': make_scorer(recall_score, pos_label=0),\n",
       "                        'tpr': make_scorer(recall_score, pos_label=1)})}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data\\\\3_modeling\\\\01052021_rf_gridsearches.joblib']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dir = os.path.join(\"data\", \"3_modeling\")\n",
    "file_path = os.path.join(model_dir, \"\".join([\"01052021\", \"_rf_gridsearches.joblib\"]))\n",
    "\n",
    "# save all gridsearches\n",
    "joblib.dump(results, file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
