{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation 2 - Learning Curves\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Revised on: 2021-02-21\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import joblib \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split, \\\n",
    "    ShuffleSplit, StratifiedKFold, learning_curve\n",
    "from sklearn.metrics import make_scorer, accuracy_score, \\\n",
    "    recall_score, confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, \\\n",
    "    RandomForestClassifier, GradientBoostingClassifier, \\\n",
    "    VotingClassifier\n",
    "\n",
    "import custom.evaluate_models as E\n",
    "\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "dt_object = datetime.fromtimestamp(time.time())\n",
    "day, T = str(dt_object).split('.')[0].split(' ')\n",
    "print('Revised on: ' + day)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Test Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_y(data):\n",
    "    raw_path = os.path.join(\"data\",\"1_raw\")\n",
    "    filename = ''.join([data, \".csv\"])\n",
    "    out_dfm = pd.read_csv(os.path.join(raw_path, filename))\n",
    "    out_arr = np.array(out_dfm.iloc[:,0].ravel())\n",
    "    return out_arr\n",
    "\n",
    "y_test = load_y(\"y_test\") \n",
    "\n",
    "def make_int(y_array):\n",
    "    y = y_array.copy()\n",
    "    y[y=='ham'] = 0\n",
    "    y[y=='spam'] = 1\n",
    "    y = y.astype('int')\n",
    "    return y\n",
    "\n",
    "y = make_int(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Preprocessed Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_X(filename):\n",
    "    proc_dir = os.path.join(\"data\", \"2_processed\")\n",
    "    filename = ''.join([filename, '.npz'])\n",
    "    X = sp.load_npz(os.path.join(proc_dir, filename))\n",
    "    return X\n",
    "\n",
    "X = load_X('X_test_processed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate Candidate Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_clf1 = RandomForestClassifier(\n",
    "    random_state=42, n_estimators=100, max_features=150, \n",
    "    max_depth=8, min_samples_split=3, warm_start=True, \n",
    "    n_jobs=1)\n",
    "\n",
    "rnd_clf2 = RandomForestClassifier(\n",
    "    random_state=42, n_estimators=100, max_features=300, \n",
    "    max_depth=8, min_samples_split=3, warm_start=True, \n",
    "    n_jobs=1)\n",
    "    \n",
    "ada_clf1 =  AdaBoostClassifier(\n",
    "    random_state=42 , n_estimators=10, \n",
    "    learning_rate=0.001)\n",
    "\n",
    "gbc1a = GradientBoostingClassifier(\n",
    "    random_state=42, n_estimators=50, max_features=None, \n",
    "    max_depth=1, min_samples_split=2)\n",
    "\n",
    "gbc2a = GradientBoostingClassifier(\n",
    "    random_state=42, n_estimators=100, max_features=300, \n",
    "    max_depth=8, min_samples_split=5)\n",
    "\n",
    "gbc2c = GradientBoostingClassifier(\n",
    "    random_state=42, n_estimators=50, max_features=300, \n",
    "    max_depth=3, min_samples_split=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10-fold Cross Validation Learning Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10-fold cross validation\n",
    "cv = ShuffleSplit(n_splits=10, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "E.compare_two_classifiers(X, y, rnd_clf1, rnd_clf2, \"rnd_clf1\", \"rnd_clf2\", cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E.compare_two_classifiers(X, y, ada_clf1, gbc1a, \"ada_clf1\", \"gbc1a\", cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E.compare_two_classifiers(X, y, gbc2a, gbc2c, \"gbc2a\", \"gbc2c\", cv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
