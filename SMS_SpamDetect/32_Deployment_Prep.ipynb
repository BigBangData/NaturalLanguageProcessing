{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Deployment 1\n",
    "\n",
    "---\n",
    "\n",
    "Prepping the model and the various pre-processing steps and transformers for deployment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import joblib \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "import custom.clean_preprocess as cp\n",
    "\n",
    "from datetime import datetime\n",
    "from xgboost import XGBClassifier\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create deployment dir\n",
    "dep_dir = os.path.join(\"data\",\"5_deployment\")\n",
    "\n",
    "try:\n",
    "    os.stat(dep_dir)\n",
    "except:\n",
    "    os.mkdir(dep_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_raw(data):\n",
    "    raw_path = os.path.join(\"data\",\"1_raw\")\n",
    "    filename = ''.join([data, \".csv\"])\n",
    "    out_dfm = pd.read_csv(os.path.join(raw_path, filename))\n",
    "    out_arr = np.array(out_dfm.iloc[:,0].ravel())\n",
    "    return out_arr\n",
    "\n",
    "def make_int(y_array):\n",
    "    y = y_array.copy()\n",
    "    y[y=='ham'] = 0\n",
    "    y[y=='spam'] = 1\n",
    "    y = y.astype('int')\n",
    "    return y\n",
    "\n",
    "X_train_raw = load_raw(\"X_train\")\n",
    "X_test_raw = load_raw(\"X_test\")\n",
    "y_train_raw = load_raw(\"y_train\")\n",
    "y_test_raw = load_raw(\"y_test\")\n",
    "\n",
    "y_train = make_int(y_train_raw)\n",
    "y_test = make_int(y_test_raw)\n",
    "\n",
    "y_array = np.hstack((y_train_raw, y_test_raw))\n",
    "\n",
    "# concatenate all data\n",
    "X = np.hstack((X_train_raw, X_test_raw))\n",
    "y = np.hstack((y_train, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data\\\\5_deployment\\\\X_train_transformer.joblib']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preprocess pipeline\n",
    "pipe = Pipeline([('counter', cp.DocumentToNgramCounterTransformer(n_grams=3)),\n",
    "                 ('bot', cp.WordCounterToVectorTransformer(vocabulary_size=2000)),\n",
    "                 ('tfidf', TfidfTransformer(sublinear_tf=True))])\n",
    "\n",
    "# counters\n",
    "X_train_counter = pipe['counter'].fit_transform(X) \n",
    "#X_test_counter = pipe['counter'].fit_transform(new_data) # use pipeline counter\n",
    "\n",
    "X_train_transformer = pipe['bot'].fit(X_train_counter)  # same counter\n",
    "\n",
    "# SAVE 1\n",
    "X_train_transformer_path = os.path.join(dep_dir, 'X_train_transformer.joblib')\n",
    "joblib.dump(X_train_transformer, X_train_transformer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data\\\\5_deployment\\\\X_train_fit.joblib']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BoTs\n",
    "X_train_bot = X_train_transformer.transform(X_train_counter)\n",
    "#X_test_bot = X_train_transformer.transform(X_test_counter) # same transformer\n",
    "\n",
    "# fit Tfidf\n",
    "X_train_fit = pipe['tfidf'].fit(X_train_bot) # save this (has idf)\n",
    "\n",
    "# SAVE 2\n",
    "X_train_fit_path = os.path.join(dep_dir, 'X_train_fit.joblib')\n",
    "joblib.dump(X_train_fit, X_train_fit_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform Tfidf\n",
    "X_train_tfidf = X_train_fit.transform(X_train_bot)\n",
    "#X_test_tfidf = X_train_fit.transform(X_test_bot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data\\\\5_deployment\\\\X_train_svd_transformer.joblib']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import custom.deploy_models as dp\n",
    "\n",
    "# instantiate SVD transformer\n",
    "X_train_svd_transformer = dp.TruncatedSVD()\n",
    "\n",
    "# fit transformer\n",
    "X_train_svd_transformer.fit(X_train_tfidf.T) # save this\n",
    "\n",
    "# SAVE 3\n",
    "X_train_svd_transformer_path = os.path.join(dep_dir, 'X_train_svd_transformer.joblib')\n",
    "joblib.dump(X_train_svd_transformer, X_train_svd_transformer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# project\n",
    "sigma_inverse = 1 / X_train_svd_transformer.sigma_\n",
    "U_transpose = X_train_svd_transformer.U_.T\n",
    "\n",
    "#UT_TestTfidfT = (U_transpose @ X_test_tfidf.T)\n",
    "\n",
    "# project into SVD space\n",
    "X_train_svd = X_train_svd_transformer.V_\n",
    "#X_test_svd = (sigma_inverse.reshape(-1,1) * UT_TestTfidfT).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data\\\\5_deployment\\\\X_train_svd_spam.joblib']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all similarities\n",
    "train_similarities = cosine_similarity(X_train_svd)\n",
    "\n",
    "# spam similarities\n",
    "train_df = pd.DataFrame({'sms':X, 'target':y_array}) \n",
    "train_spam_ix = train_df.loc[train_df['target']=='spam'].index\n",
    "\n",
    "# mean spam sims\n",
    "train_mean_spam_sims = []\n",
    "for ix in range(train_similarities.shape[0]):\n",
    "    mean_spam_sim = np.mean(train_similarities[ix, train_spam_ix])\n",
    "    train_mean_spam_sims.append(mean_spam_sim)\n",
    "\n",
    "# SAVE 4\n",
    "X_train_svd_spam_path = os.path.join(dep_dir, 'X_train_svd_spam.joblib')\n",
    "joblib.dump(X_train_svd[train_spam_ix], X_train_svd_spam_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack onto svd\n",
    "X_train_processed = sp.hstack((csr_matrix(train_mean_spam_sims).T, X_train_svd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get test similarities using X_train_svd spam sims\n",
    "#test_similarities = cosine_similarity(sp.vstack((X_test_svd, \n",
    "#                                                 X_train_svd[train_spam_ix]))) # will need this\n",
    "\n",
    "# get spam cols for spam similarities\n",
    "#spam_cols = range(X_test_svd.shape[0], test_similarities.shape[0])\n",
    "\n",
    "# mean spam sims\n",
    "#test_mean_spam_sims = []\n",
    "#for ix in range(X_test_svd.shape[0]):\n",
    "#    mean_spam_sim = np.mean(test_similarities[ix, spam_cols])\n",
    "#    test_mean_spam_sims.append(mean_spam_sim)\n",
    "\n",
    "# stack onto svd\n",
    "#X_test_processed = sp.hstack((csr_matrix(test_mean_spam_sims).T, X_test_svd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model on all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = XGBClassifier(\n",
    "    seed=42, eval_metric='error',\n",
    "    use_label_encoder=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, eval_metric='error',\n",
       "              gamma=0, gpu_id=-1, importance_type='gain',\n",
       "              interaction_constraints='', learning_rate=0.300000012,\n",
       "              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=100, n_jobs=8,\n",
       "              num_parallel_tree=1, random_state=42, reg_alpha=0, reg_lambda=1,\n",
       "              scale_pos_weight=1, seed=42, subsample=1, tree_method='exact',\n",
       "              use_label_encoder=False, validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit classifier\n",
    "clf.fit(X_train_processed, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data\\\\5_deployment\\\\XGboost_mod1.joblib']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SAVE MODEL\n",
    "XGboost_mod1 = os.path.join(dep_dir, 'XGboost_mod1.joblib')\n",
    "joblib.dump(clf, XGboost_mod1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
