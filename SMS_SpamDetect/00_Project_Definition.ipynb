{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Goals\n",
    "\n",
    "- study NLP and practice ML by building classifiers that use open text fields as input\n",
    "- create a Python framework that generalizes a workflow in R for detecting SMS spam messages\n",
    "- evaluate the effectiveness of the framework with Twitter data to predict some binary outcome\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General ML Project Structure\n",
    "\n",
    "These steps do not need to be sequential. For example, feature engineering can be done sooner. They are also cyclic: in practice, one might need to continuously re-define the problem and iterate on exploratory data analysis and statistical modeling steps:\n",
    "\n",
    "1. define the problem, set expectations and evaluation criteria\n",
    "2. preliminary and minimal EDA and pre-splitting cleanup\n",
    "3. split dataset into trainining and test subsets; set the test subset aside\n",
    "4. create a cleanup and preprocessing pipeline for the training data that can be re-applied to the test data\n",
    "5. train a couple baseline models to ensure process is smooth and pre-processing is dialed in\n",
    "6. using cross-validation, evaluate a variety models without hyperparameter tuning to establish some baselines\n",
    "7. short-list promising models for further hyperparemeter tuning\n",
    "8. iterate on any phase of the project as needed\n",
    "9. consider feature selection and feature engineering\n",
    "10. decide on a final cleanup and processing pipeline\n",
    "11. settle on a final model\n",
    "12. re-apply all cleanup and processing steps to the test set and evaluate final model(s)\n",
    "13. create a final presentation of the solution for technical and non-technical audiences\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Inspiration\n",
    "\n",
    "There is a lot more unstructured, text data than structured data. To leverage it one needs to apply text analytic techniques to structure the data before getting value from it. \n",
    "\n",
    "Value can be defined in many ways, here are a couple:\n",
    "\n",
    "**Framework for Binary Classification** \n",
    "\n",
    "\n",
    "Given the goal of binary classification, say, to separate *spam* from *ham* (legitimate) messages, or *positive* (happier) from *negative* (unhappier) comments on social media, one can build classifiers that learn from a corpus of documents and predicts an outcome given an instance (a text, post, comment).\n",
    "\n",
    "Both cases are well-known and mostly solved. It is less clear to me whether classifiers built for spam detection would also perform well for predicting negative Tweets. Having a framework that quickly deploys and assesses the accuracy of classifiers for binary predictions given open text fields seems a valuable pursuit.\n",
    "\n",
    "\n",
    "**Named-Entity Recognition** \n",
    "\n",
    "A common need in businesses that capture data through open text fields is to be able to extract keywords from variable-size text inputs. Say a business has an online app that historically has captured information through an open text field but nobody has had the time to read that input. Going forward, product owners decide this field should be turned into a drop-down menu. To integrate the past and future versions of this field, there's a need to bucket the unstructured text into categories for the new drop-down. To solve this, a data scientist can apply entity extraction techniques such as NER:\n",
    "\n",
    "> \"Named-entity recognition (NER) [...] is a subtask of information extraction that seeks to locate and classify named entities mentioned in unstructured text into pre-defined categories...\" [Wikipedia, accessed Dec 19, 2020](https://en.wikipedia.org/wiki/Named-entity_recognition)\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Definition\n",
    "\n",
    "\n",
    "#### What is the problem this project is trying to solve?\n",
    "\n",
    "Automatically separate *spam* from *ham* (legitimate) SMS (short message service, aka \"text\") messages.\n",
    "\n",
    "\n",
    "#### What are the expectations?\n",
    "\n",
    "That the classifier built for this purpose can do this task quickly and accurately enough to avoid frustrating SMS users. I'm also not building an app or hosting the spam detector online, just building the classifier in Jupyter Notebooks and presenting results in slides or some other friendly format.\n",
    "\n",
    "#### What does success look like for this project?\n",
    "\n",
    "Train a classifier that achieves high accuracy, but not at the expense of either sensitivity or specificity. Given the positive case of spam - since it is a spam detector after all - this classifier can correctly classify most spam as spam (sensitivity, or true positive rate) but also, and most importantly, most ham as ham (specificity, or true negative rate), since this mistake is worse: it would be worse to send a legitimate message to the spam folder where it's likely to be ignored, than to let some spam end up in the inbox, where it can be quickly deleted. \n",
    "\n",
    "Success looks like a 98% (give or take 1%) F1-score (harmonic mean of sensitivity and specificity) and a quick, subsecond prediction pipeline for new inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "The dataset is now spread across the internet, perhaps a good source is the [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/sms+spam+collection#). The dataset is a collage of sources; the data collection process is explained by the original authors Tiago A. Almeida and José María Gómez Hidalgo in this [University of Campinas website.](http://www.dt.fee.unicamp.br/~tiago/smsspamcollection/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acknowledgements\n",
    "\n",
    "This journey into the fields of NLP and ML took months of learning and development of my own understanding of various inner workings of models I never ended up deploying. I am indebted to numerous tutorials and blogs I've read and watched along the way. Below is a list in order of most-to-least influential:\n",
    "\n",
    "- [Data Science Dojo's](https://datasciencedojo.com/) [Introduction To Text Analytics With R](https://www.youtube.com/playlist?list=PLTJTBoU5HOCR5Vkah2Z-AU76ZYsZjGFK6) by [David Langer](https://www.daveondata.com/)\n",
    "- Aurélien Géron's [Classification Notebook](https://github.com/ageron/handson-ml/blob/master/03_classification.ipynb) \n",
    "- Scikit-Learn's [API Docs](https://scikit-learn.org/stable/modules/classes.html)\n",
    "- Chayan Kathuria's tutorial [Build & Deploy a Spam Classifier app on Heroku Cloud in 10 minutes!](https://towardsdatascience.com/build-deploy-a-spam-classifier-app-on-heroku-cloud-in-10-minutes-f9347b27ff72)\n",
    "- Analytics Vidhya's [Introduction to Topic Modeling and Latent Semantic Analysis](https://www.analyticsvidhya.com/blog/2018/10/stepwise-guide-topic-modeling-latent-semantic-analysis/)\n",
    "- Prof. Steve Brunton's [YouTube lectures on Singular Value Decomposition](https://www.youtube.com/playlist?list=PLMrJAkhIeNNSVjnsviglFoY2nXildDCcv) \n",
    "- Kevin Arvai's tutorial [Fine Tuning a Classifier in Scikit-Learn](https://towardsdatascience.com/fine-tuning-a-classifier-in-scikit-learn-66e048c21e65)\n",
    "- Cole Brendel's article [Quickly Compare Multiple Models](https://towardsdatascience.com/quickly-test-multiple-models-a98477476f0)\n",
    "- Josh Starmer's [StatQuest YouTube channel](https://www.youtube.com/channel/UCtYLUTtgS3k1Fg4y5tAhLbw)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
