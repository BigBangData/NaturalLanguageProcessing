{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaBoost\n",
    "---\n",
    "\n",
    "__This Notebook__\n",
    "\n",
    "- implements AdaBoost with full params\n",
    "\n",
    "__Results__ \n",
    "\n",
    "- 10-fold CV maxes out at about 97% sensitivity, for learning rates 0.001, 0.01 and number of trees ranging from 10 to 500\n",
    "- my hypothesis is that the default estimator's `max_depth=1` is causing this cap on sensitivity, I'm testing that next\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Revised on: 2021-02-07\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "import time\n",
    "import joblib \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "dt_object = datetime.fromtimestamp(time.time())\n",
    "day, T = str(dt_object).split('.')[0].split(' ')\n",
    "print('Revised on: ' + day)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load target vector\n",
    "raw_path = os.path.join(\"data\",\"1_raw\")\n",
    "y_df = pd.read_csv(os.path.join(raw_path, 'y_train.csv'))\n",
    "y_array = np.array(y_df.iloc[:,0].ravel())\n",
    "\n",
    "y = y_array.copy()\n",
    "\n",
    "# transform y_array into int type\n",
    "y[y=='ham'] = 0\n",
    "y[y=='spam'] = 1\n",
    "y = y.astype('int')\n",
    "\n",
    "# load matrix\n",
    "proc_dir = os.path.join(\"data\", \"2_processed\")\n",
    "X_tfidf_svd800_spamcos = sp.load_npz(os.path.join(proc_dir, 'X_tfidf_svd800_spamcos.npz'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helpful Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train classifier and time it\n",
    "def time_deco(func):\n",
    "    def wrapper(clf):\n",
    "        start = time.time()\n",
    "        func(clf)\n",
    "        m,s = divmod(time.time() - start, 60)\n",
    "        print(f'Elapsed: {m:0.0f}m {s:0.0f}s')\n",
    "    return wrapper\n",
    "\n",
    "@time_deco\n",
    "def fit_clf(clf):\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "# evaluate classifier\n",
    "def eval_clf(y_val, y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_val, \n",
    "                                      y_pred).ravel()\n",
    "    confmat_df = pd.DataFrame(\n",
    "        np.array(([tn, fp], [fn, tp])),\n",
    "        columns=['pred_neg', 'pred_pos'], \n",
    "        index=['cond_neg', 'cond_pos']\n",
    "    )\n",
    "    # unpack metrics\n",
    "    acc = (tp + tn) / (tp + tn + fp + fn)\n",
    "    tpr = tp / (tp + fn)\n",
    "    tnr = tn / (tn + fp)\n",
    "    # print results\n",
    "    print(confmat_df)\n",
    "    print(f'acc: {acc:0.4f}')\n",
    "    print(f'tpr: {tpr:0.4f}')\n",
    "    print(f'tnr: {tnr:0.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_tfidf_svd800_spamcos,\n",
    "                                                  y, \n",
    "                                                  stratify=y,\n",
    "                                                  random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  AdaBoost (Adaptive Boosting) \n",
    "\n",
    "\n",
    "The first successful boosting algorithm for binary classification. Many current boosting methods build on it.\n",
    "\n",
    "Scikit-Learn implements [SAMME](https://web.stanford.edu/~hastie/Papers/samme.pdf): *Stagewise Additive Modeling using a Multiclass Esponential loss function.* With two classes, SAMME works just as AdaBoost would. If predictions can estimate class probabilities, Scikit-Learn uses a variant of SAMME called *SAMME.R* (R=Real).\n",
    "\n",
    "```\n",
    "class AdaBoostClassifier(ClassifierMixin, BaseWeightBoosting):\n",
    "    \"\"\"An AdaBoost classifier.\n",
    "    An AdaBoost [1] classifier is a meta-estimator that begins by fitting a\n",
    "    classifier on the original dataset and then fits additional copies of the\n",
    "    classifier on the same dataset but where the weights of incorrectly\n",
    "    classified instances are adjusted such that subsequent classifiers focus\n",
    "    more on difficult cases.\n",
    "    \n",
    "    This class implements the algorithm known as AdaBoost-SAMME [2].\n",
    "\n",
    "```\n",
    "\n",
    "See [docs](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html), [code](https://github.com/scikit-learn/scikit-learn/blob/95119c13a/sklearn/ensemble/_weight_boosting.py#L285)\n",
    "\n",
    "\n",
    "__Some defaults:__\n",
    "\n",
    "- `base_estimator`: the default (None) is a DecisionTreeClassifier initialized with max_depth=1\n",
    "- `n_estimators`: default=50\n",
    "- `learning_rate`: default=1, shrinks contribution of each classifier; there's a trade-off with n_estimators\n",
    "- `algorithm{‘SAMME’, ‘SAMME.R’}`: default=’SAMME.R’\n",
    "- `random_state`: default=None\n",
    "\n",
    "__Some methods:__\n",
    "\n",
    "- `.get_params`: returns the parameters\n",
    "- `.decision_function`: evaluates the decision function for the samples in X, if binary from -1 to 1\n",
    "- `.predict`: performs the classification, equivalent to decision_function with a 0 threshold\n",
    "- `.predict_proba`: predict class probabilities for X. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, accuracy_score, recall_score\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "def gridsearch_wrapper(X, y, param_grid, k=5, n_jobs=6):\n",
    "    \"\"\"\n",
    "    Performs a grid search with\n",
    "    Args:\n",
    "        X: numeric matrix\n",
    "        y: target variable\n",
    "        k: number of CV folds\n",
    "        n_jobs: number of logical cores\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "\n",
    "    # split into training and validation sets\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, \n",
    "                                                      y, \n",
    "                                                      stratify=y,\n",
    "                                                      random_state=42)\n",
    "\n",
    "    # setup scorers\n",
    "    scorers = {\n",
    "        'acc': make_scorer(accuracy_score),\n",
    "        'tpr': make_scorer(recall_score, pos_label=1), # sensitivity, recall\n",
    "        'tnr': make_scorer(recall_score, pos_label=0) # specificity, selectivity\n",
    "    }\n",
    "\n",
    "    # instantiate estimator\n",
    "    clf =  AdaBoostClassifier(random_state=42)\n",
    "\n",
    "    # instantiate k-fold gridsearch\n",
    "    cv_folds = StratifiedKFold(n_splits=k)\n",
    "    \n",
    "    grid_search_clf = GridSearchCV(clf, \n",
    "                                   param_grid,\n",
    "                                   scoring=scorers, \n",
    "                                   refit='tpr', \n",
    "                                   cv=cv_folds, \n",
    "                                   return_train_score=True, \n",
    "                                   n_jobs=n_jobs,\n",
    "                                   verbose=1)\n",
    "    \n",
    "    # train models\n",
    "    grid_search_clf.fit(X_train, y_train)\n",
    "\n",
    "    # predict\n",
    "    y_pred = grid_search_clf.predict(X_val)\n",
    "    print(f'Best params: {grid_search_clf.best_params_}')\n",
    "\n",
    "    # eval metrics\n",
    "    print('Evaluation metrics:')\n",
    "    eval_clf(y_val, y_pred)\n",
    "    \n",
    "    return grid_search_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_params = {\n",
    "    'n_estimators': [10, 25, 50, 100],\n",
    "    'learning_rate': [.01, .1, 1]  \n",
    "}\n",
    "\n",
    "full_params = {\n",
    "    'n_estimators': [10, 25, 50, 100, 250, 500],\n",
    "    'learning_rate': [.001, .01, .1, 10, 100]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed: 29.8min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed: 35.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'learning_rate': 0.001, 'n_estimators': 10}\n",
      "Evaluation metrics:\n",
      "          pred_neg  pred_pos\n",
      "cond_neg       839         7\n",
      "cond_pos         2       127\n",
      "acc: 0.9908\n",
      "tpr: 0.9845\n",
      "tnr: 0.9917\n"
     ]
    }
   ],
   "source": [
    "grid_search_clf = gridsearch_wrapper(X_tfidf_svd800_spamcos, \n",
    "                                     y, \n",
    "                                     full_params, # only change in this notebook\n",
    "                                     k=10, \n",
    "                                     n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data\\\\3_modeling\\\\02062021_ada_gridsearch.joblib']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# persist\n",
    "save_path = os.path.join(\"data\", \"3_modeling\", \"02062021_ada_gridsearch.joblib\")\n",
    "joblib.dump(grid_search_clf, save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_df(gd):\n",
    "    gd_res = gd.cv_results_\n",
    "    df = pd.concat([\n",
    "                    pd.DataFrame(gd_res[\"params\"]),\n",
    "                    pd.DataFrame(gd_res[\"mean_test_acc\"], columns=[\"mean_val_acc\"]),\n",
    "                    pd.DataFrame(gd_res[\"mean_test_tpr\"], columns=[\"mean_val_tpr\"]),\n",
    "                    pd.DataFrame(gd_res[\"mean_test_tnr\"], columns=[\"mean_val_tnr\"]),\n",
    "                    pd.DataFrame(gd_res[\"mean_fit_time\"], columns=[\"mean_fit_time\"]),\n",
    "                    pd.DataFrame(gd_res[\"std_test_acc\"], columns=[\"std_val_acc\"]),\n",
    "                    pd.DataFrame(gd_res[\"std_test_tpr\"], columns=[\"std_val_tpr\"]),\n",
    "                    pd.DataFrame(gd_res[\"std_test_tnr\"], columns=[\"std_val_tnr\"]),\n",
    "                   ]\n",
    "                   , axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>mean_val_acc</th>\n",
       "      <th>mean_val_tpr</th>\n",
       "      <th>mean_val_tnr</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_val_acc</th>\n",
       "      <th>std_val_tpr</th>\n",
       "      <th>std_val_tnr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>10</td>\n",
       "      <td>0.993157</td>\n",
       "      <td>0.969096</td>\n",
       "      <td>0.996849</td>\n",
       "      <td>6.754271</td>\n",
       "      <td>0.004055</td>\n",
       "      <td>0.025236</td>\n",
       "      <td>0.003858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001</td>\n",
       "      <td>25</td>\n",
       "      <td>0.993157</td>\n",
       "      <td>0.969096</td>\n",
       "      <td>0.996849</td>\n",
       "      <td>14.475300</td>\n",
       "      <td>0.004055</td>\n",
       "      <td>0.025236</td>\n",
       "      <td>0.003858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001</td>\n",
       "      <td>50</td>\n",
       "      <td>0.993157</td>\n",
       "      <td>0.969096</td>\n",
       "      <td>0.996849</td>\n",
       "      <td>22.211141</td>\n",
       "      <td>0.004055</td>\n",
       "      <td>0.025236</td>\n",
       "      <td>0.003858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001</td>\n",
       "      <td>100</td>\n",
       "      <td>0.993157</td>\n",
       "      <td>0.969096</td>\n",
       "      <td>0.996849</td>\n",
       "      <td>49.560276</td>\n",
       "      <td>0.004055</td>\n",
       "      <td>0.025236</td>\n",
       "      <td>0.003858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001</td>\n",
       "      <td>250</td>\n",
       "      <td>0.993157</td>\n",
       "      <td>0.969096</td>\n",
       "      <td>0.996849</td>\n",
       "      <td>124.449003</td>\n",
       "      <td>0.004055</td>\n",
       "      <td>0.025236</td>\n",
       "      <td>0.003858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.001</td>\n",
       "      <td>500</td>\n",
       "      <td>0.993157</td>\n",
       "      <td>0.969096</td>\n",
       "      <td>0.996849</td>\n",
       "      <td>249.589529</td>\n",
       "      <td>0.004055</td>\n",
       "      <td>0.025236</td>\n",
       "      <td>0.003858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.010</td>\n",
       "      <td>10</td>\n",
       "      <td>0.993157</td>\n",
       "      <td>0.969096</td>\n",
       "      <td>0.996849</td>\n",
       "      <td>5.065993</td>\n",
       "      <td>0.004055</td>\n",
       "      <td>0.025236</td>\n",
       "      <td>0.003858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.010</td>\n",
       "      <td>25</td>\n",
       "      <td>0.993157</td>\n",
       "      <td>0.969096</td>\n",
       "      <td>0.996849</td>\n",
       "      <td>12.545388</td>\n",
       "      <td>0.004055</td>\n",
       "      <td>0.025236</td>\n",
       "      <td>0.003858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.010</td>\n",
       "      <td>50</td>\n",
       "      <td>0.993157</td>\n",
       "      <td>0.969096</td>\n",
       "      <td>0.996849</td>\n",
       "      <td>25.127611</td>\n",
       "      <td>0.004055</td>\n",
       "      <td>0.025236</td>\n",
       "      <td>0.003858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.010</td>\n",
       "      <td>100</td>\n",
       "      <td>0.993157</td>\n",
       "      <td>0.969096</td>\n",
       "      <td>0.996849</td>\n",
       "      <td>49.912503</td>\n",
       "      <td>0.004055</td>\n",
       "      <td>0.025236</td>\n",
       "      <td>0.003858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.100</td>\n",
       "      <td>10</td>\n",
       "      <td>0.993157</td>\n",
       "      <td>0.969096</td>\n",
       "      <td>0.996847</td>\n",
       "      <td>5.114630</td>\n",
       "      <td>0.004055</td>\n",
       "      <td>0.022480</td>\n",
       "      <td>0.003858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>10.000</td>\n",
       "      <td>25</td>\n",
       "      <td>0.991448</td>\n",
       "      <td>0.966532</td>\n",
       "      <td>0.995274</td>\n",
       "      <td>11.191849</td>\n",
       "      <td>0.004401</td>\n",
       "      <td>0.025730</td>\n",
       "      <td>0.005223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.010</td>\n",
       "      <td>500</td>\n",
       "      <td>0.993155</td>\n",
       "      <td>0.966532</td>\n",
       "      <td>0.997241</td>\n",
       "      <td>251.214402</td>\n",
       "      <td>0.004845</td>\n",
       "      <td>0.025866</td>\n",
       "      <td>0.003958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.010</td>\n",
       "      <td>250</td>\n",
       "      <td>0.993840</td>\n",
       "      <td>0.966532</td>\n",
       "      <td>0.998030</td>\n",
       "      <td>125.536131</td>\n",
       "      <td>0.004279</td>\n",
       "      <td>0.025866</td>\n",
       "      <td>0.003175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.100</td>\n",
       "      <td>25</td>\n",
       "      <td>0.993498</td>\n",
       "      <td>0.966532</td>\n",
       "      <td>0.997636</td>\n",
       "      <td>12.530864</td>\n",
       "      <td>0.004453</td>\n",
       "      <td>0.025866</td>\n",
       "      <td>0.004016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.100</td>\n",
       "      <td>50</td>\n",
       "      <td>0.993155</td>\n",
       "      <td>0.966532</td>\n",
       "      <td>0.997241</td>\n",
       "      <td>25.351042</td>\n",
       "      <td>0.004845</td>\n",
       "      <td>0.025866</td>\n",
       "      <td>0.003958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.100</td>\n",
       "      <td>100</td>\n",
       "      <td>0.993498</td>\n",
       "      <td>0.966532</td>\n",
       "      <td>0.997636</td>\n",
       "      <td>50.422332</td>\n",
       "      <td>0.004453</td>\n",
       "      <td>0.025866</td>\n",
       "      <td>0.004016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.100</td>\n",
       "      <td>250</td>\n",
       "      <td>0.993840</td>\n",
       "      <td>0.966532</td>\n",
       "      <td>0.998030</td>\n",
       "      <td>126.287881</td>\n",
       "      <td>0.004279</td>\n",
       "      <td>0.025866</td>\n",
       "      <td>0.003175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.100</td>\n",
       "      <td>500</td>\n",
       "      <td>0.993499</td>\n",
       "      <td>0.966532</td>\n",
       "      <td>0.997636</td>\n",
       "      <td>253.932929</td>\n",
       "      <td>0.004181</td>\n",
       "      <td>0.025866</td>\n",
       "      <td>0.003150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>10.000</td>\n",
       "      <td>50</td>\n",
       "      <td>0.853866</td>\n",
       "      <td>0.726518</td>\n",
       "      <td>0.873428</td>\n",
       "      <td>14.928625</td>\n",
       "      <td>0.173861</td>\n",
       "      <td>0.320582</td>\n",
       "      <td>0.199838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>10.000</td>\n",
       "      <td>100</td>\n",
       "      <td>0.852501</td>\n",
       "      <td>0.726518</td>\n",
       "      <td>0.871853</td>\n",
       "      <td>21.269108</td>\n",
       "      <td>0.172920</td>\n",
       "      <td>0.320582</td>\n",
       "      <td>0.199018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>10.000</td>\n",
       "      <td>250</td>\n",
       "      <td>0.852501</td>\n",
       "      <td>0.726518</td>\n",
       "      <td>0.871853</td>\n",
       "      <td>41.225398</td>\n",
       "      <td>0.172920</td>\n",
       "      <td>0.320582</td>\n",
       "      <td>0.199018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>10.000</td>\n",
       "      <td>500</td>\n",
       "      <td>0.852501</td>\n",
       "      <td>0.726518</td>\n",
       "      <td>0.871853</td>\n",
       "      <td>70.467420</td>\n",
       "      <td>0.172920</td>\n",
       "      <td>0.320582</td>\n",
       "      <td>0.199018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>10.000</td>\n",
       "      <td>10</td>\n",
       "      <td>0.634431</td>\n",
       "      <td>0.558232</td>\n",
       "      <td>0.646396</td>\n",
       "      <td>5.028501</td>\n",
       "      <td>0.163783</td>\n",
       "      <td>0.227337</td>\n",
       "      <td>0.204444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>100.000</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.934155</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>100.000</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.904474</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>100.000</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.902912</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>100.000</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.889093</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>100.000</td>\n",
       "      <td>250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.871008</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>100.000</td>\n",
       "      <td>500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.870108</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    learning_rate  n_estimators  mean_val_acc  mean_val_tpr  mean_val_tnr  \\\n",
       "0           0.001            10      0.993157      0.969096      0.996849   \n",
       "1           0.001            25      0.993157      0.969096      0.996849   \n",
       "2           0.001            50      0.993157      0.969096      0.996849   \n",
       "3           0.001           100      0.993157      0.969096      0.996849   \n",
       "4           0.001           250      0.993157      0.969096      0.996849   \n",
       "5           0.001           500      0.993157      0.969096      0.996849   \n",
       "6           0.010            10      0.993157      0.969096      0.996849   \n",
       "7           0.010            25      0.993157      0.969096      0.996849   \n",
       "8           0.010            50      0.993157      0.969096      0.996849   \n",
       "9           0.010           100      0.993157      0.969096      0.996849   \n",
       "12          0.100            10      0.993157      0.969096      0.996847   \n",
       "19         10.000            25      0.991448      0.966532      0.995274   \n",
       "11          0.010           500      0.993155      0.966532      0.997241   \n",
       "10          0.010           250      0.993840      0.966532      0.998030   \n",
       "13          0.100            25      0.993498      0.966532      0.997636   \n",
       "14          0.100            50      0.993155      0.966532      0.997241   \n",
       "15          0.100           100      0.993498      0.966532      0.997636   \n",
       "16          0.100           250      0.993840      0.966532      0.998030   \n",
       "17          0.100           500      0.993499      0.966532      0.997636   \n",
       "20         10.000            50      0.853866      0.726518      0.873428   \n",
       "21         10.000           100      0.852501      0.726518      0.871853   \n",
       "22         10.000           250      0.852501      0.726518      0.871853   \n",
       "23         10.000           500      0.852501      0.726518      0.871853   \n",
       "18         10.000            10      0.634431      0.558232      0.646396   \n",
       "24        100.000            10           NaN           NaN           NaN   \n",
       "25        100.000            25           NaN           NaN           NaN   \n",
       "26        100.000            50           NaN           NaN           NaN   \n",
       "27        100.000           100           NaN           NaN           NaN   \n",
       "28        100.000           250           NaN           NaN           NaN   \n",
       "29        100.000           500           NaN           NaN           NaN   \n",
       "\n",
       "    mean_fit_time  std_val_acc  std_val_tpr  std_val_tnr  \n",
       "0        6.754271     0.004055     0.025236     0.003858  \n",
       "1       14.475300     0.004055     0.025236     0.003858  \n",
       "2       22.211141     0.004055     0.025236     0.003858  \n",
       "3       49.560276     0.004055     0.025236     0.003858  \n",
       "4      124.449003     0.004055     0.025236     0.003858  \n",
       "5      249.589529     0.004055     0.025236     0.003858  \n",
       "6        5.065993     0.004055     0.025236     0.003858  \n",
       "7       12.545388     0.004055     0.025236     0.003858  \n",
       "8       25.127611     0.004055     0.025236     0.003858  \n",
       "9       49.912503     0.004055     0.025236     0.003858  \n",
       "12       5.114630     0.004055     0.022480     0.003858  \n",
       "19      11.191849     0.004401     0.025730     0.005223  \n",
       "11     251.214402     0.004845     0.025866     0.003958  \n",
       "10     125.536131     0.004279     0.025866     0.003175  \n",
       "13      12.530864     0.004453     0.025866     0.004016  \n",
       "14      25.351042     0.004845     0.025866     0.003958  \n",
       "15      50.422332     0.004453     0.025866     0.004016  \n",
       "16     126.287881     0.004279     0.025866     0.003175  \n",
       "17     253.932929     0.004181     0.025866     0.003150  \n",
       "20      14.928625     0.173861     0.320582     0.199838  \n",
       "21      21.269108     0.172920     0.320582     0.199018  \n",
       "22      41.225398     0.172920     0.320582     0.199018  \n",
       "23      70.467420     0.172920     0.320582     0.199018  \n",
       "18       5.028501     0.163783     0.227337     0.204444  \n",
       "24       0.934155          NaN          NaN          NaN  \n",
       "25       0.904474          NaN          NaN          NaN  \n",
       "26       0.902912          NaN          NaN          NaN  \n",
       "27       0.889093          NaN          NaN          NaN  \n",
       "28       0.871008          NaN          NaN          NaN  \n",
       "29       0.870108          NaN          NaN          NaN  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = extract_df(grid_search_clf)\n",
    "df.sort_values(by=['mean_val_tpr'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "\n",
    "rnd_clf = RandomForestClassifier(\n",
    "    n_jobs=-1\n",
    "    , random_state=42\n",
    "    , max_depth=8\n",
    "    , max_features=150\n",
    "    , min_samples_split=3\n",
    "    , n_estimators=100)\n",
    "\n",
    "ada_clf =  AdaBoostClassifier(\n",
    "    base_estimator=DecisionTreeClassifier()\n",
    "    , algorithm='SAMME.R'\n",
    "    , n_estimators=10\n",
    "    , learning_rate=0.001\n",
    "    , random_state=42)\n",
    "\n",
    "vot_clf_soft = VotingClassifier(\n",
    "    estimators=[('rnd', rnd_clf), ('ada', ada_clf)]\n",
    "    , voting='soft'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quick_eval(classifiers):\n",
    "    for clf in classifiers:\n",
    "        T1 = time.time()\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_val)\n",
    "        mins, secs = divmod(time.time() - T1, 60)\n",
    "        print(clf.__class__, 'acc', round(accuracy_score(y_val, y_pred), 4))\n",
    "        print(clf.__class__, 'tpr', round(recall_score(y_val, y_pred, pos_label=1) , 4))\n",
    "        print(clf.__class__, 'tnr', round(recall_score(y_val, y_pred, pos_label=0), 4))\n",
    "        print(f'{clf.__class__} - train time: {mins:0.0f}m {secs:0.0f}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> acc 0.9928\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> tpr 0.969\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> tnr 0.9965\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> - train time: 0m 4s\n",
      "<class 'sklearn.ensemble._weight_boosting.AdaBoostClassifier'> acc 0.9897\n",
      "<class 'sklearn.ensemble._weight_boosting.AdaBoostClassifier'> tpr 0.9767\n",
      "<class 'sklearn.ensemble._weight_boosting.AdaBoostClassifier'> tnr 0.9917\n",
      "<class 'sklearn.ensemble._weight_boosting.AdaBoostClassifier'> - train time: 0m 1s\n",
      "<class 'sklearn.ensemble._voting.VotingClassifier'> acc 0.9897\n",
      "<class 'sklearn.ensemble._voting.VotingClassifier'> tpr 0.9767\n",
      "<class 'sklearn.ensemble._voting.VotingClassifier'> tnr 0.9917\n",
      "<class 'sklearn.ensemble._voting.VotingClassifier'> - train time: 0m 7s\n"
     ]
    }
   ],
   "source": [
    "quick_eval([rnd_clf, ada_clf, vot_clf_soft])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voting doesn't appear to improve AdaBoost just compare it against RandomForest... and takes longer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
