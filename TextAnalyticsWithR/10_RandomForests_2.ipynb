{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forests 2\n",
    "\n",
    "---\n",
    "\n",
    "__This Notebook__:\n",
    "\n",
    "Shallow gridsearch on all 12 representations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Revised on: 2021-01-03\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "import matplotlib.pyplot as plt \n",
    "plt.style.use(\"ggplot\")\n",
    "\n",
    "from datetime import datetime\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import roc_curve, precision_recall_curve, auc, make_scorer\n",
    "from sklearn.metrics import recall_score, accuracy_score, precision_score, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "dt_object = datetime.fromtimestamp(time.time())\n",
    "day, T = str(dt_object).split('.')[0].split(' ')\n",
    "print('Revised on: ' + day)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load target\n",
    "raw_path = os.path.join(\"data\",\"1_raw\")\n",
    "filename = \"y_train.csv\"\n",
    "y = pd.read_csv(os.path.join(raw_path, filename))\n",
    "y = np.array(y.iloc[:,0].ravel())\n",
    "y[y=='ham'] = 0\n",
    "y[y=='spam'] = 1\n",
    "y = y.astype('int')\n",
    "\n",
    "# load 12 matrices\n",
    "proc_dir = os.path.join(\"data\",\"2_processed\")\n",
    "Xnames = [x for x in os.listdir(proc_dir) if re.search('.npz', x)]\n",
    "Xs = []\n",
    "for ix, X in enumerate(Xnames):\n",
    "    path_ = os.path.join(proc_dir, Xnames[ix])\n",
    "    Xs.append(sp.load_npz(path_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 X_bot\n",
      "2 X_bot_feat\n",
      "3 X_bot_svd\n",
      "4 X_bot_svd_cos\n",
      "5 X_bot_svd_feat\n",
      "6 X_bot_svd_feat_cos\n",
      "7 X_bot_tfidf\n",
      "8 X_bot_tfidf_feat\n",
      "9 X_bot_tfidf_svd\n",
      "10 X_bot_tfidf_svd_cos\n",
      "11 X_bot_tfidf_svd_feat\n",
      "12 X_bot_tfidf_svd_feat_cos\n"
     ]
    }
   ],
   "source": [
    "# 12 representations\n",
    "for ix, Xname in enumerate(Xnames):\n",
    "    Xname = Xname.split('.')[0]\n",
    "    print(ix+1, Xname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid search random forest models\n",
    "\n",
    "Using sklearn's GridSearchCV with 10-fold cross validation on a shallow param grid, varying representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_eval_metrics(y_val, y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_val, y_pred).ravel()\n",
    "    acc = (tp + tn) / (tp + tn + fp + fn)\n",
    "    tpr = tp / (tp + fn)\n",
    "    tnr = tn / (tn + fp)\n",
    "    print(f'accuracy: {acc:0.4f}')\n",
    "    print(f'sensitivity: {tpr:0.4f}')\n",
    "    print(f'specificity: {tnr:0.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training 1: X_bot...\n"
     ]
    }
   ],
   "source": [
    "# instantiate list of dicts to gather results\n",
    "gridsearches = []\n",
    "for ix, X_name in enumerate(Xnames):\n",
    "    \n",
    "    X_ = Xs[ix].toarray()\n",
    "    X_name = X_name.split('.')[0]\n",
    "        \n",
    "    # split into training and validation sets\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_, y, stratify=y)\n",
    "\n",
    "    # setup shallow param grid\n",
    "    param_grid = {\n",
    "        'min_samples_split': [5, 10, 15], \n",
    "        'n_estimators' : [100, 200],\n",
    "        'max_depth': [5, 10, 20],\n",
    "        'max_features': [50, 100, 250]\n",
    "    }\n",
    "\n",
    "    # setup scorers\n",
    "    scorers = {\n",
    "        'acc': make_scorer(accuracy_score),\n",
    "        'tpr': make_scorer(recall_score, pos_label=1), # sensitivity, recall\n",
    "        'tnr': make_scorer(recall_score, pos_label=0) # specificity, selectivity\n",
    "    }\n",
    "    \n",
    "    # instantiate estimator\n",
    "    clf = RandomForestClassifier(n_jobs=-1, random_state=42)\n",
    "\n",
    "    # instantiate 10-fold gridsearch\n",
    "    cv_folds = StratifiedKFold(n_splits=10)\n",
    "    grid_search_clf = GridSearchCV(clf, param_grid, scoring=scorers, refit='tpr', \n",
    "                                   cv=cv_folds, return_train_score=True, n_jobs=-1)\n",
    "\n",
    "    # train models\n",
    "    print(f'\\nTraining {ix+1}: {X_name}...')\n",
    "    start_gs = time.time()\n",
    "    grid_search_clf.fit(X_train, y_train)\n",
    "    elapsed_secs = time.time() - start_gs\n",
    "    print(f'Elapsed: {elapsed_secs:0.0f} s')\n",
    "    \n",
    "    # predict\n",
    "    y_pred = grid_search_clf.predict(X_val)\n",
    "    print(f'Best params: {grid_search_clf.best_params_}')\n",
    "    \n",
    "    # confusion matrix on validation set\n",
    "    print(f'Confusion matrix on validation set:')\n",
    "    print(pd.DataFrame(confusion_matrix(y_val, y_pred),\n",
    "                       columns=['pred_neg', 'pred_pos'],\n",
    "                       index=['neg', 'pos']))\n",
    "    # eval metrics\n",
    "    print('Evaluation metrics:')\n",
    "    print_eval_metrics(y_val, y_pred)\n",
    "    \n",
    "    # gather results into a list of dicts\n",
    "    data = {'representation':X_name,\n",
    "            'gridsearch_res':grid_search_clf}\n",
    "    \n",
    "    gridsearches.append(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Persist results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data\\\\3_modeling\\\\01032020_rf_gridsearches_shallowparams.joblib']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "model_dir = os.path.join(\"data\", \"3_modeling\")\n",
    "file_path = os.path.join(model_dir, \"01032020_rf_gridsearches_shallowparams.joblib\")\n",
    "\n",
    "joblib.dump(gridsearches, file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
