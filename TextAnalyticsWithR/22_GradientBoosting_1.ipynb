{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting Classifier\n",
    "\n",
    "---\n",
    "\n",
    "__This Notebook__\n",
    "\n",
    "- implement sklearn.ensemble.GradientBoostingClassifier\n",
    "\n",
    "__Results__ \n",
    "\n",
    "- \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Revised on: 2021-02-09\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "import time\n",
    "import joblib \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "dt_object = datetime.fromtimestamp(time.time())\n",
    "day, T = str(dt_object).split('.')[0].split(' ')\n",
    "print('Revised on: ' + day)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load target vector\n",
    "raw_path = os.path.join(\"data\",\"1_raw\")\n",
    "y_df = pd.read_csv(os.path.join(raw_path, 'y_train.csv'))\n",
    "y_array = np.array(y_df.iloc[:,0].ravel())\n",
    "\n",
    "y = y_array.copy()\n",
    "\n",
    "# transform y_array into int type\n",
    "y[y=='ham'] = 0\n",
    "y[y=='spam'] = 1\n",
    "y = y.astype('int')\n",
    "\n",
    "# load matrix\n",
    "proc_dir = os.path.join(\"data\", \"2_processed\")\n",
    "X_tfidf_svd800_spamcos = sp.load_npz(os.path.join(proc_dir, 'X_tfidf_svd800_spamcos.npz'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helpful Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train classifier and time it\n",
    "def time_deco(func):\n",
    "    def wrapper(clf):\n",
    "        start = time.time()\n",
    "        func(clf)\n",
    "        m,s = divmod(time.time() - start, 60)\n",
    "        print(f'Elapsed: {m:0.0f}m {s:0.0f}s')\n",
    "    return wrapper\n",
    "\n",
    "@time_deco\n",
    "def fit_clf(clf):\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "# evaluate classifier\n",
    "def eval_clf(y_val, y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_val, \n",
    "                                      y_pred).ravel()\n",
    "    confmat_df = pd.DataFrame(\n",
    "        np.array(([tn, fp], [fn, tp])),\n",
    "        columns=['pred_neg', 'pred_pos'], \n",
    "        index=['cond_neg', 'cond_pos']\n",
    "    )\n",
    "    # unpack metrics\n",
    "    acc = (tp + tn) / (tp + tn + fp + fn)\n",
    "    tpr = tp / (tp + fn)\n",
    "    tnr = tn / (tn + fp)\n",
    "    # print results\n",
    "    print(confmat_df)\n",
    "    print(f'acc: {acc:0.4f}')\n",
    "    print(f'tpr: {tpr:0.4f}')\n",
    "    print(f'tnr: {tnr:0.4f}')\n",
    "\n",
    "def extract_df(gd):\n",
    "    gd_res = gd.cv_results_\n",
    "    df = pd.concat([\n",
    "                    pd.DataFrame(gd_res[\"params\"]),\n",
    "                    pd.DataFrame(gd_res[\"mean_train_acc\"], columns=[\"mean_train_acc\"]),\n",
    "                    pd.DataFrame(gd_res[\"mean_train_tpr\"], columns=[\"mean_train_tpr\"]),\n",
    "                    pd.DataFrame(gd_res[\"mean_train_tnr\"], columns=[\"mean_train_tnr\"]),\n",
    "                    pd.DataFrame(gd_res[\"mean_test_acc\"], columns=[\"mean_val_acc\"]),\n",
    "                    pd.DataFrame(gd_res[\"mean_test_tpr\"], columns=[\"mean_val_tpr\"]),\n",
    "                    pd.DataFrame(gd_res[\"mean_test_tnr\"], columns=[\"mean_val_tnr\"]),\n",
    "                    pd.DataFrame(gd_res[\"mean_fit_time\"], columns=[\"mean_fit_time\"])\n",
    "                    #pd.DataFrame(gd_res[\"std_test_acc\"], columns=[\"std_val_acc\"]),\n",
    "                    #pd.DataFrame(gd_res[\"std_test_tpr\"], columns=[\"std_val_tpr\"]),\n",
    "                    #pd.DataFrame(gd_res[\"std_test_tnr\"], columns=[\"std_val_tnr\"]),\n",
    "                   ]\n",
    "                   , axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Gradient Boosting Classifier\n",
    "\n",
    "\n",
    "```\n",
    "class GradientBoostingClassifier(ClassifierMixin, BaseGradientBoosting):\n",
    "    \"\"\"Gradient Boosting for classification.\n",
    "    GB builds an additive model in a\n",
    "    forward stage-wise fashion; it allows for the optimization of\n",
    "    arbitrary differentiable loss functions. In each stage ``n_classes_``\n",
    "    regression trees are fit on the negative gradient of the\n",
    "    binomial or multinomial deviance loss function. Binary classification\n",
    "    is a special case where only a single regression tree is induced.\n",
    "```\n",
    "\n",
    "See [docs](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html), [code](https://github.com/scikit-learn/scikit-learn/blob/95119c13a/sklearn/ensemble/_gb.py#L768)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Some defaults:__\n",
    "\n",
    "\n",
    "- `loss='deviance'`\n",
    "- `learning_rate=0.1`\n",
    "- `n_estimators=100`\n",
    "- `subsample=1.0`\n",
    "- `criterion='friedman_mse'`\n",
    "- `min_samples_split=2`\n",
    "- `min_samples_leaf=1`\n",
    "- `min_weight_fraction_leaf=0.0`\n",
    "- `max_depth=3`\n",
    "- `min_impurity_decrease=0.0`\n",
    "- `min_impurity_split=None`\n",
    "- `init=None`\n",
    "- `random_state=None`\n",
    "- `max_features=None`\n",
    "- `verbose=0`\n",
    "- `max_leaf_nodes=None`\n",
    "- `warm_start=False`\n",
    "- `validation_fraction=0.1`\n",
    "- `n_iter_no_change=None`\n",
    "- `tol=0.0001`\n",
    "- `ccp_alpha=0.0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, accuracy_score, recall_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_tfidf_svd800_spamcos,\n",
    "                                                  y, \n",
    "                                                  stratify=y,\n",
    "                                                  random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_clf = GradientBoostingClassifier(\n",
    "    random_state=42\n",
    "    , verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.5988            2.47m\n",
      "         2           0.5007            2.40m\n",
      "         3           0.4298            2.37m\n",
      "         4           0.3746            2.35m\n",
      "         5           0.3297            2.32m\n",
      "         6           0.2921            2.29m\n",
      "         7           0.2597            2.26m\n",
      "         8           0.2322            2.24m\n",
      "         9           0.2079            2.21m\n",
      "        10           0.1869            2.19m\n",
      "        20           0.0696            1.94m\n",
      "        30           0.0285            1.71m\n",
      "        40           0.0138            1.46m\n",
      "        50           0.0078            1.21m\n",
      "        60           0.0054           58.15s\n",
      "        70           0.0044           43.73s\n",
      "        80           0.0036           29.05s\n",
      "        90           0.0031           14.48s\n",
      "       100           0.0026            0.00s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(random_state=42, verbose=1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# evaluate using decision function\n",
    "y_score = gb_clf.decision_function(X_val)\n",
    "plt.plot(sorted(y_score))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          pred_neg  pred_pos\n",
      "cond_neg       842         4\n",
      "cond_pos         2       127\n",
      "acc: 0.9938\n",
      "tpr: 0.9845\n",
      "tnr: 0.9953\n"
     ]
    }
   ],
   "source": [
    "# default threshold\n",
    "thresh = 0\n",
    "y_pred = np.where(y_score > thresh, 1, 0)\n",
    "eval_clf(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAD4CAYAAAAJmJb0AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAQZ0lEQVR4nO3df4xlZ13H8ffHXVqBFlvo0pTdll3MFt0/+NGOpfgDqqB0i3El8Y8WsdBANk2oQf1DSogag/8gagihsNnUyg+VxkADa7NYjT/gDyx2q1C6LS1DC+2w1U5FEUtiWfj6xz3AvffM7pyZvdvZeeb9Sm7mnnOeO/N97rafeeZ5zrknVYUkqU0/tNYFSJJOHkNekhpmyEtSwwx5SWqYIS9JDdu8Vj/4nHPOqe3bt6/Vj5ekdenOO+98rKq2DG2/ZiG/fft2Dh06tFY/XpLWpSRfXUl7p2skqWGGvCQ1zJCXpIYZ8pLUMENekhq2bMgnuSnJo0nuPsbxJHlPkvkkdyW5aPZlSpJWY8hI/gPA5cc5vhvY2T32Au8/8bIkSbOw7HnyVfXpJNuP02QP8KEafWbx7UnOSnJeVT0yqyIlaYj5R/+XA58/Aqf4R6jPbX8mL7tw8PVMJ2QWF0NtBR4e217o9vVCPsleRqN9Lrjgghn8aEn6gQ9+5it8+Pavkqx1Jcd37ct/dF2F/FJv55K/RqtqP7AfYG5u7tT+VStp3flOFVvOPJ073v7KtS7llDGLs2sWgPPHtrcBR2bwfSVpRU7xWZo1MYuQPwBc3Z1lcynwDefjJenUsOx0TZKPAJcB5yRZAH4PeApAVe0DDgJXAPPAt4BrTlaxkrScU3w6/kk35Oyaq5Y5XsCbZ1aRJK2a8zXTvOJVUlNO9TNrnmyGvKRmuPDaZ8hLUsMMeUlNiUuvEwx5Sc1wuqbPkJfUFBdeJxnykppRnkLZY8hLUsMMeUlNcbZmkiEvqRkuvPYZ8pKaEldeJxjykprhQL7PkJekhhnykprhnHyfIS9JDTPkJTXFdddJhrykZnjFa58hL0kNM+QltaOcrplmyEtSwwx5SU3xpiGTDHlJzXDZtc+Ql6SGGfKSmlFVLrxOMeQlqWGGvKSmOJCfZMhLaoYLr32GvCQ1zJCX1Iwq7ww1zZCXpIYZ8pKa4jh+0qCQT3J5kvuSzCe5fonjP5Lkr5N8PsnhJNfMvlRJOj4XXvuWDfkkm4AbgN3ALuCqJLummr0ZuKeqXghcBvxxktNmXKskaYWGjOQvAear6oGqegK4Gdgz1aaAMzNa8TgD+DpwdKaVStIyqsr5milDQn4r8PDY9kK3b9x7gR8HjgBfAN5SVd+d/kZJ9iY5lOTQ4uLiKkuWJA01JOSX+r04PfX1KuBzwHOAFwHvTfKM3ouq9lfVXFXNbdmyZYWlStLyHMhPGhLyC8D5Y9vbGI3Yx10D3FIj88CDwI/NpkRJGsaF174hIX8HsDPJjm4x9UrgwFSbh4BXACQ5F3g+8MAsC5Ukrdzm5RpU1dEk1wG3AZuAm6rqcJJru+P7gHcAH0jyBUZ/Lb21qh47iXVLUp9XvPYsG/IAVXUQODi1b9/Y8yPAL8y2NEnSifKKV0lNcRw/yZCX1Ixy6bXHkJekhhnykpox+qjhta7i1GLIS1LDDHlJzRh9dI1D+XGGvCQ1zJCXpIYZ8pKaUZQLr1MMeUlqmCEvqRnltVA9hrwkNcyQl6SGGfKSmlH4UcPTDHlJapghL6kZoyteNc6Ql6SGGfKS1DBDXlJDvOJ1miEvSQ0z5CU1w5uG9BnyktQwQ16SGmbIS2pG4Z2hphnyktQwQ15SM6o8hXKaIS9JDTPkJalhhrykZowWXjXOkJekhg0K+SSXJ7kvyXyS64/R5rIkn0tyOMmnZlumJC2vRncNWesyTimbl2uQZBNwA/DzwAJwR5IDVXXPWJuzgPcBl1fVQ0mefZLqlSStwJCR/CXAfFU9UFVPADcDe6bavBa4paoeAqiqR2dbpiRpNYaE/Fbg4bHthW7fuAuBs5P8U5I7k1y91DdKsjfJoSSHFhcXV1exJB2DC699Q0J+qfesprY3AxcDrwZeBfxOkgt7L6raX1VzVTW3ZcuWFRcrSVqZZefkGY3czx/b3gYcWaLNY1X1OPB4kk8DLwTun0mVkjSAV7z2DRnJ3wHsTLIjyWnAlcCBqTafAH4myeYkTwNeAtw721IlSSu17Ei+qo4muQ64DdgE3FRVh5Nc2x3fV1X3Jvkb4C7gu8CNVXX3ySxckrS8IdM1VNVB4ODUvn1T2+8C3jW70iRp5ZytmeQVr5LUMENeUjNG93h1LD/OkJekhhnykppRvUt4ZMhLaoqTNZMMeUlqmCEvqRmjhde1ruLUYshLUsMMeUnNKNddewx5SU2JS68TDHlJapghL6kZRXkO5RRDXpIaZshLaoYLr32GvKSmOFszyZCXpIYZ8pKaUXjF6zRDXpIaZshLaocLrz2GvKSmeMXrJENekhpmyEtqRlEuvE4x5CWpYYa8pGZ4xWufIS+pKU7XTDLkJalhhrykZhSeQjnNkJekhhnykppRrrz2GPKSmuLC6yRDXlIzHMf3DQr5JJcnuS/JfJLrj9PuJ5J8J8mvzK5ESdJqLRvySTYBNwC7gV3AVUl2HaPdO4HbZl2kJGl1hozkLwHmq+qBqnoCuBnYs0S7Xwc+Bjw6w/okaTDXXfuGhPxW4OGx7YVu3/cl2Qq8Bth3vG+UZG+SQ0kOLS4urrRWSVpWXHmdMCTkl3rHpn9fvht4a1V953jfqKr2V9VcVc1t2bJlYImSNIwD+b7NA9osAOePbW8Djky1mQNu7n6DngNckeRoVX18FkVK0lCO4ycNCfk7gJ1JdgBfA64EXjveoKp2fO95kg8AtxrwkrT2lg35qjqa5DpGZ81sAm6qqsNJru2OH3ceXpKeNK689gwZyVNVB4GDU/uWDPeqesOJlyVJq+O66ySveJXUDMfxfYa8pKY4kJ9kyEtSwwx5Sc1w3bXPkJfUFK94nWTIS2pGufTaY8hLaorj+EmGvCQ1zJCX1AwXXvsMeUlNcd11kiEvqRmO5PsMeUmNcSg/zpCXpIYZ8pKa4WxNnyEvqSkuvE4y5CU1o1x57THkJTXFgfwkQ16SGmbIS1LDDHlJTXHhdZIhL6kZrrv2GfKSmhKXXicY8pKa4U1D+gx5SWqYIS+pKS68TjLkJTXDhdc+Q15SUxzJTzLkJTXDgXyfIS9JDTPkJTXF8+QnDQr5JJcnuS/JfJLrlzj+q0nu6h6fSfLC2ZcqScfnRw33LRvySTYBNwC7gV3AVUl2TTV7EHh5Vb0AeAewf9aFStIgDuQnDBnJXwLMV9UDVfUEcDOwZ7xBVX2mqv6r27wd2DbbMiVpeY7j+4aE/Fbg4bHthW7fsbwR+ORSB5LsTXIoyaHFxcXhVUqSVmVIyC/1x8+SvzCT/CyjkH/rUseran9VzVXV3JYtW4ZXKUkDOVszafOANgvA+WPb24Aj042SvAC4EdhdVf85m/IkaQWcr+kZMpK/A9iZZEeS04ArgQPjDZJcANwC/FpV3T/7MiVpmHjJ64RlR/JVdTTJdcBtwCbgpqo6nOTa7vg+4HeBZwHv697go1U1d/LKlqQ+B/J9Q6ZrqKqDwMGpffvGnr8JeNNsS5MknSiveJXUFCdrJhnykprhFa99hrykprjuOsmQl9QMx/F9hrwkNcyQl9QUZ2smGfKSmuG6a58hL6kpXvE6yZCX1Ixy6bXHkJfUFMfxkwx5SWqYIS+pGS689hnyktrifM0EQ15SMxzJ9xnykpoSh/ITDHlJapghL0kNM+QlNcULXicZ8pKa4U1D+gx5SU1xID/JkJfUDMfxfYa8JDXMkJfUFBdeJxnykprhumufIS+pKV7xOsmQl9QMbxrSZ8hLUsMMeUlNceF1kiEvqRkuvPYZ8pKa4kh+kiEvqRkO5PsGhXySy5Pcl2Q+yfVLHE+S93TH70py0exLlSSt1LIhn2QTcAOwG9gFXJVk11Sz3cDO7rEXeP+M65SkgZyvGbd5QJtLgPmqegAgyc3AHuCesTZ7gA/V6HM+b09yVpLzquqRWRf8qfsX+YNb71m+oaQN5+uPP7HWJZxyhoT8VuDhse0F4CUD2mwFJkI+yV5GI30uuOCCldYKwBmnb2bnuWes6rWS2nbhuWfymhdvXesyTilDQn6pv32m1zeGtKGq9gP7Aebm5la1RnLxc8/m4udevJqXStKGM2ThdQE4f2x7G3BkFW0kSU+yISF/B7AzyY4kpwFXAgem2hwAru7OsrkU+MbJmI+XJK3MstM1VXU0yXXAbcAm4KaqOpzk2u74PuAgcAUwD3wLuObklSxJGmrInDxVdZBRkI/v2zf2vIA3z7Y0SdKJ8opXSWqYIS9JDTPkJalhhrwkNSy1Rh/AnGQR+OoqX34O8NgMy1lPNmrfN2q/YeP2faP2G47f9+dW1Zah32jNQv5EJDlUVXNrXcda2Kh936j9ho3b943ab5ht352ukaSGGfKS1LD1GvL717qANbRR+75R+w0bt+8btd8ww76vyzl5SdIw63UkL0kawJCXpIatu5Bf7qbi61mS85P8Y5J7kxxO8pZu/zOT/F2SL3Vfzx57zdu69+K+JK9au+pPXJJNSf4tya3d9kbp91lJPprki92//Us3Qt+T/Gb33/ndST6S5Idb7XeSm5I8muTusX0r7muSi5N8oTv2niTL39C2qtbNg9FHHX8ZeB5wGvB5YNda1zXD/p0HXNQ9PxO4n9HN0/8QuL7bfz3wzu75ru49OB3Y0b03m9a6HyfQ/98C/hK4tdveKP3+IPCm7vlpwFmt953R7UEfBJ7abf8V8IZW+w28DLgIuHts34r7CvwL8FJGd+P7JLB7uZ+93kby37+peFU9AXzvpuJNqKpHqupfu+ffBO5l9D/DHkZBQPf1l7vne4Cbq+r/qupBRp/nf8mTWvSMJNkGvBq4cWz3Ruj3MxgFwJ8CVNUTVfXfbIC+M/qo86cm2Qw8jdHd5Jrsd1V9Gvj61O4V9TXJecAzquqfa5T4Hxp7zTGtt5A/1g3Dm5NkO/Bi4LPAudXdaav7+uyuWUvvx7uB3wa+O7ZvI/T7ecAi8GfdVNWNSZ5O432vqq8BfwQ8BDzC6G5yf0vj/Z6y0r5u7Z5P7z+u9Rbyg24Yvt4lOQP4GPAbVfU/x2u6xL51934k+UXg0aq6c+hLlti37vrd2czoz/j3V9WLgccZ/el+LE30vZt/3sNoOuI5wNOTvO54L1li37rr90DH6uuq3oP1FvLN3zA8yVMYBfxfVNUt3e7/6P5Uo/v6aLe/lffjp4BfSvIVRlNwP5fkz2m/3zDqy0JVfbbb/iij0G+9768EHqyqxar6NnAL8JO03+9xK+3rQvd8ev9xrbeQH3JT8XWrWyn/U+DeqvqTsUMHgNd3z18PfGJs/5VJTk+yA9jJaGFmXamqt1XVtqrazujf9B+q6nU03m+Aqvp34OEkz+92vQK4h/b7/hBwaZKndf/dv4LRGlTr/R63or52UzrfTHJp955dPfaaY1vrVedVrFJfweisky8Db1/rembct59m9OfXXcDnuscVwLOAvwe+1H195thr3t69F/cxYKX9VH8Al/GDs2s2RL+BFwGHun/3jwNnb4S+A78PfBG4G/gwo7NJmuw38BFGaw/fZjQif+Nq+grMde/Xl4H30n1qwfEefqyBJDVsvU3XSJJWwJCXpIYZ8pLUMENekhpmyEtSwwx5SWqYIS9JDft/jlGTh76SPyAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = gb_clf.predict(X_val)\n",
    "plt.plot(sorted(y_pred))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          pred_neg  pred_pos\n",
      "cond_neg       842         4\n",
      "cond_pos         2       127\n",
      "acc: 0.9938\n",
      "tpr: 0.9845\n",
      "tnr: 0.9953\n"
     ]
    }
   ],
   "source": [
    "eval_clf(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, accuracy_score, recall_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "def gridsearch_wrapper(X, y, param_grid, k=5, n_jobs=6):\n",
    "    \"\"\"\n",
    "    Performs a grid search with\n",
    "    Args:\n",
    "        X: numeric matrix\n",
    "        y: target variable\n",
    "        param_grid : dict of hyperparameters for search\n",
    "        k: number of CV folds\n",
    "        n_jobs: number of logical cores\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "\n",
    "    # split into training and validation sets\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, \n",
    "                                                      y, \n",
    "                                                      stratify=y,\n",
    "                                                      random_state=42)\n",
    "\n",
    "    # setup scorers\n",
    "    scorers = {\n",
    "        'acc': make_scorer(accuracy_score),\n",
    "        'tpr': make_scorer(recall_score, pos_label=1), # sensitivity, recall\n",
    "        'tnr': make_scorer(recall_score, pos_label=0) # specificity, selectivity\n",
    "    }\n",
    "\n",
    "    # instantiate estimator\n",
    "    clf =  GradientBoostingClassifier(\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # instantiate k-fold gridsearch\n",
    "    cv_folds = StratifiedKFold(n_splits=k)\n",
    "    \n",
    "    grid_search_clf = GridSearchCV(clf, \n",
    "                                   param_grid,\n",
    "                                   scoring=scorers, \n",
    "                                   refit='tpr', \n",
    "                                   cv=cv_folds, \n",
    "                                   return_train_score=True, \n",
    "                                   n_jobs=n_jobs,\n",
    "                                   verbose=1)\n",
    "    \n",
    "    # train models\n",
    "    grid_search_clf.fit(X_train, y_train)\n",
    "\n",
    "    # predict\n",
    "    y_pred = grid_search_clf.predict(X_val)\n",
    "    print(f'Best params: {grid_search_clf.best_params_}')\n",
    "\n",
    "    # eval metrics\n",
    "    print('Evaluation metrics:')\n",
    "    eval_clf(y_val, y_pred)\n",
    "    \n",
    "    return grid_search_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_params = {\n",
    "    'n_estimators': [10, 25],\n",
    "    'learning_rate': [.1, 1],\n",
    "    'max_depth': [1, 2, 3]\n",
    "}\n",
    "\n",
    "params = {\n",
    "    'n_estimators': [10, 50, 100],\n",
    "    'learning_rate': [.001, .01, .1, 1],\n",
    "    'max_depth': [1, 2, 3]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed:  5.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'learning_rate': 0.1, 'max_depth': 1, 'n_estimators': 25}\n",
      "Evaluation metrics:\n",
      "          pred_neg  pred_pos\n",
      "cond_neg       839         7\n",
      "cond_pos         2       127\n",
      "acc: 0.9908\n",
      "tpr: 0.9845\n",
      "tnr: 0.9917\n"
     ]
    }
   ],
   "source": [
    "gridsearch_clf = gridsearch_wrapper(X_tfidf_svd800_spamcos,\n",
    "                                    y, \n",
    "                                    test_params,\n",
    "                                    k=10,                        \n",
    "                                    n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>mean_train_acc</th>\n",
       "      <th>mean_train_tpr</th>\n",
       "      <th>mean_train_tnr</th>\n",
       "      <th>mean_val_acc</th>\n",
       "      <th>mean_val_tpr</th>\n",
       "      <th>mean_val_tnr</th>\n",
       "      <th>mean_fit_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>0.994644</td>\n",
       "      <td>0.975659</td>\n",
       "      <td>0.997547</td>\n",
       "      <td>0.993157</td>\n",
       "      <td>0.969096</td>\n",
       "      <td>0.996849</td>\n",
       "      <td>16.131887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>0.998822</td>\n",
       "      <td>0.991122</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.992474</td>\n",
       "      <td>0.969096</td>\n",
       "      <td>0.996060</td>\n",
       "      <td>47.023306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.995214</td>\n",
       "      <td>0.982532</td>\n",
       "      <td>0.997153</td>\n",
       "      <td>0.991449</td>\n",
       "      <td>0.969096</td>\n",
       "      <td>0.994879</td>\n",
       "      <td>6.850760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>0.995251</td>\n",
       "      <td>0.982532</td>\n",
       "      <td>0.997197</td>\n",
       "      <td>0.991449</td>\n",
       "      <td>0.969096</td>\n",
       "      <td>0.994879</td>\n",
       "      <td>16.830054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>0.997227</td>\n",
       "      <td>0.979957</td>\n",
       "      <td>0.999869</td>\n",
       "      <td>0.992473</td>\n",
       "      <td>0.966532</td>\n",
       "      <td>0.996454</td>\n",
       "      <td>30.856894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.994606</td>\n",
       "      <td>0.967352</td>\n",
       "      <td>0.998774</td>\n",
       "      <td>0.993499</td>\n",
       "      <td>0.963968</td>\n",
       "      <td>0.998030</td>\n",
       "      <td>6.669920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.997455</td>\n",
       "      <td>0.980814</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.993841</td>\n",
       "      <td>0.963968</td>\n",
       "      <td>0.998422</td>\n",
       "      <td>18.596509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.989741</td>\n",
       "      <td>0.963968</td>\n",
       "      <td>0.993693</td>\n",
       "      <td>18.580140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.989741</td>\n",
       "      <td>0.963968</td>\n",
       "      <td>0.993695</td>\n",
       "      <td>44.552344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.998405</td>\n",
       "      <td>0.997421</td>\n",
       "      <td>0.998555</td>\n",
       "      <td>0.985975</td>\n",
       "      <td>0.958772</td>\n",
       "      <td>0.990139</td>\n",
       "      <td>13.032878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>0.998709</td>\n",
       "      <td>0.999140</td>\n",
       "      <td>0.998643</td>\n",
       "      <td>0.984951</td>\n",
       "      <td>0.958772</td>\n",
       "      <td>0.988958</td>\n",
       "      <td>31.715422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.995745</td>\n",
       "      <td>0.968210</td>\n",
       "      <td>0.999956</td>\n",
       "      <td>0.992474</td>\n",
       "      <td>0.956275</td>\n",
       "      <td>0.998030</td>\n",
       "      <td>12.489986</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    learning_rate  max_depth  n_estimators  mean_train_acc  mean_train_tpr  \\\n",
       "1             0.1          1            25        0.994644        0.975659   \n",
       "5             0.1          3            25        0.998822        0.991122   \n",
       "6             1.0          1            10        0.995214        0.982532   \n",
       "7             1.0          1            25        0.995251        0.982532   \n",
       "3             0.1          2            25        0.997227        0.979957   \n",
       "0             0.1          1            10        0.994606        0.967352   \n",
       "4             0.1          3            10        0.997455        0.980814   \n",
       "10            1.0          3            10        1.000000        1.000000   \n",
       "11            1.0          3            25        1.000000        1.000000   \n",
       "8             1.0          2            10        0.998405        0.997421   \n",
       "9             1.0          2            25        0.998709        0.999140   \n",
       "2             0.1          2            10        0.995745        0.968210   \n",
       "\n",
       "    mean_train_tnr  mean_val_acc  mean_val_tpr  mean_val_tnr  mean_fit_time  \n",
       "1         0.997547      0.993157      0.969096      0.996849      16.131887  \n",
       "5         1.000000      0.992474      0.969096      0.996060      47.023306  \n",
       "6         0.997153      0.991449      0.969096      0.994879       6.850760  \n",
       "7         0.997197      0.991449      0.969096      0.994879      16.830054  \n",
       "3         0.999869      0.992473      0.966532      0.996454      30.856894  \n",
       "0         0.998774      0.993499      0.963968      0.998030       6.669920  \n",
       "4         1.000000      0.993841      0.963968      0.998422      18.596509  \n",
       "10        1.000000      0.989741      0.963968      0.993693      18.580140  \n",
       "11        1.000000      0.989741      0.963968      0.993695      44.552344  \n",
       "8         0.998555      0.985975      0.958772      0.990139      13.032878  \n",
       "9         0.998643      0.984951      0.958772      0.988958      31.715422  \n",
       "2         0.999956      0.992474      0.956275      0.998030      12.489986  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = extract_df(gridsearch_clf)\n",
    "df.sort_values(by=['mean_val_tpr'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Early Stopping\n",
    "\n",
    "`\n",
    "IN PROGRESS....\n",
    "`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_tfidf_svd800_spamcos, y, stratify=y)\n",
    "gb_clf = GradientBoostingClassifier(max_depth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators: 1\n",
      "recall: 0.0000\n",
      "max_val_recall: 1.0000\n",
      "Recall not going up\n",
      "recall_not_going_up: 1.0000\n",
      "\n",
      "n_estimators: 2\n",
      "recall: 0.0000\n",
      "max_val_recall: 0.0000\n",
      "Recall stabilizing\n",
      "recall_not_going_up: 2.0000\n",
      "\n",
      "n_estimators: 3\n",
      "recall: 0.0000\n",
      "max_val_recall: 0.0000\n",
      "Recall stabilizing\n",
      "recall_not_going_up: 3.0000\n",
      "\n",
      "n_estimators: 4\n",
      "recall: 0.0000\n",
      "max_val_recall: 0.0000\n",
      "Recall stabilizing\n",
      "recall_not_going_up: 4.0000\n",
      "\n",
      "n_estimators: 5\n",
      "recall: 0.9457\n",
      "max_val_recall: 0.0000\n",
      "Recall going up\n",
      "recall_not_going_up: 0.0000\n",
      "\n",
      "n_estimators: 6\n",
      "recall: 0.9457\n",
      "max_val_recall: 0.9457\n",
      "Recall stabilizing\n",
      "recall_not_going_up: 1.0000\n",
      "\n",
      "n_estimators: 7\n",
      "recall: 0.9690\n",
      "max_val_recall: 0.9457\n",
      "Recall going up\n",
      "recall_not_going_up: 0.0000\n",
      "\n",
      "n_estimators: 8\n",
      "recall: 0.9690\n",
      "max_val_recall: 0.9690\n",
      "Recall stabilizing\n",
      "recall_not_going_up: 1.0000\n",
      "\n",
      "n_estimators: 9\n",
      "recall: 0.9690\n",
      "max_val_recall: 0.9690\n",
      "Recall stabilizing\n",
      "recall_not_going_up: 2.0000\n",
      "\n",
      "n_estimators: 10\n",
      "recall: 0.9690\n",
      "max_val_recall: 0.9690\n",
      "Recall stabilizing\n",
      "recall_not_going_up: 3.0000\n",
      "\n",
      "n_estimators: 11\n",
      "recall: 0.9690\n",
      "max_val_recall: 0.9690\n",
      "Recall stabilizing\n",
      "recall_not_going_up: 4.0000\n",
      "\n",
      "n_estimators: 12\n",
      "recall: 0.9690\n",
      "max_val_recall: 0.9690\n",
      "Recall stabilizing\n",
      "recall_not_going_up: 5.0000\n",
      "\n",
      "best_n_estimators: 7\n"
     ]
    }
   ],
   "source": [
    "max_val_recall = 1.0\n",
    "recall_not_going_up = 0.0\n",
    "\n",
    "for n_estimators in range(1, 100):\n",
    "    gb_clf.n_estimators = n_estimators\n",
    "    gb_clf.fit(X_train, y_train)\n",
    "    y_pred = gb_clf.predict(X_val)\n",
    "    recall = recall_score(y_val, y_pred)\n",
    "    \n",
    "    print(f'n_estimators: {n_estimators:0.0f}')\n",
    "    print(f'recall: {recall:0.4f}')\n",
    "    print(f'max_val_recall: {max_val_recall:0.4f}')\n",
    "    \n",
    "    if recall < max_val_recall:\n",
    "        print('Recall not going up')\n",
    "        recall_not_going_up += 1\n",
    "        max_val_recall = recall\n",
    "        print(f'recall_not_going_up: {recall_not_going_up:0.4f}\\n')\n",
    "        if recall_not_going_up == 5:\n",
    "            gb_clf.n_estimators_ = n_estimators-5\n",
    "            print(f'best_n_estimators: {n_estimators-5:0.0f}')\n",
    "            break\n",
    "    elif recall == max_val_recall:\n",
    "        print('Recall stabilizing')\n",
    "        recall_not_going_up += 1\n",
    "        max_val_recall = recall\n",
    "        print(f'recall_not_going_up: {recall_not_going_up:0.4f}\\n')\n",
    "        if recall_not_going_up == 5:\n",
    "            gb_clf.n_estimators_ = n_estimators-5\n",
    "            print(f'best_n_estimators: {n_estimators-5:0.0f}')\n",
    "            break\n",
    "    else:\n",
    "        print('Recall going up')\n",
    "        recall_not_going_up = 0\n",
    "        max_val_recall = recall\n",
    "        print(f'recall_not_going_up: {recall_not_going_up:0.4f}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_clf.n_estimators_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          pred_neg  pred_pos\n",
      "cond_neg       846         0\n",
      "cond_pos         4       125\n",
      "acc: 0.9959\n",
      "tpr: 0.9690\n",
      "tnr: 1.0000\n"
     ]
    }
   ],
   "source": [
    "y_pred = gb_clf.predict(X_val)\n",
    "eval_clf(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
