{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting Classifier\n",
    "\n",
    "---\n",
    "\n",
    "__This Notebook__\n",
    "\n",
    "- implement sklearn.ensemble.GradientBoostingClassifier\n",
    "\n",
    "__Results__ \n",
    "\n",
    "- \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Revised on: 2021-02-07\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "import time\n",
    "import joblib \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "dt_object = datetime.fromtimestamp(time.time())\n",
    "day, T = str(dt_object).split('.')[0].split(' ')\n",
    "print('Revised on: ' + day)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load target vector\n",
    "raw_path = os.path.join(\"data\",\"1_raw\")\n",
    "y_df = pd.read_csv(os.path.join(raw_path, 'y_train.csv'))\n",
    "y_array = np.array(y_df.iloc[:,0].ravel())\n",
    "\n",
    "y = y_array.copy()\n",
    "\n",
    "# transform y_array into int type\n",
    "y[y=='ham'] = 0\n",
    "y[y=='spam'] = 1\n",
    "y = y.astype('int')\n",
    "\n",
    "# load matrix\n",
    "proc_dir = os.path.join(\"data\", \"2_processed\")\n",
    "X_tfidf_svd800_spamcos = sp.load_npz(os.path.join(proc_dir, 'X_tfidf_svd800_spamcos.npz'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helpful Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train classifier and time it\n",
    "def time_deco(func):\n",
    "    def wrapper(clf):\n",
    "        start = time.time()\n",
    "        func(clf)\n",
    "        m,s = divmod(time.time() - start, 60)\n",
    "        print(f'Elapsed: {m:0.0f}m {s:0.0f}s')\n",
    "    return wrapper\n",
    "\n",
    "@time_deco\n",
    "def fit_clf(clf):\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "# evaluate classifier\n",
    "def eval_clf(y_val, y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_val, \n",
    "                                      y_pred).ravel()\n",
    "    confmat_df = pd.DataFrame(\n",
    "        np.array(([tn, fp], [fn, tp])),\n",
    "        columns=['pred_neg', 'pred_pos'], \n",
    "        index=['cond_neg', 'cond_pos']\n",
    "    )\n",
    "    # unpack metrics\n",
    "    acc = (tp + tn) / (tp + tn + fp + fn)\n",
    "    tpr = tp / (tp + fn)\n",
    "    tnr = tn / (tn + fp)\n",
    "    # print results\n",
    "    print(confmat_df)\n",
    "    print(f'acc: {acc:0.4f}')\n",
    "    print(f'tpr: {tpr:0.4f}')\n",
    "    print(f'tnr: {tnr:0.4f}')\n",
    "\n",
    "def extract_df(gd):\n",
    "    gd_res = gd.cv_results_\n",
    "    df = pd.concat([\n",
    "                    pd.DataFrame(gd_res[\"params\"]),\n",
    "                    pd.DataFrame(gd_res[\"mean_train_acc\"], columns=[\"mean_train_acc\"]),\n",
    "                    pd.DataFrame(gd_res[\"mean_train_tpr\"], columns=[\"mean_train_tpr\"]),\n",
    "                    pd.DataFrame(gd_res[\"mean_train_tnr\"], columns=[\"mean_train_tnr\"]),\n",
    "                    pd.DataFrame(gd_res[\"mean_test_acc\"], columns=[\"mean_val_acc\"]),\n",
    "                    pd.DataFrame(gd_res[\"mean_test_tpr\"], columns=[\"mean_val_tpr\"]),\n",
    "                    pd.DataFrame(gd_res[\"mean_test_tnr\"], columns=[\"mean_val_tnr\"]),\n",
    "                    pd.DataFrame(gd_res[\"mean_fit_time\"], columns=[\"mean_fit_time\"]),\n",
    "                    pd.DataFrame(gd_res[\"std_test_acc\"], columns=[\"std_val_acc\"]),\n",
    "                    pd.DataFrame(gd_res[\"std_test_tpr\"], columns=[\"std_val_tpr\"]),\n",
    "                    pd.DataFrame(gd_res[\"std_test_tnr\"], columns=[\"std_val_tnr\"]),\n",
    "                   ]\n",
    "                   , axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Gradient Boosting Classifier\n",
    "\n",
    "\n",
    "```\n",
    "class GradientBoostingClassifier(ClassifierMixin, BaseGradientBoosting):\n",
    "    \"\"\"Gradient Boosting for classification.\n",
    "    GB builds an additive model in a\n",
    "    forward stage-wise fashion; it allows for the optimization of\n",
    "    arbitrary differentiable loss functions. In each stage ``n_classes_``\n",
    "    regression trees are fit on the negative gradient of the\n",
    "    binomial or multinomial deviance loss function. Binary classification\n",
    "    is a special case where only a single regression tree is induced.\n",
    "```\n",
    "\n",
    "See [docs](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html), [code](https://github.com/scikit-learn/scikit-learn/blob/95119c13a/sklearn/ensemble/_gb.py#L768)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Some defaults:__\n",
    "\n",
    "\n",
    "- `loss='deviance'`\n",
    "- `learning_rate=0.1`\n",
    "- `n_estimators=100`\n",
    "- `subsample=1.0`\n",
    "- `criterion='friedman_mse'`\n",
    "- `min_samples_split=2`\n",
    "- `min_samples_leaf=1`\n",
    "- `min_weight_fraction_leaf=0.0`\n",
    "- `max_depth=3`\n",
    "- `min_impurity_decrease=0.0`\n",
    "- `min_impurity_split=None`\n",
    "- `init=None`\n",
    "- `random_state=None`\n",
    "- `max_features=None`\n",
    "- `verbose=0`\n",
    "- `max_leaf_nodes=None`\n",
    "- `warm_start=False`\n",
    "- `validation_fraction=0.1`\n",
    "- `n_iter_no_change=None`\n",
    "- `tol=0.0001`\n",
    "- `ccp_alpha=0.0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, accuracy_score, recall_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_tfidf_svd800_spamcos,\n",
    "                                                  y, \n",
    "                                                  stratify=y,\n",
    "                                                  random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_clf = GradientBoostingClassifier(\n",
    "    random_state=42\n",
    "    , verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.5970           57.27s\n",
      "         2           0.4986           56.15s\n",
      "         3           0.4280           55.11s\n",
      "         4           0.3728           54.46s\n",
      "         5           0.3278           53.67s\n",
      "         6           0.2902           52.85s\n",
      "         7           0.2575           52.13s\n",
      "         8           0.2298           51.49s\n",
      "         9           0.2052           50.83s\n",
      "        10           0.1842           50.21s\n",
      "        20           0.0661           44.16s\n",
      "        30           0.0261           38.49s\n",
      "        40           0.0117           32.92s\n",
      "        50           0.0063           27.39s\n",
      "        60           0.0040           21.97s\n",
      "        70           0.0031           16.46s\n",
      "        80           0.0025           10.96s\n",
      "        90           0.0021            5.48s\n",
      "       100           0.0018            0.00s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(random_state=42, verbose=1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# evaluate using decision function\n",
    "y_score = gb_clf.decision_function(X_val)\n",
    "plt.plot(sorted(y_score))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          pred_neg  pred_pos\n",
      "cond_neg       844         2\n",
      "cond_pos         5       124\n",
      "acc: 0.9928\n",
      "tpr: 0.9612\n",
      "tnr: 0.9976\n"
     ]
    }
   ],
   "source": [
    "# default threshold\n",
    "thresh = 0\n",
    "y_pred = np.where(y_score > thresh, 1, 0)\n",
    "eval_clf(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAD4CAYAAAAJmJb0AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAQbklEQVR4nO3dbZBeZ13H8e/PhCKlYAsNTEnaJjABzAse2rUUH6CKSlIcozO+aBELHZhMHeqgjmPLMOo4+AZRh2EoZDKlVnwgo9CB2AlWxwd4gWBThdK0tIRWmqXVbkGRKaMl9O+Lc9LeZ7vJnt3c6Wav/X5m7tn7nHPdu9d1J/nl2ut/zn1SVUiS2vR9K90BSdLJY8hLUsMMeUlqmCEvSQ0z5CWpYetX6gefffbZtXnz5pX68ZK0Kt12220PV9WGse1XLOQ3b97MgQMHVurHS9KqlORrS2nvco0kNcyQl6SGGfKS1DBDXpIaZshLUsMWDfkkNyR5KMkdxzieJO9PcijJ7UkumH43JUnLMWYmfyOw/TjHdwBb+8cu4EMn3i1J0jQsep58VX0myebjNNkJfKS6zyz+XJIzk5xTVQ9Oq5OStBQfu22W+7/xyEp345hmNj+H17x49PVMJ2QaF0NtBA5PbM/2+54U8kl20c32Oe+886bwoyVp6NEjj/Ebf/VFAJIV7swxXPXaF62qkF/obVzwTiRVtQfYAzAzM+PdSiRN3WP9jZCu2f5SfvmSF61wb1beNM6umQXOndjeBDwwhe8rSTpB0wj5fcAV/Vk2FwPfcj1ekk4Niy7XJPkocAlwdpJZ4HeApwFU1W5gP3ApcAj4DnDlyeqsJI11qq7HP9XGnF1z+SLHC3j71HokSSegrPYNeMWrpCY5ke8Y8pKaUguf3LdmGfKS1DBDXlKTLLx2DHlJTbHwOmTIS2pSLL0ChrykxjiRHzLkJalhhrykJll47RjykppSVl4HDHlJapghL6kpzuOHDHlJapghL6kpR5fkY+UVMOQlqWmGvKQmOY/vGPKS2mLldcCQl6SGGfKSmnL0piHWXTuGvCQ1zJCX1CQn8h1DXlJT/OiaIUNekhpmyEtqytGJvFe8dgx5SWqYIS+pSU7kO4a8pKZ405AhQ16SGmbIS2rK44XXFe3FqcOQl6SGGfKS2mTlFRgZ8km2J7k7yaEk1y5w/AeS/HWSLyY5mOTK6XdVkhZn3XVo0ZBPsg64DtgBbAMuT7JtXrO3A3dW1cuBS4A/THLalPsqSVqiMTP5i4BDVXVvVT0K7AV2zmtTwLPSXWJ2BvBN4MhUeypJIzz+UcMr3I9TxZiQ3wgcntie7fdN+gDwg8ADwJeAd1TVY/O/UZJdSQ4kOTA3N7fMLkuSxhoT8gv9hzh/1ev1wBeAFwCvAD6Q5NlPelHVnqqaqaqZDRs2LLGrkjSeddfOmJCfBc6d2N5EN2OfdCVwU3UOAfcBL51OFyVpCSy8DowJ+VuBrUm29MXUy4B989rcD7wOIMnzgZcA906zo5KkpVu/WIOqOpLkauAWYB1wQ1UdTHJVf3w38G7gxiRfolveuaaqHj6J/ZakBT1xxavrNTAi5AGqaj+wf96+3RPPHwB+erpdkySdKK94ldQkC68dQ15SU7zidciQl6SGGfKSmuIVr0OGvCQ1zJCX1JSja/IWXjuGvCQ1zJCXpIYZ8pKa4hWvQ4a8JDXMkJfUlHq88rqy/ThVGPKS1DBDXpIaZshLaoqrNUOGvCQ1zJCX1KR4yStgyEtS0wx5SWqYIS+pKRZehwx5SWqYIS+pKY/fNMSpPGDIS1LTDHlJapghL6kp3hlqyJCXpIYZ8pKa4k1Dhgx5SWqYIS9JDTPkJTXl6J2hLLx2DHlJatiokE+yPcndSQ4lufYYbS5J8oUkB5N8errdlKRxavEma8r6xRokWQdcB/wUMAvcmmRfVd050eZM4IPA9qq6P8nzTlJ/JUlLMGYmfxFwqKrurapHgb3Aznlt3gjcVFX3A1TVQ9PtpiRpOcaE/Ebg8MT2bL9v0ouBs5L8U5Lbklyx0DdKsivJgSQH5ubmltdjSTqOJ654tfIK40J+oXdq/rLXeuBC4A3A64HfSvLiJ72oak9VzVTVzIYNG5bcWUnS0iy6Jk83cz93YnsT8MACbR6uqkeAR5J8Bng5cM9UeilJo/WnUK5wL04VY2bytwJbk2xJchpwGbBvXptPAj+WZH2S04FXAXdNt6uSpKVadCZfVUeSXA3cAqwDbqiqg0mu6o/vrqq7kvwNcDvwGHB9Vd1xMjsuSQspz6EcGLNcQ1XtB/bP27d73vZ7gfdOr2uStHzWXTte8SpJDTPkJTXFjxoeMuQlqWGGvKSmWHgdMuQlNcnCa8eQl6SGGfKSmlJe8TpgyEtSwwx5SU2x8DpkyEtqkoXXjiEvSQ0z5CU15YnlGqfyYMhLUtMMeUlNqSfduG5tM+QlNcnCa8eQl6SGGfKSmnK08OpEvmPIS1LDDHlJapghL6lJsfIKGPKS1DRDXlJTLLwOGfKS1DBDXlJTvOJ1yJCX1CTrrh1DXpIaZshLasrjhVdn8oAhL0lNM+QlNcWy65AhL6lJ8Ux5wJCX1Jgq5/KTRoV8ku1J7k5yKMm1x2n3Q0m+l+QXptdFSVoGJ/LAiJBPsg64DtgBbAMuT7LtGO3eA9wy7U5KkpZnzEz+IuBQVd1bVY8Ce4GdC7T7FeDjwENT7J8kLYmLNUNjQn4jcHhie7bf97gkG4GfB3Yf7xsl2ZXkQJIDc3NzS+2rJI3mak1nTMgv9F7N/8/yfcA1VfW9432jqtpTVTNVNbNhw4aRXZSk8ay7Dq0f0WYWOHdiexPwwLw2M8De/kP6zwYuTXKkqj4xjU5K0lJ505DOmJC/FdiaZAvwdeAy4I2TDapqy9HnSW4EbjbgJWnlLRryVXUkydV0Z82sA26oqoNJruqPH3cdXpKeWq7XTBozk6eq9gP75+1bMNyr6i0n3i1JOjEu1nS84lVSUyy8Dhnykppk3bVjyEtSwwx5SU1xtWbIkJfUJD9quGPIS2qKhdchQ15Skyy8dgx5SWqYIS+pKd4ZasiQl9QkV2s6hrykpjiPHzLkJbXJqTxgyEtS0wx5SU2x7jpkyEtqkle8dgx5SU0pS68DhrykJnnFa8eQl6SGGfKS2uJqzYAhL6lJrtZ0DHlJTXEiP2TIS2pSrLwChrykxngx1JAhL0kNM+QlNcnVmo4hL6kpXvE6ZMhLapIT+Y4hL6kpFl6HDHlJapghL6lJFl47o0I+yfYkdyc5lOTaBY7/YpLb+8dnk7x8+l2VpMW5WjO0aMgnWQdcB+wAtgGXJ9k2r9l9wGur6mXAu4E90+6oJC2NU3kYN5O/CDhUVfdW1aPAXmDnZIOq+mxV/Ve/+Tlg03S7KUnjlJXXgTEhvxE4PLE92+87lrcCn1roQJJdSQ4kOTA3Nze+l5KkZRkT8gv9zrPgf5VJfpwu5K9Z6HhV7amqmaqa2bBhw/heStISWXjtrB/RZhY4d2J7E/DA/EZJXgZcD+yoqm9Mp3uStDQu1gyNmcnfCmxNsiXJacBlwL7JBknOA24Cfqmq7pl+NyVpaZzIdxadyVfVkSRXA7cA64Abqupgkqv647uB3waeC3yw/wznI1U1c/K6LUnH4FR+YMxyDVW1H9g/b9/uiedvA9423a5Jkk6UV7xKapJ3huoY8pKa4kcNDxnykprkPL5jyEtqihe8DhnyktQwQ15Sk6y7dgx5SU1xuWbIkJfUpFh6BQx5SY1xIj9kyEtqkmvyHUNekhpmyEtqineGGjLkJalhhrykpjiPHzLkJTXJwmvHkJfUFJfkhwx5SWqYIS+pSV7x2jHkJTXG9ZpJhrykJll47Rjykppi4XXIkJekhhnykprkck3HkJfUFFdrhgx5SU3yFMqOIS+pKRZehwx5SWqYIS+pSRZeO4a8pKaUpdcBQ15Sk5zIdwx5SU2x8Do0KuSTbE9yd5JDSa5d4HiSvL8/fnuSC6bfVUnSUi0a8knWAdcBO4BtwOVJts1rtgPY2j92AR+acj8laUksvHbWj2hzEXCoqu4FSLIX2AncOdFmJ/CR6m6T/rkkZyY5p6oenHaHP33PHL93852LN5S0Jn37f4+sdBdOKWNCfiNweGJ7FnjViDYbgUHIJ9lFN9PnvPPOW2pfATjj6evZ+vwzlvVaSWvDmaefxvnPfeZKd+OUMCbkF/qlZ35pY0wbqmoPsAdgZmZmWeWRC88/iwvPv3A5L5WkNWdM4XUWOHdiexPwwDLaSJKeYmNC/lZga5ItSU4DLgP2zWuzD7iiP8vmYuBbJ2M9XpK0NIsu11TVkSRXA7cA64Abqupgkqv647uB/cClwCHgO8CVJ6/LkqSxxqzJU1X76YJ8ct/uiecFvH26XZMknSiveJWkhhnyktQwQ16SGmbIS1LDUiv0kW1J5oCvLfPlZwMPT7E7q8laHftaHTes3bGv1XHD8cd+flVtGPuNVizkT0SSA1U1s9L9WAlrdexrddywdse+VscN0x27yzWS1DBDXpIatlpDfs9Kd2AFrdWxr9Vxw9od+1odN0xx7KtyTV6SNM5qnclLkkYw5CWpYasu5Be7qfhqluTcJP+Y5K4kB5O8o9//nCR/l+Qr/dezJl7zzv69uDvJ61eu9ycuybok/5bk5n57rYz7zCQfS/Ll/s/+1Wth7El+rf97fkeSjyb5/lbHneSGJA8luWNi35LHmuTCJF/qj70/GXEn26paNQ+6jzr+KvBC4DTgi8C2le7XFMd3DnBB//xZwD10N0//feDafv+1wHv659v69+DpwJb+vVm30uM4gfH/OvAXwM399loZ958Ab+ufnwac2frY6W4Peh/wjH77L4G3tDpu4DXABcAdE/uWPFbgX4BX092N71PAjsV+9mqbyT9+U/GqehQ4elPxJlTVg1X1r/3zbwN30f1j2EkXBPRff65/vhPYW1X/V1X30X2e/0VPaaenJMkm4A3A9RO718K4n00XAB8GqKpHq+q/WQNjp/uo82ckWQ+cTnc3uSbHXVWfAb45b/eSxprkHODZVfXP1SX+RyZec0yrLeSPdcPw5iTZDLwS+Dzw/OrvtNV/fV7frKX3433AbwKPTexbC+N+ITAH/HG/VHV9kmfS+Nir6uvAHwD3Aw/S3U3ub2l83PMsdawb++fz9x/Xagv5UTcMX+2SnAF8HPjVqvqf4zVdYN+qez+S/AzwUFXdNvYlC+xbdePuraf7Nf5DVfVK4BG6X92PpYmx9+vPO+mWI14APDPJm473kgX2rbpxj3SssS7rPVhtId/8DcOTPI0u4P+8qm7qd/9n/6sa/deH+v2tvB8/Avxskn+nW4L7iSR/Rvvjhm4ss1X1+X77Y3Sh3/rYfxK4r6rmquq7wE3AD9P+uCctdayz/fP5+49rtYX8mJuKr1p9pfzDwF1V9UcTh/YBb+6fvxn45MT+y5I8PckWYCtdYWZVqap3VtWmqtpM92f6D1X1JhofN0BV/QdwOMlL+l2vA+6k/bHfD1yc5PT+7/3r6GpQrY970pLG2i/pfDvJxf17dsXEa45tpavOy6hSX0p31slXgXetdH+mPLYfpfv163bgC/3jUuC5wN8DX+m/PmfiNe/q34u7GVFpP9UfwCU8cXbNmhg38ArgQP/n/gngrLUwduB3gS8DdwB/Snc2SZPjBj5KV3v4Lt2M/K3LGSsw079fXwU+QP+pBcd7+LEGktSw1bZcI0laAkNekhpmyEtSwwx5SWqYIS9JDTPkJalhhrwkNez/AdpqkVqhzNyvAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = gb_clf.predict(X_val)\n",
    "plt.plot(sorted(y_pred))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          pred_neg  pred_pos\n",
      "cond_neg       844         2\n",
      "cond_pos         5       124\n",
      "acc: 0.9928\n",
      "tpr: 0.9612\n",
      "tnr: 0.9976\n"
     ]
    }
   ],
   "source": [
    "eval_clf(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, accuracy_score, recall_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "def gridsearch_wrapper(X, y, param_grid, k=5, n_jobs=6):\n",
    "    \"\"\"\n",
    "    Performs a grid search with\n",
    "    Args:\n",
    "        X: numeric matrix\n",
    "        y: target variable\n",
    "        k: number of CV folds\n",
    "        n_jobs: number of logical cores\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "\n",
    "    # split into training and validation sets\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, \n",
    "                                                      y, \n",
    "                                                      stratify=y,\n",
    "                                                      random_state=42)\n",
    "\n",
    "    # setup scorers\n",
    "    scorers = {\n",
    "        'acc': make_scorer(accuracy_score),\n",
    "        'tpr': make_scorer(recall_score, pos_label=1), # sensitivity, recall\n",
    "        'tnr': make_scorer(recall_score, pos_label=0) # specificity, selectivity\n",
    "    }\n",
    "\n",
    "    # instantiate estimator\n",
    "    clf =  GradientBoostingClassifier(\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # instantiate k-fold gridsearch\n",
    "    cv_folds = StratifiedKFold(n_splits=k)\n",
    "    \n",
    "    grid_search_clf = GridSearchCV(clf, \n",
    "                                   param_grid,\n",
    "                                   scoring=scorers, \n",
    "                                   refit='tpr', \n",
    "                                   cv=cv_folds, \n",
    "                                   return_train_score=True, \n",
    "                                   n_jobs=n_jobs,\n",
    "                                   verbose=1)\n",
    "    \n",
    "    # train models\n",
    "    grid_search_clf.fit(X_train, y_train)\n",
    "\n",
    "    # predict\n",
    "    y_pred = grid_search_clf.predict(X_val)\n",
    "    print(f'Best params: {grid_search_clf.best_params_}')\n",
    "\n",
    "    # eval metrics\n",
    "    print('Evaluation metrics:')\n",
    "    eval_clf(y_val, y_pred)\n",
    "    \n",
    "    return grid_search_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'n_estimators': [10, 50, 100],\n",
    "    'learning_rate': [.001, .01]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:  7.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'learning_rate': 0.01, 'n_estimators': 100}\n",
      "Evaluation metrics:\n",
      "          pred_neg  pred_pos\n",
      "cond_neg       843         3\n",
      "cond_pos         3       126\n",
      "acc: 0.9938\n",
      "tpr: 0.9767\n",
      "tnr: 0.9965\n"
     ]
    }
   ],
   "source": [
    "gridsearch_clf1 = gridsearch_wrapper(X_tfidf_svd800_spamcos,\n",
    "                                     y, \n",
    "                                     params,\n",
    "                                     k=10,                        \n",
    "                                     n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>mean_train_acc</th>\n",
       "      <th>mean_train_tpr</th>\n",
       "      <th>mean_train_tnr</th>\n",
       "      <th>mean_val_acc</th>\n",
       "      <th>mean_val_tpr</th>\n",
       "      <th>mean_val_tnr</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_val_acc</th>\n",
       "      <th>std_val_tpr</th>\n",
       "      <th>std_val_tnr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.010</td>\n",
       "      <td>100</td>\n",
       "      <td>0.997455</td>\n",
       "      <td>0.980815</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.993499</td>\n",
       "      <td>0.961404</td>\n",
       "      <td>0.998422</td>\n",
       "      <td>100.329280</td>\n",
       "      <td>0.004951</td>\n",
       "      <td>0.030935</td>\n",
       "      <td>0.001933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>10</td>\n",
       "      <td>0.867350</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.867351</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.362479</td>\n",
       "      <td>0.001271</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001</td>\n",
       "      <td>50</td>\n",
       "      <td>0.867350</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.867351</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>53.317426</td>\n",
       "      <td>0.001271</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001</td>\n",
       "      <td>100</td>\n",
       "      <td>0.867350</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.867351</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>108.201271</td>\n",
       "      <td>0.001271</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.010</td>\n",
       "      <td>10</td>\n",
       "      <td>0.867350</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.867351</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.036705</td>\n",
       "      <td>0.001271</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.010</td>\n",
       "      <td>50</td>\n",
       "      <td>0.867502</td>\n",
       "      <td>0.001146</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.867351</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>54.453029</td>\n",
       "      <td>0.001271</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   learning_rate  n_estimators  mean_train_acc  mean_train_tpr  \\\n",
       "5          0.010           100        0.997455        0.980815   \n",
       "0          0.001            10        0.867350        0.000000   \n",
       "1          0.001            50        0.867350        0.000000   \n",
       "2          0.001           100        0.867350        0.000000   \n",
       "3          0.010            10        0.867350        0.000000   \n",
       "4          0.010            50        0.867502        0.001146   \n",
       "\n",
       "   mean_train_tnr  mean_val_acc  mean_val_tpr  mean_val_tnr  mean_fit_time  \\\n",
       "5             1.0      0.993499      0.961404      0.998422     100.329280   \n",
       "0             1.0      0.867351      0.000000      1.000000       9.362479   \n",
       "1             1.0      0.867351      0.000000      1.000000      53.317426   \n",
       "2             1.0      0.867351      0.000000      1.000000     108.201271   \n",
       "3             1.0      0.867351      0.000000      1.000000      11.036705   \n",
       "4             1.0      0.867351      0.000000      1.000000      54.453029   \n",
       "\n",
       "   std_val_acc  std_val_tpr  std_val_tnr  \n",
       "5     0.004951     0.030935     0.001933  \n",
       "0     0.001271     0.000000     0.000000  \n",
       "1     0.001271     0.000000     0.000000  \n",
       "2     0.001271     0.000000     0.000000  \n",
       "3     0.001271     0.000000     0.000000  \n",
       "4     0.001271     0.000000     0.000000  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = extract_df(gridsearch_clf1)\n",
    "df.sort_values(by=['mean_val_tpr'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>mean_train_acc</th>\n",
       "      <th>mean_train_tpr</th>\n",
       "      <th>mean_train_tnr</th>\n",
       "      <th>mean_val_acc</th>\n",
       "      <th>mean_val_tpr</th>\n",
       "      <th>mean_val_tnr</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_val_acc</th>\n",
       "      <th>std_val_tpr</th>\n",
       "      <th>std_val_tnr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>10</td>\n",
       "      <td>0.994644</td>\n",
       "      <td>0.975659</td>\n",
       "      <td>0.997547</td>\n",
       "      <td>0.993157</td>\n",
       "      <td>0.969096</td>\n",
       "      <td>0.996849</td>\n",
       "      <td>4.802966</td>\n",
       "      <td>0.004055</td>\n",
       "      <td>0.025236</td>\n",
       "      <td>0.003858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001</td>\n",
       "      <td>50</td>\n",
       "      <td>0.994644</td>\n",
       "      <td>0.975659</td>\n",
       "      <td>0.997547</td>\n",
       "      <td>0.993157</td>\n",
       "      <td>0.969096</td>\n",
       "      <td>0.996849</td>\n",
       "      <td>37.895976</td>\n",
       "      <td>0.004055</td>\n",
       "      <td>0.025236</td>\n",
       "      <td>0.003858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001</td>\n",
       "      <td>100</td>\n",
       "      <td>0.994644</td>\n",
       "      <td>0.975659</td>\n",
       "      <td>0.997547</td>\n",
       "      <td>0.993157</td>\n",
       "      <td>0.969096</td>\n",
       "      <td>0.996849</td>\n",
       "      <td>74.574805</td>\n",
       "      <td>0.004055</td>\n",
       "      <td>0.025236</td>\n",
       "      <td>0.003858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.010</td>\n",
       "      <td>10</td>\n",
       "      <td>0.994644</td>\n",
       "      <td>0.975659</td>\n",
       "      <td>0.997547</td>\n",
       "      <td>0.993157</td>\n",
       "      <td>0.969096</td>\n",
       "      <td>0.996849</td>\n",
       "      <td>8.171846</td>\n",
       "      <td>0.004055</td>\n",
       "      <td>0.025236</td>\n",
       "      <td>0.003858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.010</td>\n",
       "      <td>50</td>\n",
       "      <td>0.994644</td>\n",
       "      <td>0.975659</td>\n",
       "      <td>0.997547</td>\n",
       "      <td>0.993157</td>\n",
       "      <td>0.969096</td>\n",
       "      <td>0.996849</td>\n",
       "      <td>39.862671</td>\n",
       "      <td>0.004055</td>\n",
       "      <td>0.025236</td>\n",
       "      <td>0.003858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.010</td>\n",
       "      <td>100</td>\n",
       "      <td>0.994644</td>\n",
       "      <td>0.975659</td>\n",
       "      <td>0.997547</td>\n",
       "      <td>0.993157</td>\n",
       "      <td>0.969096</td>\n",
       "      <td>0.996849</td>\n",
       "      <td>76.285308</td>\n",
       "      <td>0.004055</td>\n",
       "      <td>0.025236</td>\n",
       "      <td>0.003858</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   learning_rate  n_estimators  mean_train_acc  mean_train_tpr  \\\n",
       "0          0.001            10        0.994644        0.975659   \n",
       "1          0.001            50        0.994644        0.975659   \n",
       "2          0.001           100        0.994644        0.975659   \n",
       "3          0.010            10        0.994644        0.975659   \n",
       "4          0.010            50        0.994644        0.975659   \n",
       "5          0.010           100        0.994644        0.975659   \n",
       "\n",
       "   mean_train_tnr  mean_val_acc  mean_val_tpr  mean_val_tnr  mean_fit_time  \\\n",
       "0        0.997547      0.993157      0.969096      0.996849       4.802966   \n",
       "1        0.997547      0.993157      0.969096      0.996849      37.895976   \n",
       "2        0.997547      0.993157      0.969096      0.996849      74.574805   \n",
       "3        0.997547      0.993157      0.969096      0.996849       8.171846   \n",
       "4        0.997547      0.993157      0.969096      0.996849      39.862671   \n",
       "5        0.997547      0.993157      0.969096      0.996849      76.285308   \n",
       "\n",
       "   std_val_acc  std_val_tpr  std_val_tnr  \n",
       "0     0.004055     0.025236     0.003858  \n",
       "1     0.004055     0.025236     0.003858  \n",
       "2     0.004055     0.025236     0.003858  \n",
       "3     0.004055     0.025236     0.003858  \n",
       "4     0.004055     0.025236     0.003858  \n",
       "5     0.004055     0.025236     0.003858  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = extract_df(gridsearch_clf1)\n",
    "df.sort_values(by=['mean_val_tpr'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deeper trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:  7.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'learning_rate': 0.01, 'n_estimators': 10}\n",
      "Evaluation metrics:\n",
      "          pred_neg  pred_pos\n",
      "cond_neg       839         7\n",
      "cond_pos         3       126\n",
      "acc: 0.9897\n",
      "tpr: 0.9767\n",
      "tnr: 0.9917\n"
     ]
    }
   ],
   "source": [
    "gridsearch_clf2 = gridsearch_wrapper(X_tfidf_svd800_spamcos, \n",
    "                                     y, \n",
    "                                     params,\n",
    "                                     k=10, \n",
    "                                     max_depth=5,\n",
    "                                     n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>mean_train_acc</th>\n",
       "      <th>mean_train_tpr</th>\n",
       "      <th>mean_train_tnr</th>\n",
       "      <th>mean_val_acc</th>\n",
       "      <th>mean_val_tpr</th>\n",
       "      <th>mean_val_tnr</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_val_acc</th>\n",
       "      <th>std_val_tpr</th>\n",
       "      <th>std_val_tnr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.010</td>\n",
       "      <td>10</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.989399</td>\n",
       "      <td>0.969096</td>\n",
       "      <td>0.992510</td>\n",
       "      <td>9.844403</td>\n",
       "      <td>0.005815</td>\n",
       "      <td>0.025236</td>\n",
       "      <td>0.005699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.010</td>\n",
       "      <td>50</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.989399</td>\n",
       "      <td>0.969096</td>\n",
       "      <td>0.992510</td>\n",
       "      <td>29.583053</td>\n",
       "      <td>0.005815</td>\n",
       "      <td>0.025236</td>\n",
       "      <td>0.005699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.010</td>\n",
       "      <td>100</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.989399</td>\n",
       "      <td>0.969096</td>\n",
       "      <td>0.992510</td>\n",
       "      <td>40.069161</td>\n",
       "      <td>0.005815</td>\n",
       "      <td>0.025236</td>\n",
       "      <td>0.005699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>10</td>\n",
       "      <td>0.999506</td>\n",
       "      <td>0.996275</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.988716</td>\n",
       "      <td>0.963968</td>\n",
       "      <td>0.992512</td>\n",
       "      <td>17.247713</td>\n",
       "      <td>0.005731</td>\n",
       "      <td>0.026231</td>\n",
       "      <td>0.006700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001</td>\n",
       "      <td>50</td>\n",
       "      <td>0.999658</td>\n",
       "      <td>0.997421</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.988716</td>\n",
       "      <td>0.963968</td>\n",
       "      <td>0.992512</td>\n",
       "      <td>54.347530</td>\n",
       "      <td>0.005731</td>\n",
       "      <td>0.026231</td>\n",
       "      <td>0.006700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001</td>\n",
       "      <td>100</td>\n",
       "      <td>0.999658</td>\n",
       "      <td>0.997421</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.988716</td>\n",
       "      <td>0.963968</td>\n",
       "      <td>0.992512</td>\n",
       "      <td>81.525042</td>\n",
       "      <td>0.005731</td>\n",
       "      <td>0.026231</td>\n",
       "      <td>0.006700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   learning_rate  n_estimators  mean_train_acc  mean_train_tpr  \\\n",
       "3          0.010            10        1.000000        1.000000   \n",
       "4          0.010            50        1.000000        1.000000   \n",
       "5          0.010           100        1.000000        1.000000   \n",
       "0          0.001            10        0.999506        0.996275   \n",
       "1          0.001            50        0.999658        0.997421   \n",
       "2          0.001           100        0.999658        0.997421   \n",
       "\n",
       "   mean_train_tnr  mean_val_acc  mean_val_tpr  mean_val_tnr  mean_fit_time  \\\n",
       "3             1.0      0.989399      0.969096      0.992510       9.844403   \n",
       "4             1.0      0.989399      0.969096      0.992510      29.583053   \n",
       "5             1.0      0.989399      0.969096      0.992510      40.069161   \n",
       "0             1.0      0.988716      0.963968      0.992512      17.247713   \n",
       "1             1.0      0.988716      0.963968      0.992512      54.347530   \n",
       "2             1.0      0.988716      0.963968      0.992512      81.525042   \n",
       "\n",
       "   std_val_acc  std_val_tpr  std_val_tnr  \n",
       "3     0.005815     0.025236     0.005699  \n",
       "4     0.005815     0.025236     0.005699  \n",
       "5     0.005815     0.025236     0.005699  \n",
       "0     0.005731     0.026231     0.006700  \n",
       "1     0.005731     0.026231     0.006700  \n",
       "2     0.005731     0.026231     0.006700  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = extract_df(gridsearch_clf2)\n",
    "df.sort_values(by=['mean_val_tpr'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   38.4s\n",
      "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed:  2.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'learning_rate': 0.1, 'n_estimators': 20}\n",
      "Evaluation metrics:\n",
      "          pred_neg  pred_pos\n",
      "cond_neg       843         3\n",
      "cond_pos         2       127\n",
      "acc: 0.9949\n",
      "tpr: 0.9845\n",
      "tnr: 0.9965\n"
     ]
    }
   ],
   "source": [
    "gridsearch_clf3 = gridsearch_wrapper(X_tfidf_svd800_spamcos, \n",
    "                                     y, \n",
    "                                     {'n_estimators': [5, 10, 20],\n",
    "                                      'learning_rate': [.001, .01, .1, 1]},\n",
    "                                     k=10, \n",
    "                                     max_depth=2,\n",
    "                                     n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>mean_train_acc</th>\n",
       "      <th>mean_train_tpr</th>\n",
       "      <th>mean_train_tnr</th>\n",
       "      <th>mean_val_acc</th>\n",
       "      <th>mean_val_tpr</th>\n",
       "      <th>mean_val_tnr</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_val_acc</th>\n",
       "      <th>std_val_tpr</th>\n",
       "      <th>std_val_tnr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.100</td>\n",
       "      <td>20</td>\n",
       "      <td>0.998974</td>\n",
       "      <td>0.992269</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.994183</td>\n",
       "      <td>0.969163</td>\n",
       "      <td>0.998030</td>\n",
       "      <td>17.887918</td>\n",
       "      <td>0.003445</td>\n",
       "      <td>0.022339</td>\n",
       "      <td>0.003631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001</td>\n",
       "      <td>10</td>\n",
       "      <td>0.995783</td>\n",
       "      <td>0.976518</td>\n",
       "      <td>0.998730</td>\n",
       "      <td>0.992133</td>\n",
       "      <td>0.966532</td>\n",
       "      <td>0.996061</td>\n",
       "      <td>7.444222</td>\n",
       "      <td>0.004342</td>\n",
       "      <td>0.030529</td>\n",
       "      <td>0.005282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001</td>\n",
       "      <td>20</td>\n",
       "      <td>0.995783</td>\n",
       "      <td>0.976518</td>\n",
       "      <td>0.998730</td>\n",
       "      <td>0.992133</td>\n",
       "      <td>0.966532</td>\n",
       "      <td>0.996061</td>\n",
       "      <td>16.940128</td>\n",
       "      <td>0.004342</td>\n",
       "      <td>0.030529</td>\n",
       "      <td>0.005282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.010</td>\n",
       "      <td>5</td>\n",
       "      <td>0.995859</td>\n",
       "      <td>0.975945</td>\n",
       "      <td>0.998905</td>\n",
       "      <td>0.992815</td>\n",
       "      <td>0.966532</td>\n",
       "      <td>0.996849</td>\n",
       "      <td>4.642983</td>\n",
       "      <td>0.003892</td>\n",
       "      <td>0.030529</td>\n",
       "      <td>0.003858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.010</td>\n",
       "      <td>10</td>\n",
       "      <td>0.996125</td>\n",
       "      <td>0.976518</td>\n",
       "      <td>0.999124</td>\n",
       "      <td>0.992474</td>\n",
       "      <td>0.966532</td>\n",
       "      <td>0.996455</td>\n",
       "      <td>9.401912</td>\n",
       "      <td>0.003994</td>\n",
       "      <td>0.030529</td>\n",
       "      <td>0.004472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.010</td>\n",
       "      <td>20</td>\n",
       "      <td>0.996201</td>\n",
       "      <td>0.976232</td>\n",
       "      <td>0.999255</td>\n",
       "      <td>0.992815</td>\n",
       "      <td>0.966532</td>\n",
       "      <td>0.996849</td>\n",
       "      <td>18.485027</td>\n",
       "      <td>0.003892</td>\n",
       "      <td>0.030529</td>\n",
       "      <td>0.003858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.100</td>\n",
       "      <td>5</td>\n",
       "      <td>0.996125</td>\n",
       "      <td>0.975086</td>\n",
       "      <td>0.999343</td>\n",
       "      <td>0.992815</td>\n",
       "      <td>0.966532</td>\n",
       "      <td>0.996849</td>\n",
       "      <td>5.553625</td>\n",
       "      <td>0.003892</td>\n",
       "      <td>0.030529</td>\n",
       "      <td>0.003858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.100</td>\n",
       "      <td>10</td>\n",
       "      <td>0.996733</td>\n",
       "      <td>0.977949</td>\n",
       "      <td>0.999606</td>\n",
       "      <td>0.993498</td>\n",
       "      <td>0.966532</td>\n",
       "      <td>0.997636</td>\n",
       "      <td>10.071650</td>\n",
       "      <td>0.004453</td>\n",
       "      <td>0.030529</td>\n",
       "      <td>0.003609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>5</td>\n",
       "      <td>0.995707</td>\n",
       "      <td>0.975660</td>\n",
       "      <td>0.998774</td>\n",
       "      <td>0.992134</td>\n",
       "      <td>0.963968</td>\n",
       "      <td>0.996455</td>\n",
       "      <td>3.865002</td>\n",
       "      <td>0.004062</td>\n",
       "      <td>0.030839</td>\n",
       "      <td>0.004806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.000</td>\n",
       "      <td>10</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.992473</td>\n",
       "      <td>0.963900</td>\n",
       "      <td>0.996846</td>\n",
       "      <td>8.946135</td>\n",
       "      <td>0.004280</td>\n",
       "      <td>0.031044</td>\n",
       "      <td>0.002364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.000</td>\n",
       "      <td>20</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.991793</td>\n",
       "      <td>0.958839</td>\n",
       "      <td>0.996847</td>\n",
       "      <td>16.742811</td>\n",
       "      <td>0.002743</td>\n",
       "      <td>0.028604</td>\n",
       "      <td>0.002363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.999848</td>\n",
       "      <td>0.998854</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.986318</td>\n",
       "      <td>0.958772</td>\n",
       "      <td>0.990537</td>\n",
       "      <td>4.464860</td>\n",
       "      <td>0.005735</td>\n",
       "      <td>0.028812</td>\n",
       "      <td>0.005349</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    learning_rate  n_estimators  mean_train_acc  mean_train_tpr  \\\n",
       "8           0.100            20        0.998974        0.992269   \n",
       "1           0.001            10        0.995783        0.976518   \n",
       "2           0.001            20        0.995783        0.976518   \n",
       "3           0.010             5        0.995859        0.975945   \n",
       "4           0.010            10        0.996125        0.976518   \n",
       "5           0.010            20        0.996201        0.976232   \n",
       "6           0.100             5        0.996125        0.975086   \n",
       "7           0.100            10        0.996733        0.977949   \n",
       "0           0.001             5        0.995707        0.975660   \n",
       "10          1.000            10        1.000000        1.000000   \n",
       "11          1.000            20        1.000000        1.000000   \n",
       "9           1.000             5        0.999848        0.998854   \n",
       "\n",
       "    mean_train_tnr  mean_val_acc  mean_val_tpr  mean_val_tnr  mean_fit_time  \\\n",
       "8         1.000000      0.994183      0.969163      0.998030      17.887918   \n",
       "1         0.998730      0.992133      0.966532      0.996061       7.444222   \n",
       "2         0.998730      0.992133      0.966532      0.996061      16.940128   \n",
       "3         0.998905      0.992815      0.966532      0.996849       4.642983   \n",
       "4         0.999124      0.992474      0.966532      0.996455       9.401912   \n",
       "5         0.999255      0.992815      0.966532      0.996849      18.485027   \n",
       "6         0.999343      0.992815      0.966532      0.996849       5.553625   \n",
       "7         0.999606      0.993498      0.966532      0.997636      10.071650   \n",
       "0         0.998774      0.992134      0.963968      0.996455       3.865002   \n",
       "10        1.000000      0.992473      0.963900      0.996846       8.946135   \n",
       "11        1.000000      0.991793      0.958839      0.996847      16.742811   \n",
       "9         1.000000      0.986318      0.958772      0.990537       4.464860   \n",
       "\n",
       "    std_val_acc  std_val_tpr  std_val_tnr  \n",
       "8      0.003445     0.022339     0.003631  \n",
       "1      0.004342     0.030529     0.005282  \n",
       "2      0.004342     0.030529     0.005282  \n",
       "3      0.003892     0.030529     0.003858  \n",
       "4      0.003994     0.030529     0.004472  \n",
       "5      0.003892     0.030529     0.003858  \n",
       "6      0.003892     0.030529     0.003858  \n",
       "7      0.004453     0.030529     0.003609  \n",
       "0      0.004062     0.030839     0.004806  \n",
       "10     0.004280     0.031044     0.002364  \n",
       "11     0.002743     0.028604     0.002363  \n",
       "9      0.005735     0.028812     0.005349  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = extract_df(gridsearch_clf3)\n",
    "df.sort_values(by=['mean_val_tpr'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data\\\\3_modeling\\\\02072021_ada_gridsearch3.joblib']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# persist\n",
    "save_path = os.path.join(\"data\", \"3_modeling\", \"02072021_ada_gridsearch3.joblib\")\n",
    "joblib.dump(gridsearch_clf3, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   33.6s\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:   58.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'learning_rate': 0.001, 'n_estimators': 10}\n",
      "Evaluation metrics:\n",
      "          pred_neg  pred_pos\n",
      "cond_neg       839         7\n",
      "cond_pos         2       127\n",
      "acc: 0.9908\n",
      "tpr: 0.9845\n",
      "tnr: 0.9917\n"
     ]
    }
   ],
   "source": [
    "gridsearch_clf4 = gridsearch_wrapper(X_tfidf_svd800_spamcos, \n",
    "                                     y, \n",
    "                                     {'n_estimators': [10, 20],\n",
    "                                      'learning_rate': [.001, .01, .1]},\n",
    "                                     k=10, \n",
    "                                     min_samples_split=5,\n",
    "                                     n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>mean_train_acc</th>\n",
       "      <th>mean_train_tpr</th>\n",
       "      <th>mean_train_tnr</th>\n",
       "      <th>mean_val_acc</th>\n",
       "      <th>mean_val_tpr</th>\n",
       "      <th>mean_val_tnr</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_val_acc</th>\n",
       "      <th>std_val_tpr</th>\n",
       "      <th>std_val_tnr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.100</td>\n",
       "      <td>20</td>\n",
       "      <td>0.998974</td>\n",
       "      <td>0.992269</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.994183</td>\n",
       "      <td>0.969163</td>\n",
       "      <td>0.998030</td>\n",
       "      <td>17.887918</td>\n",
       "      <td>0.003445</td>\n",
       "      <td>0.022339</td>\n",
       "      <td>0.003631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001</td>\n",
       "      <td>10</td>\n",
       "      <td>0.995783</td>\n",
       "      <td>0.976518</td>\n",
       "      <td>0.998730</td>\n",
       "      <td>0.992133</td>\n",
       "      <td>0.966532</td>\n",
       "      <td>0.996061</td>\n",
       "      <td>7.444222</td>\n",
       "      <td>0.004342</td>\n",
       "      <td>0.030529</td>\n",
       "      <td>0.005282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001</td>\n",
       "      <td>20</td>\n",
       "      <td>0.995783</td>\n",
       "      <td>0.976518</td>\n",
       "      <td>0.998730</td>\n",
       "      <td>0.992133</td>\n",
       "      <td>0.966532</td>\n",
       "      <td>0.996061</td>\n",
       "      <td>16.940128</td>\n",
       "      <td>0.004342</td>\n",
       "      <td>0.030529</td>\n",
       "      <td>0.005282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.010</td>\n",
       "      <td>5</td>\n",
       "      <td>0.995859</td>\n",
       "      <td>0.975945</td>\n",
       "      <td>0.998905</td>\n",
       "      <td>0.992815</td>\n",
       "      <td>0.966532</td>\n",
       "      <td>0.996849</td>\n",
       "      <td>4.642983</td>\n",
       "      <td>0.003892</td>\n",
       "      <td>0.030529</td>\n",
       "      <td>0.003858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.010</td>\n",
       "      <td>10</td>\n",
       "      <td>0.996125</td>\n",
       "      <td>0.976518</td>\n",
       "      <td>0.999124</td>\n",
       "      <td>0.992474</td>\n",
       "      <td>0.966532</td>\n",
       "      <td>0.996455</td>\n",
       "      <td>9.401912</td>\n",
       "      <td>0.003994</td>\n",
       "      <td>0.030529</td>\n",
       "      <td>0.004472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.010</td>\n",
       "      <td>20</td>\n",
       "      <td>0.996201</td>\n",
       "      <td>0.976232</td>\n",
       "      <td>0.999255</td>\n",
       "      <td>0.992815</td>\n",
       "      <td>0.966532</td>\n",
       "      <td>0.996849</td>\n",
       "      <td>18.485027</td>\n",
       "      <td>0.003892</td>\n",
       "      <td>0.030529</td>\n",
       "      <td>0.003858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.100</td>\n",
       "      <td>5</td>\n",
       "      <td>0.996125</td>\n",
       "      <td>0.975086</td>\n",
       "      <td>0.999343</td>\n",
       "      <td>0.992815</td>\n",
       "      <td>0.966532</td>\n",
       "      <td>0.996849</td>\n",
       "      <td>5.553625</td>\n",
       "      <td>0.003892</td>\n",
       "      <td>0.030529</td>\n",
       "      <td>0.003858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.100</td>\n",
       "      <td>10</td>\n",
       "      <td>0.996733</td>\n",
       "      <td>0.977949</td>\n",
       "      <td>0.999606</td>\n",
       "      <td>0.993498</td>\n",
       "      <td>0.966532</td>\n",
       "      <td>0.997636</td>\n",
       "      <td>10.071650</td>\n",
       "      <td>0.004453</td>\n",
       "      <td>0.030529</td>\n",
       "      <td>0.003609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>5</td>\n",
       "      <td>0.995707</td>\n",
       "      <td>0.975660</td>\n",
       "      <td>0.998774</td>\n",
       "      <td>0.992134</td>\n",
       "      <td>0.963968</td>\n",
       "      <td>0.996455</td>\n",
       "      <td>3.865002</td>\n",
       "      <td>0.004062</td>\n",
       "      <td>0.030839</td>\n",
       "      <td>0.004806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.000</td>\n",
       "      <td>10</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.992473</td>\n",
       "      <td>0.963900</td>\n",
       "      <td>0.996846</td>\n",
       "      <td>8.946135</td>\n",
       "      <td>0.004280</td>\n",
       "      <td>0.031044</td>\n",
       "      <td>0.002364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.000</td>\n",
       "      <td>20</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.991793</td>\n",
       "      <td>0.958839</td>\n",
       "      <td>0.996847</td>\n",
       "      <td>16.742811</td>\n",
       "      <td>0.002743</td>\n",
       "      <td>0.028604</td>\n",
       "      <td>0.002363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.999848</td>\n",
       "      <td>0.998854</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.986318</td>\n",
       "      <td>0.958772</td>\n",
       "      <td>0.990537</td>\n",
       "      <td>4.464860</td>\n",
       "      <td>0.005735</td>\n",
       "      <td>0.028812</td>\n",
       "      <td>0.005349</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    learning_rate  n_estimators  mean_train_acc  mean_train_tpr  \\\n",
       "8           0.100            20        0.998974        0.992269   \n",
       "1           0.001            10        0.995783        0.976518   \n",
       "2           0.001            20        0.995783        0.976518   \n",
       "3           0.010             5        0.995859        0.975945   \n",
       "4           0.010            10        0.996125        0.976518   \n",
       "5           0.010            20        0.996201        0.976232   \n",
       "6           0.100             5        0.996125        0.975086   \n",
       "7           0.100            10        0.996733        0.977949   \n",
       "0           0.001             5        0.995707        0.975660   \n",
       "10          1.000            10        1.000000        1.000000   \n",
       "11          1.000            20        1.000000        1.000000   \n",
       "9           1.000             5        0.999848        0.998854   \n",
       "\n",
       "    mean_train_tnr  mean_val_acc  mean_val_tpr  mean_val_tnr  mean_fit_time  \\\n",
       "8         1.000000      0.994183      0.969163      0.998030      17.887918   \n",
       "1         0.998730      0.992133      0.966532      0.996061       7.444222   \n",
       "2         0.998730      0.992133      0.966532      0.996061      16.940128   \n",
       "3         0.998905      0.992815      0.966532      0.996849       4.642983   \n",
       "4         0.999124      0.992474      0.966532      0.996455       9.401912   \n",
       "5         0.999255      0.992815      0.966532      0.996849      18.485027   \n",
       "6         0.999343      0.992815      0.966532      0.996849       5.553625   \n",
       "7         0.999606      0.993498      0.966532      0.997636      10.071650   \n",
       "0         0.998774      0.992134      0.963968      0.996455       3.865002   \n",
       "10        1.000000      0.992473      0.963900      0.996846       8.946135   \n",
       "11        1.000000      0.991793      0.958839      0.996847      16.742811   \n",
       "9         1.000000      0.986318      0.958772      0.990537       4.464860   \n",
       "\n",
       "    std_val_acc  std_val_tpr  std_val_tnr  \n",
       "8      0.003445     0.022339     0.003631  \n",
       "1      0.004342     0.030529     0.005282  \n",
       "2      0.004342     0.030529     0.005282  \n",
       "3      0.003892     0.030529     0.003858  \n",
       "4      0.003994     0.030529     0.004472  \n",
       "5      0.003892     0.030529     0.003858  \n",
       "6      0.003892     0.030529     0.003858  \n",
       "7      0.004453     0.030529     0.003609  \n",
       "0      0.004062     0.030839     0.004806  \n",
       "10     0.004280     0.031044     0.002364  \n",
       "11     0.002743     0.028604     0.002363  \n",
       "9      0.005735     0.028812     0.005349  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = extract_df(gridsearch_clf3)\n",
    "df.sort_values(by=['mean_val_tpr'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
