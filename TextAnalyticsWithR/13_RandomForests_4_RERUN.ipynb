{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forests 4\n",
    "\n",
    "---\n",
    "\n",
    "__This Notebook__\n",
    "\n",
    "\n",
    "- *original goal:*\n",
    "    - evaluate the results of the last batch of random forest grid searches\n",
    "    - narrow down search space and conduct final and more robust search\n",
    "\n",
    "- *results:*\n",
    "    - unexpectedly low sensitivity; my early attempts achieved 93% sensitivity while the latter, more comprehensive attempts maxed at 89% \n",
    "\n",
    "Since \"something went wrong\" - this notebook turned into troubleshooting and debugging\n",
    "\n",
    "__The Issue__\n",
    "\n",
    "- *MinMaxScaler()*:\n",
    "    - in __Notebook 6: Dimensionality Reduction__ I created a custom `performSVD` function that scaled results to remove negative values from the $V$ matrix so I could run a logistic classifier and \"test the waters\" with some quick modeling\n",
    "    - I had no idea that scaling the $V$ matrix would have such great impact on the performance of random forests, with respect to runtime and sensitivity\n",
    "\n",
    "Below I test the differences in hyperparameters and representations and notice how scaling is the culprit after all\n",
    "\n",
    "__Results__ \n",
    "\n",
    "- the newer grid search yields a model that achieves 96% sensitivity; I can now narrow down and push the envelope a bit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup & Load\n",
    "\n",
    "The are the results of the grid searches in the previous 3 notebooks (__12_RandomForests3.1__, __3.2__, and __3.3__)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Revised on: 2021-01-17\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import joblib \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "dt_object = datetime.fromtimestamp(time.time())\n",
    "day, T = str(dt_object).split('.')[0].split(' ')\n",
    "print('Revised on: ' + day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "# load grid searches\n",
    "mod_path = os.path.join(\"data\",\"3_modeling\")\n",
    "\n",
    "gridsearch_names = ['01052021_rf_gridsearches.joblib',\n",
    "                    '01062021_rf_gridsearches_1.joblib',\n",
    "                    '01062021_rf_gridsearches_2.joblib',\n",
    "                    '01062021_rf_gridsearches_3.joblib']\n",
    "\n",
    "gridsearches = []\n",
    "for name in gridsearch_names:\n",
    "    filepath = os.path.join(mod_path, name)\n",
    "    gridsearches.append(joblib.load(filepath))\n",
    "        \n",
    "gridsearches = [item for sublist in gridsearches for item in sublist]        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>representation</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>max_features</th>\n",
       "      <th>min_samples_split</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>mean_val_acc</th>\n",
       "      <th>mean_val_tpr</th>\n",
       "      <th>mean_val_tnr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>858</th>\n",
       "      <td>X_bot</td>\n",
       "      <td>20</td>\n",
       "      <td>500</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>0.981544</td>\n",
       "      <td>0.894534</td>\n",
       "      <td>0.994876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853</th>\n",
       "      <td>X_bot</td>\n",
       "      <td>20</td>\n",
       "      <td>250</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>0.984277</td>\n",
       "      <td>0.894467</td>\n",
       "      <td>0.998027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>852</th>\n",
       "      <td>X_bot</td>\n",
       "      <td>20</td>\n",
       "      <td>250</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>0.982911</td>\n",
       "      <td>0.891835</td>\n",
       "      <td>0.996846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>X_bot</td>\n",
       "      <td>20</td>\n",
       "      <td>500</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>0.980517</td>\n",
       "      <td>0.889339</td>\n",
       "      <td>0.994479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>859</th>\n",
       "      <td>X_bot</td>\n",
       "      <td>20</td>\n",
       "      <td>500</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>0.981543</td>\n",
       "      <td>0.889339</td>\n",
       "      <td>0.995663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>X_bot</td>\n",
       "      <td>20</td>\n",
       "      <td>500</td>\n",
       "      <td>15</td>\n",
       "      <td>100</td>\n",
       "      <td>0.980859</td>\n",
       "      <td>0.886775</td>\n",
       "      <td>0.995269</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    representation  max_depth  max_features  min_samples_split  n_estimators  \\\n",
       "858          X_bot         20           500                  5           100   \n",
       "853          X_bot         20           250                  5           200   \n",
       "852          X_bot         20           250                  5           100   \n",
       "860          X_bot         20           500                 10           100   \n",
       "859          X_bot         20           500                  5           200   \n",
       "862          X_bot         20           500                 15           100   \n",
       "\n",
       "     mean_val_acc  mean_val_tpr  mean_val_tnr  \n",
       "858      0.981544      0.894534      0.994876  \n",
       "853      0.984277      0.894467      0.998027  \n",
       "852      0.982911      0.891835      0.996846  \n",
       "860      0.980517      0.889339      0.994479  \n",
       "859      0.981543      0.889339      0.995663  \n",
       "862      0.980859      0.886775      0.995269  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_df(dic):\n",
    "    df = pd.concat([\n",
    "                    pd.DataFrame({'representation':[dic['representation']] \\\n",
    "                                * len(dic['gridsearch_res'].cv_results_[\"params\"])}),\n",
    "                    pd.DataFrame(dic['gridsearch_res'].cv_results_[\"params\"]),\n",
    "                    pd.DataFrame(dic['gridsearch_res'].cv_results_[\"mean_test_acc\"], \n",
    "                                 columns=[\"mean_val_acc\"]),\n",
    "                    pd.DataFrame(dic['gridsearch_res'].cv_results_[\"mean_test_tpr\"], \n",
    "                                 columns=[\"mean_val_tpr\"]),\n",
    "                    pd.DataFrame(dic['gridsearch_res'].cv_results_[\"mean_test_tnr\"], \n",
    "                                 columns=[\"mean_val_tnr\"])\n",
    "                    ], axis=1)\n",
    "    return df\n",
    "\n",
    "# create list of dfs\n",
    "df_list = []\n",
    "for ix, dic in enumerate(gridsearches):\n",
    "    df_list.append(extract_df(dic))\n",
    "\n",
    "# flatten and reindex\n",
    "dfm = pd.concat(df_list)\n",
    "dfm.index = range(len(dfm))\n",
    "\n",
    "# sort by top mean validation sensitivity\n",
    "top_tpr = dfm.sort_values(by=['mean_val_tpr'], ascending=False).iloc[:6,:].copy()\n",
    "top_tpr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rerunning old grid search\n",
    "\n",
    "Re-run `scikitlearn_cv`, `collect_cvs`,  `build_random_forests` (a first \"gridsearch_wrapper\") in ill-attempt to identify why my new gridsearch mean validation true positive rates are worse than my first attempts at building random forests. \n",
    "\n",
    "Results below confirm that it is not the old random forest model hypeparameters that were optimal, the issue is with the representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse as sp\n",
    "\n",
    "# load target\n",
    "raw_path = os.path.join(\"data\",\"1_raw\")\n",
    "filename = \"y_train.csv\"\n",
    "y = pd.read_csv(os.path.join(raw_path, filename))\n",
    "y = np.array(y.iloc[:,0].ravel())\n",
    "y[y=='ham'] = 0\n",
    "y[y=='spam'] = 1\n",
    "y = y.astype('int')\n",
    "\n",
    "# load 12 matrices\n",
    "proc_dir = os.path.join(\"data\",\"2_processed\")\n",
    "Xnames = ['X_bot_svd_cos.npz', 'X_bot_tfidf_svd_cos.npz']\n",
    "Xs = []\n",
    "for ix, X in enumerate(Xnames):\n",
    "    path_ = os.path.join(proc_dir, Xnames[ix])\n",
    "    Xs.append(sp.load_npz(path_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes 2h 45m\n",
    "#import custom.old_gridsearch as og\n",
    "#gridsearch = og.build_random_forests(Xs, \n",
    "#                                     Xnames,\n",
    "#                                     y,\n",
    "#                                     cv_seed=423, \n",
    "#                                     rf_seed=514,\n",
    "#                                     mtry_=[50, 100, 250],\n",
    "#                                     trees=500, \n",
    "#                                     max_leaf_nodes=99,\n",
    "#                                     cv=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| representation | mean accuracy | mean sensitivity | mean specificity | mtry | elapsed (secs.)|\n",
    "|:--------------------------|:---------:|:---------:|:---------:|:-----:|:---------:|\n",
    "| X_bot_svd_cos.npz     \t| 0.9746\t| 0.8451\t| 0.9944\t| 50\t| 707.2\t\t|\n",
    "| X_bot_tfidf_svd_cos.npz\t| 0.9787\t| 0.8643\t| 0.9962\t| 50\t| 553.3\t\t|\n",
    "| X_bot_svd_cos.npz\t\t\t| 0.9736\t| 0.8490\t| 0.9926\t| 100\t| 1374.2\t|\n",
    "| X_bot_tfidf_svd_cos.npz\t| 0.9797\t| 0.8798\t| 0.9950\t| 100\t| 1063.6\t|\n",
    "| X_bot_svd_cos.npz\t\t\t| 0.9713\t| 0.8432\t| 0.9908\t| 250\t| 3399.1\t|\n",
    "| X_bot_tfidf_svd_cos.npz\t| 0.9797\t| 0.8855\t| 0.9941\t| 250\t| 2772.7\t|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The old grid searcn run above confirms that it is not the random forest hyperparameters but something else driving the lower mean validation sensitivity.\n",
    "\n",
    "\n",
    "## Rerunning original representations \n",
    "\n",
    "Here I step back to earlier in the project, before the mistake scaling SVD in Notebook 9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urlextract\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "def load_data(data):\n",
    "    raw_path = os.path.join(\"data\",\"1_raw\")\n",
    "    filename = ''.join([data, \".csv\"])\n",
    "    out_dfm = pd.read_csv(os.path.join(raw_path, filename))\n",
    "    out_arr = np.array(out_dfm.iloc[:,0].ravel())\n",
    "    return out_arr\n",
    "\n",
    "X_train = load_data(\"X_train\")\n",
    "y_train = load_data(\"y_train\")\n",
    "\n",
    "y = y_train.copy()\n",
    "\n",
    "# transform y_array into int type\n",
    "y[y=='ham'] = 0\n",
    "y[y=='spam'] = 1\n",
    "y = y.astype('int')\n",
    "\n",
    "# load contractions map for custom cleanup\n",
    "with open(\"contractions_map.json\") as f:\n",
    "    contractions_map = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import custom.clean_preprocess as cp\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "pipe = Pipeline([('counter', cp.DocumentToNgramCounterTransformer(n_grams=3)),\n",
    "                 ('bot', cp.WordCounterToVectorTransformer(vocabulary_size=2000)),\n",
    "                 ('tfidf', TfidfTransformer(sublinear_tf=True))\n",
    "                ])\n",
    "\n",
    "X_counter = pipe['counter'].fit_transform(X_train)\n",
    "X_bot = pipe['bot'].fit_transform(X_counter)\n",
    "X_tfidf = pipe.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse.linalg import svds\n",
    "from sklearn.utils.extmath import svd_flip\n",
    "\n",
    "def perform_SVD(X, n_components=300):\n",
    "    \n",
    "    X_array = X.asfptype()\n",
    "    U, Sigma, VT = svds(X_array.T, # term-document matrix\n",
    "                        k=n_components)\n",
    "    # reverse outputs\n",
    "    Sigma = Sigma[::-1]\n",
    "    U, VT = svd_flip(U[:, ::-1], VT[::-1])\n",
    "    \n",
    "    # return V \n",
    "    V = VT.T\n",
    "    return V # do not scale\n",
    "\n",
    "X_svd_bot = perform_SVD(X_bot)\n",
    "X_svd_tfidf = perform_SVD(X_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "X_cossim_svd_bot = cosine_similarity(X_svd_bot)\n",
    "X_cossim_svd_tfidf = cosine_similarity(X_svd_tfidf)\n",
    "\n",
    "train_df = pd.DataFrame({'sms':X_train, 'target':y_train})\n",
    "\n",
    "# get spam indexes\n",
    "spam_ix = train_df.loc[train_df['target']=='spam'].index\n",
    "\n",
    "# calculate average spam similarity on SVD\n",
    "mean_spam_sims_bot, mean_spam_sims_tfidf = [], []\n",
    "\n",
    "for ix in range(X_cossim_svd_bot.shape[0]):\n",
    "    mean_spam_sims_bot.append(np.mean(X_cossim_svd_bot[ix, spam_ix]))\n",
    "    mean_spam_sims_tfidf.append(np.mean(X_cossim_svd_tfidf[ix, spam_ix]))\n",
    "\n",
    "X_bot_cossim_bot = sp.hstack((csr_matrix(mean_spam_sims_bot).T, X_svd_bot)) \n",
    "X_tfidf_cossim_tfidf = sp.hstack((csr_matrix(mean_spam_sims_tfidf).T, X_svd_tfidf)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs = [X_bot_cossim_bot, X_tfidf_cossim_tfidf]\n",
    "Xnames = ['X_bot_cossim_bot', 'X_tfidf_cossim_tfidf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes 42m (compared to 2h 45m, but cv=5)\n",
    "#gridsearch = og.build_random_forests(Xs, \n",
    "#                                     Xnames,\n",
    "#                                     y,\n",
    "#                                     cv_seed=423,\n",
    "#                                     rf_seed=514,\n",
    "#                                     mtry_=[50, 100, 250],\n",
    "#                                     trees=500, \n",
    "#                                     max_leaf_nodes=99, \n",
    "#                                     cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "| representation | mean accuracy | mean sensitivity | mean specificity | mtry | elapsed (secs.)|\n",
    "|:--------------------------|:---------:|:---------:|:---------:|:-----:|:---------:|\n",
    "| X_bot_cossim_bot\t\t    | 0.9874\t| 0.9265\t| 0.9967\t| 50    | 295.3\t    |\n",
    "| X_tfidf_cossim_tfidf\t    | 0.9872\t| 0.9342\t| 0.9953\t| 50    | 180.7\t    |\n",
    "| X_bot_cossim_bot\t\t    | 0.9872\t| 0.9362\t| 0.9950\t| 100   | 340.3\t    |\n",
    "| X_tfidf_cossim_tfidf\t    | 0.9874\t| 0.9361\t| 0.9953\t| 100   | 309.7\t    |\n",
    "| X_bot_cossim_bot\t\t    | 0.9846\t| 0.9226\t| 0.9941\t| 250   | 716.7\t    |\n",
    "| X_tfidf_cossim_tfidf\t    | 0.9872\t| 0.9380\t| 0.9947\t| 250   | 699.0\t    |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Mean validation sensitivity is a lot higher."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try new grid search wrapper with non-scaled representations\n",
    "\n",
    "Finally, I check that the newer grid search performs at least equally well and confirm that the problem was the scaled SVD after all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import custom.new_gridsearch as ng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_params = {\n",
    "    'max_features':[50, 100, 250],\n",
    "    'n_estimators':[500], \n",
    "    'max_leaf_nodes':[99]\n",
    "}\n",
    "\n",
    "# takes around X min\n",
    "gridsearch_old = ng.gridsearch_wrapper(X, Xnames, y, old_params, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_params = {\n",
    "    'n_estimators' : [100, 250, 500],   # trees\n",
    "    'max_features': [50, 75, 100, 125], # mtry\n",
    "    'max_depth': [10, 20, 30],\n",
    "    'min_samples_split': [5, 10, 15]\n",
    "}\n",
    "\n",
    "# takes around Y min\n",
    "gridsearch_old = ng.gridsearch_wrapper(X, Xnames, y, new_params, k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "96% sensitivity?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check save path\n",
    "save_path = os.path.join(mod_path, \"\".join([\"01092021_RERUN\", \"_rf_gridsearches.joblib\"]))\n",
    "save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# persist gridsearches\n",
    "joblib.dump(gridsearch_cv, save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
