{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Revised on: 2021-01-20\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "import time\n",
    "import joblib \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "dt_object = datetime.fromtimestamp(time.time())\n",
    "day, T = str(dt_object).split('.')[0].split(' ')\n",
    "print('Revised on: ' + day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import urlextract\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "def load_data(data):\n",
    "    raw_path = os.path.join(\"data\",\"1_raw\")\n",
    "    filename = ''.join([data, \".csv\"])\n",
    "    out_dfm = pd.read_csv(os.path.join(raw_path, filename))\n",
    "    out_arr = np.array(out_dfm.iloc[:,0].ravel())\n",
    "    return out_arr\n",
    "\n",
    "X_train = load_data(\"X_train\")\n",
    "y_train = load_data(\"y_train\")\n",
    "\n",
    "y = y_train.copy()\n",
    "\n",
    "# transform y_array into int type\n",
    "y[y=='ham'] = 0\n",
    "y[y=='spam'] = 1\n",
    "y = y.astype('int')\n",
    "\n",
    "# load contractions map for custom cleanup\n",
    "with open(\"contractions_map.json\") as f:\n",
    "    contractions_map = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import custom.clean_preprocess as cp\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "pipe = Pipeline([('counter', cp.DocumentToNgramCounterTransformer(n_grams=3)),\n",
    "                 ('bot', cp.WordCounterToVectorTransformer(vocabulary_size=2000)),\n",
    "                 ('tfidf', TfidfTransformer(sublinear_tf=True))])\n",
    "\n",
    "X_tfidf = pipe.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse.linalg import svds\n",
    "from sklearn.utils.extmath import svd_flip\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "\n",
    "def perform_SVD(X, n_components=300): \n",
    "    \n",
    "    X_array = X.asfptype()\n",
    "    U, Sigma, VT = svds(X_array.T, # term-document matrix\n",
    "                        k=n_components)\n",
    "    # reverse outputs\n",
    "    Sigma = Sigma[::-1]\n",
    "    U, VT = svd_flip(U[:, ::-1], VT[::-1])\n",
    "    \n",
    "    # return V \n",
    "    V = VT.T\n",
    "    scaler = MaxAbsScaler()\n",
    "    V_scaled = scaler.fit_transform(V)\n",
    "    return V_scaled # scaled for Logistic Regression\n",
    "\n",
    "X_tfidf_svd = perform_SVD(X_tfidf, n_components=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "X_tfidf_svd_allcos = cosine_similarity(X_tfidf_svd)\n",
    "\n",
    "train_df = pd.DataFrame({'sms':X_train, 'target':y_train})\n",
    "\n",
    "# get spam indexes\n",
    "spam_ix = train_df.loc[train_df['target']=='spam'].index\n",
    "\n",
    "# calculate average spam similarity on SVD\n",
    "mean_spam_sims = []\n",
    "\n",
    "for ix in range(X_tfidf_svd_allcos.shape[0]):\n",
    "    mean_spam_sims.append(np.mean(X_tfidf_svd_allcos[ix, spam_ix]))\n",
    "\n",
    "X_tfidf_svd_spamcos = sp.hstack((csr_matrix(mean_spam_sims).T, X_tfidf_svd)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, make_scorer, accuracy_score, recall_score\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_tfidf_svd_spamcos,\n",
    "                                                  y, \n",
    "                                                  stratify=y,\n",
    "                                                  random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate estimators\n",
    "log_clf = LogisticRegression(\n",
    "    solver=\"liblinear\"\n",
    "    , random_state=42\n",
    ")\n",
    "\n",
    "rnd_clf = RandomForestClassifier(\n",
    "    n_jobs=-1\n",
    "    , random_state=42\n",
    "    , max_depth=8\n",
    "    , max_features=150\n",
    "    , min_samples_split=3\n",
    "    , n_estimators=100\n",
    ")\n",
    "\n",
    "svm_clf = SVC(\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('log', log_clf), ('rnd', rnd_clf), ('svm', svm_clf)],\n",
    "    voting='hard'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.linear_model._logistic.LogisticRegression'> __main__ acc 0.9723076923076923\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'> __main__ tpr 0.8062015503875969\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'> __main__ tnr 0.9976359338061466\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> __main__ acc 0.9887179487179487\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> __main__ tpr 0.937984496124031\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> __main__ tnr 0.9964539007092199\n",
      "<class 'sklearn.svm._classes.SVC'> __main__ acc 0.958974358974359\n",
      "<class 'sklearn.svm._classes.SVC'> __main__ tpr 0.689922480620155\n",
      "<class 'sklearn.svm._classes.SVC'> __main__ tnr 1.0\n",
      "<class 'sklearn.ensemble._voting.VotingClassifier'> __main__ acc 0.9743589743589743\n",
      "<class 'sklearn.ensemble._voting.VotingClassifier'> __main__ tpr 0.8062015503875969\n",
      "<class 'sklearn.ensemble._voting.VotingClassifier'> __main__ tnr 1.0\n"
     ]
    }
   ],
   "source": [
    "for clf in (log_clf, rnd_clf, svm_clf, voting_clf):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_val)\n",
    "    print(clf.__class__, __name__, 'acc', accuracy_score(y_val, y_pred))\n",
    "    print(clf.__class__, __name__, 'tpr', recall_score(y_val, y_pred, pos_label=1)) \n",
    "    print(clf.__class__, __name__, 'tnr', recall_score(y_val, y_pred, pos_label=0)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even after scaling to help out the logistic classifier, this ensemble still does more poorly than the highly optimized random forest model, which already does more poorly than if we hadnt scaled the SVD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.linear_model._logistic.LogisticRegression'> __main__ acc 0.9723076923076923\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'> __main__ tpr 0.8062015503875969\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'> __main__ tnr 0.9976359338061466\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> __main__ acc 0.9887179487179487\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> __main__ tpr 0.937984496124031\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> __main__ tnr 0.9964539007092199\n",
      "<class 'sklearn.ensemble._voting.VotingClassifier'> __main__ acc 0.9743589743589743\n",
      "<class 'sklearn.ensemble._voting.VotingClassifier'> __main__ tpr 0.8062015503875969\n",
      "<class 'sklearn.ensemble._voting.VotingClassifier'> __main__ tnr 1.0\n"
     ]
    }
   ],
   "source": [
    "for clf in (log_clf, rnd_clf, voting_clf):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_val)\n",
    "    print(clf.__class__, __name__, 'acc', accuracy_score(y_val, y_pred))\n",
    "    print(clf.__class__, __name__, 'tpr', recall_score(y_val, y_pred, pos_label=1)) \n",
    "    print(clf.__class__, __name__, 'tnr', recall_score(y_val, y_pred, pos_label=0)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Morale__: the *wisdom of the crowds* only works when everyone in the crowd is more or less clueless and makes mistakes. When we have an \"expert\" in the crowd, we should probably follow that expert, and so an ensemble will not necessarily perform better. Even after removing the highly \"nonoptimized\" SVD classifier, the voting classifier still doesn't recognize the superiority of the expert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
