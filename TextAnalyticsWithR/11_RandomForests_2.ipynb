{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forests 2\n",
    "\n",
    "---\n",
    "\n",
    "__This Notebook__:\n",
    "\n",
    "- performs 12 grid searches, one per representation\n",
    "- there's a test version with a smaller param grid which takes 26m in the notebook and 15m run by command line with a py script\n",
    "- since running via the command line is faster, I'll do that for the slightly more involved param grid and study resulds in the next notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Revised on: 2021-01-03\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "\n",
    "from datetime import datetime\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import make_scorer, recall_score, accuracy_score, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "dt_object = datetime.fromtimestamp(time.time())\n",
    "day, T = str(dt_object).split('.')[0].split(' ')\n",
    "print('Revised on: ' + day)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load target\n",
    "raw_path = os.path.join(\"data\",\"1_raw\")\n",
    "filename = \"y_train.csv\"\n",
    "y = pd.read_csv(os.path.join(raw_path, filename))\n",
    "y = np.array(y.iloc[:,0].ravel())\n",
    "y[y=='ham'] = 0\n",
    "y[y=='spam'] = 1\n",
    "y = y.astype('int')\n",
    "\n",
    "# load 12 matrices\n",
    "proc_dir = os.path.join(\"data\",\"2_processed\")\n",
    "Xnames = [x for x in os.listdir(proc_dir) if re.search('.npz', x)]\n",
    "Xs = []\n",
    "for ix, X in enumerate(Xnames):\n",
    "    path_ = os.path.join(proc_dir, Xnames[ix])\n",
    "    Xs.append(sp.load_npz(path_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 X_bot\n",
      "2 X_bot_feat\n",
      "3 X_bot_svd\n",
      "4 X_bot_svd_cos\n",
      "5 X_bot_svd_feat\n",
      "6 X_bot_svd_feat_cos\n",
      "7 X_bot_tfidf\n",
      "8 X_bot_tfidf_feat\n",
      "9 X_bot_tfidf_svd\n",
      "10 X_bot_tfidf_svd_cos\n",
      "11 X_bot_tfidf_svd_feat\n",
      "12 X_bot_tfidf_svd_feat_cos\n"
     ]
    }
   ],
   "source": [
    "# 12 representations\n",
    "for ix, Xname in enumerate(Xnames):\n",
    "    Xname = Xname.split('.')[0]\n",
    "    print(ix+1, Xname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid search random forest models\n",
    "\n",
    "Using sklearn's GridSearchCV with 10-fold cross validation on a shallow param grid, varying representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_eval_metrics(y_val, y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_val, y_pred).ravel()\n",
    "    acc = (tp + tn) / (tp + tn + fp + fn)\n",
    "    tpr = tp / (tp + fn)\n",
    "    tnr = tn / (tn + fp)\n",
    "    print(f'accuracy: {acc:0.4f}')\n",
    "    print(f'sensitivity: {tpr:0.4f}')\n",
    "    print(f'specificity: {tnr:0.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gridsearch_wrapper(test=False, k=10):\n",
    "    \"\"\"\n",
    "    Performs grid searches and collects them in a list\n",
    "    test: faster, shallower searches for testing\n",
    "    k: for k-fold CV \n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # instantiate list of dicts to gather results\n",
    "    gridsearches = []\n",
    "    for ix, X_name in enumerate(Xnames):\n",
    "\n",
    "        X_ = Xs[ix].toarray()\n",
    "        X_name = X_name.split('.')[0]\n",
    "\n",
    "        # split into training and validation sets\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X_, y, stratify=y)\n",
    "\n",
    "        # setup testing param grid\n",
    "        test_param_grid = {\n",
    "            'min_samples_split': [10, 20], \n",
    "            'n_estimators' : [50, 100],\n",
    "            'max_depth': [5, 10],\n",
    "            'max_features': [50, 100]\n",
    "        }\n",
    "\n",
    "        # setup param grid for final not-too-deep search\n",
    "        param_grid = {\n",
    "            'min_samples_split': [5, 10, 15],\n",
    "            'n_estimators' : [100, 200],\n",
    "            'max_depth': [5, 10, 20],\n",
    "            'max_features': [50, 100, 250, 500]\n",
    "        }\n",
    "\n",
    "        # setup scorers\n",
    "        scorers = {\n",
    "            'acc': make_scorer(accuracy_score),\n",
    "            'tpr': make_scorer(recall_score, pos_label=1), # sensitivity, recall\n",
    "            'tnr': make_scorer(recall_score, pos_label=0) # specificity, selectivity\n",
    "        }\n",
    "\n",
    "        # instantiate estimator\n",
    "        clf = RandomForestClassifier(n_jobs=-1, random_state=42)\n",
    "\n",
    "        # instantiate k-fold gridsearch\n",
    "        cv_folds = StratifiedKFold(n_splits=k)\n",
    "    \n",
    "        if test == True:\n",
    "            grid_search_clf = GridSearchCV(clf, test_param_grid, # test grid\n",
    "                                           scoring=scorers, \n",
    "                                           refit='tpr', cv=cv_folds, \n",
    "                                           return_train_score=True, n_jobs=-1)\n",
    "        else:\n",
    "            grid_search_clf = GridSearchCV(clf, param_grid,\n",
    "                                           scoring=scorers, \n",
    "                                           refit='tpr', cv=cv_folds, \n",
    "                                           return_train_score=True, n_jobs=-1)           \n",
    "\n",
    "        # train models\n",
    "        print(f'\\nTraining {ix+1}: {X_name}...')\n",
    "        start_gs = time.time()\n",
    "        grid_search_clf.fit(X_train, y_train)\n",
    "        elapsed_secs = time.time() - start_gs\n",
    "        print(f'Elapsed: {elapsed_secs:0.0f} s')\n",
    "\n",
    "        # predict\n",
    "        y_pred = grid_search_clf.predict(X_val)\n",
    "        print(f'Best params: {grid_search_clf.best_params_}')\n",
    "\n",
    "        # confusion matrix on validation set\n",
    "        print(f'Confusion matrix on validation set:')\n",
    "        print(pd.DataFrame(confusion_matrix(y_val, y_pred),\n",
    "                           columns=['pred_neg', 'pred_pos'],\n",
    "                           index=['neg', 'pos']))\n",
    "        # eval metrics\n",
    "        print('Evaluation metrics:')\n",
    "        print_eval_metrics(y_val, y_pred)\n",
    "\n",
    "        # gather results into a list of dicts\n",
    "        data = {'representation':X_name,\n",
    "                'gridsearch_res':grid_search_clf}\n",
    "        \n",
    "        gridsearches.append(data)\n",
    "        \n",
    "    mins, secs = divmod(time.time() - start_time, 60)\n",
    "    print(f'\\nTot elapsed: {mins:0.0f} m {secs:0.0f} s')\n",
    "    return gridsearches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training 1: X_bot...\n",
      "Elapsed: 35 s\n",
      "Best params: {'max_depth': 10, 'max_features': 100, 'min_samples_split': 10, 'n_estimators': 50}\n",
      "Confusion matrix on validation set:\n",
      "     pred_neg  pred_pos\n",
      "neg       845         1\n",
      "pos        18       111\n",
      "Evaluation metrics:\n",
      "accuracy: 0.9805\n",
      "sensitivity: 0.8605\n",
      "specificity: 0.9988\n",
      "\n",
      "Training 2: X_bot_feat...\n",
      "Elapsed: 34 s\n",
      "Best params: {'max_depth': 10, 'max_features': 100, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Confusion matrix on validation set:\n",
      "     pred_neg  pred_pos\n",
      "neg       846         0\n",
      "pos        14       115\n",
      "Evaluation metrics:\n",
      "accuracy: 0.9856\n",
      "sensitivity: 0.8915\n",
      "specificity: 1.0000\n",
      "\n",
      "Training 3: X_bot_svd...\n",
      "Elapsed: 183 s\n",
      "Best params: {'max_depth': 10, 'max_features': 100, 'min_samples_split': 10, 'n_estimators': 50}\n",
      "Confusion matrix on validation set:\n",
      "     pred_neg  pred_pos\n",
      "neg       837         9\n",
      "pos        27       102\n",
      "Evaluation metrics:\n",
      "accuracy: 0.9631\n",
      "sensitivity: 0.7907\n",
      "specificity: 0.9894\n",
      "\n",
      "Training 4: X_bot_svd_cos...\n",
      "Elapsed: 187 s\n",
      "Best params: {'max_depth': 10, 'max_features': 100, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Confusion matrix on validation set:\n",
      "     pred_neg  pred_pos\n",
      "neg       835        11\n",
      "pos        28       101\n",
      "Evaluation metrics:\n",
      "accuracy: 0.9600\n",
      "sensitivity: 0.7829\n",
      "specificity: 0.9870\n",
      "\n",
      "Training 5: X_bot_svd_feat...\n",
      "Elapsed: 183 s\n",
      "Best params: {'max_depth': 10, 'max_features': 100, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Confusion matrix on validation set:\n",
      "     pred_neg  pred_pos\n",
      "neg       846         0\n",
      "pos        22       107\n",
      "Evaluation metrics:\n",
      "accuracy: 0.9774\n",
      "sensitivity: 0.8295\n",
      "specificity: 1.0000\n",
      "\n",
      "Training 6: X_bot_svd_feat_cos...\n",
      "Elapsed: 177 s\n",
      "Best params: {'max_depth': 10, 'max_features': 50, 'min_samples_split': 20, 'n_estimators': 50}\n",
      "Confusion matrix on validation set:\n",
      "     pred_neg  pred_pos\n",
      "neg       840         6\n",
      "pos        22       107\n",
      "Evaluation metrics:\n",
      "accuracy: 0.9713\n",
      "sensitivity: 0.8295\n",
      "specificity: 0.9929\n",
      "\n",
      "Training 7: X_bot_tfidf...\n",
      "Elapsed: 35 s\n",
      "Best params: {'max_depth': 10, 'max_features': 100, 'min_samples_split': 10, 'n_estimators': 50}\n",
      "Confusion matrix on validation set:\n",
      "     pred_neg  pred_pos\n",
      "neg       846         0\n",
      "pos        23       106\n",
      "Evaluation metrics:\n",
      "accuracy: 0.9764\n",
      "sensitivity: 0.8217\n",
      "specificity: 1.0000\n",
      "\n",
      "Training 8: X_bot_tfidf_feat...\n",
      "Elapsed: 34 s\n",
      "Best params: {'max_depth': 10, 'max_features': 100, 'min_samples_split': 20, 'n_estimators': 50}\n",
      "Confusion matrix on validation set:\n",
      "     pred_neg  pred_pos\n",
      "neg       842         4\n",
      "pos        23       106\n",
      "Evaluation metrics:\n",
      "accuracy: 0.9723\n",
      "sensitivity: 0.8217\n",
      "specificity: 0.9953\n",
      "\n",
      "Training 9: X_bot_tfidf_svd...\n",
      "Elapsed: 174 s\n",
      "Best params: {'max_depth': 10, 'max_features': 100, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Confusion matrix on validation set:\n",
      "     pred_neg  pred_pos\n",
      "neg       841         5\n",
      "pos        15       114\n",
      "Evaluation metrics:\n",
      "accuracy: 0.9795\n",
      "sensitivity: 0.8837\n",
      "specificity: 0.9941\n",
      "\n",
      "Training 10: X_bot_tfidf_svd_cos...\n",
      "Elapsed: 171 s\n",
      "Best params: {'max_depth': 10, 'max_features': 100, 'min_samples_split': 20, 'n_estimators': 50}\n",
      "Confusion matrix on validation set:\n",
      "     pred_neg  pred_pos\n",
      "neg       844         2\n",
      "pos        12       117\n",
      "Evaluation metrics:\n",
      "accuracy: 0.9856\n",
      "sensitivity: 0.9070\n",
      "specificity: 0.9976\n",
      "\n",
      "Training 11: X_bot_tfidf_svd_feat...\n",
      "Elapsed: 171 s\n",
      "Best params: {'max_depth': 10, 'max_features': 100, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Confusion matrix on validation set:\n",
      "     pred_neg  pred_pos\n",
      "neg       843         3\n",
      "pos        17       112\n",
      "Evaluation metrics:\n",
      "accuracy: 0.9795\n",
      "sensitivity: 0.8682\n",
      "specificity: 0.9965\n",
      "\n",
      "Training 12: X_bot_tfidf_svd_feat_cos...\n",
      "Elapsed: 167 s\n",
      "Best params: {'max_depth': 10, 'max_features': 50, 'min_samples_split': 10, 'n_estimators': 50}\n",
      "Confusion matrix on validation set:\n",
      "     pred_neg  pred_pos\n",
      "neg       841         5\n",
      "pos        23       106\n",
      "Evaluation metrics:\n",
      "accuracy: 0.9713\n",
      "sensitivity: 0.8217\n",
      "specificity: 0.9941\n",
      "\n",
      "Tot elapsed: 25 m 54 s\n"
     ]
    }
   ],
   "source": [
    "results = gridsearch_wrapper(test=True, k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Persist results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data\\\\3_modeling\\\\01032020_rf_gridsearches_testparams.joblib']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dir = os.path.join(\"data\", \"3_modeling\")\n",
    "file_path = os.path.join(model_dir, \"01032021_rf_gridsearches_testparams.joblib\")\n",
    "\n",
    "joblib.dump(results, file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
