{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting Classifier 2\n",
    "\n",
    "---\n",
    "\n",
    "__This Notebook__\n",
    "\n",
    "- run fuller param GridSearchCV\n",
    "\n",
    "__Results__ \n",
    "\n",
    "- get best mean validation sensitivity at 0.974, not as great as random forests\n",
    "- strange how it overfits easily and how there seems to be no clear pattern for hyperparameters\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Revised on: 2021-02-10\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "import time\n",
    "import joblib \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "dt_object = datetime.fromtimestamp(time.time())\n",
    "day, T = str(dt_object).split('.')[0].split(' ')\n",
    "print('Revised on: ' + day)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load target vector\n",
    "raw_path = os.path.join(\"data\",\"1_raw\")\n",
    "y_df = pd.read_csv(os.path.join(raw_path, 'y_train.csv'))\n",
    "y_array = np.array(y_df.iloc[:,0].ravel())\n",
    "\n",
    "y = y_array.copy()\n",
    "\n",
    "# transform y_array into int type\n",
    "y[y=='ham'] = 0\n",
    "y[y=='spam'] = 1\n",
    "y = y.astype('int')\n",
    "\n",
    "# load matrix\n",
    "proc_dir = os.path.join(\"data\", \"2_processed\")\n",
    "X_tfidf_svd800_spamcos = sp.load_npz(os.path.join(proc_dir, 'X_tfidf_svd800_spamcos.npz'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helpful Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train classifier and time it\n",
    "def time_deco(func):\n",
    "    def wrapper(clf):\n",
    "        start = time.time()\n",
    "        func(clf)\n",
    "        m,s = divmod(time.time() - start, 60)\n",
    "        print(f'Elapsed: {m:0.0f}m {s:0.0f}s')\n",
    "    return wrapper\n",
    "\n",
    "@time_deco\n",
    "def fit_clf(clf):\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "# evaluate classifier\n",
    "def eval_clf(y_val, y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_val, \n",
    "                                      y_pred).ravel()\n",
    "    confmat_df = pd.DataFrame(\n",
    "        np.array(([tn, fp], [fn, tp])),\n",
    "        columns=['pred_neg', 'pred_pos'], \n",
    "        index=['cond_neg', 'cond_pos']\n",
    "    )\n",
    "    # unpack metrics\n",
    "    acc = (tp + tn) / (tp + tn + fp + fn)\n",
    "    tpr = tp / (tp + fn)\n",
    "    tnr = tn / (tn + fp)\n",
    "    # print results\n",
    "    print(confmat_df)\n",
    "    print(f'acc: {acc:0.4f}')\n",
    "    print(f'tpr: {tpr:0.4f}')\n",
    "    print(f'tnr: {tnr:0.4f}')\n",
    "\n",
    "def extract_df(gd):\n",
    "    gd_res = gd.cv_results_\n",
    "    df = pd.concat([\n",
    "                    pd.DataFrame(gd_res[\"params\"]),\n",
    "                    pd.DataFrame(gd_res[\"mean_train_acc\"], columns=[\"mean_train_acc\"]),\n",
    "                    pd.DataFrame(gd_res[\"mean_train_tpr\"], columns=[\"mean_train_tpr\"]),\n",
    "                    pd.DataFrame(gd_res[\"mean_train_tnr\"], columns=[\"mean_train_tnr\"]),\n",
    "                    pd.DataFrame(gd_res[\"mean_test_acc\"], columns=[\"mean_val_acc\"]),\n",
    "                    pd.DataFrame(gd_res[\"mean_test_tpr\"], columns=[\"mean_val_tpr\"]),\n",
    "                    pd.DataFrame(gd_res[\"mean_test_tnr\"], columns=[\"mean_val_tnr\"]),\n",
    "                    pd.DataFrame(gd_res[\"mean_fit_time\"], columns=[\"mean_fit_time\"])\n",
    "                    #pd.DataFrame(gd_res[\"std_test_acc\"], columns=[\"std_val_acc\"]),\n",
    "                    #pd.DataFrame(gd_res[\"std_test_tpr\"], columns=[\"std_val_tpr\"]),\n",
    "                    #pd.DataFrame(gd_res[\"std_test_tnr\"], columns=[\"std_val_tnr\"]),\n",
    "                   ]\n",
    "                   , axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Gradient Boosting Classifier\n",
    "\n",
    "\n",
    "```\n",
    "class GradientBoostingClassifier(ClassifierMixin, BaseGradientBoosting):\n",
    "    \"\"\"Gradient Boosting for classification.\n",
    "    GB builds an additive model in a\n",
    "    forward stage-wise fashion; it allows for the optimization of\n",
    "    arbitrary differentiable loss functions. In each stage ``n_classes_``\n",
    "    regression trees are fit on the negative gradient of the\n",
    "    binomial or multinomial deviance loss function. Binary classification\n",
    "    is a special case where only a single regression tree is induced.\n",
    "```\n",
    "\n",
    "See [docs](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html), [code](https://github.com/scikit-learn/scikit-learn/blob/95119c13a/sklearn/ensemble/_gb.py#L768)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Some defaults:__\n",
    "\n",
    "\n",
    "- `loss='deviance'`\n",
    "- `learning_rate=0.1`\n",
    "- `n_estimators=100`\n",
    "- `subsample=1.0`\n",
    "- `criterion='friedman_mse'`\n",
    "- `min_samples_split=2`\n",
    "- `min_samples_leaf=1`\n",
    "- `min_weight_fraction_leaf=0.0`\n",
    "- `max_depth=3`\n",
    "- `min_impurity_decrease=0.0`\n",
    "- `min_impurity_split=None`\n",
    "- `init=None`\n",
    "- `random_state=None`\n",
    "- `max_features=None`\n",
    "- `verbose=0`\n",
    "- `max_leaf_nodes=None`\n",
    "- `warm_start=False`\n",
    "- `validation_fraction=0.1`\n",
    "- `n_iter_no_change=None`\n",
    "- `tol=0.0001`\n",
    "- `ccp_alpha=0.0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, accuracy_score, recall_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, accuracy_score, recall_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "def gridsearch_wrapper(X, y, param_grid, k=5, n_jobs=6):\n",
    "    \"\"\"\n",
    "    Performs a grid search with\n",
    "    Args:\n",
    "        X: numeric matrix\n",
    "        y: target variable\n",
    "        param_grid : dict of hyperparameters for search\n",
    "        k: number of CV folds\n",
    "        n_jobs: number of logical cores\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "\n",
    "    # split into training and validation sets\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, \n",
    "                                                      y, \n",
    "                                                      stratify=y,\n",
    "                                                      random_state=42)\n",
    "\n",
    "    # setup scorers\n",
    "    scorers = {\n",
    "        'acc': make_scorer(accuracy_score),\n",
    "        'tpr': make_scorer(recall_score, pos_label=1), # sensitivity, recall\n",
    "        'tnr': make_scorer(recall_score, pos_label=0) # specificity, selectivity\n",
    "    }\n",
    "\n",
    "    # instantiate estimator\n",
    "    clf =  GradientBoostingClassifier(\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # instantiate k-fold gridsearch\n",
    "    cv_folds = StratifiedKFold(n_splits=k)\n",
    "    \n",
    "    grid_search_clf = GridSearchCV(clf, \n",
    "                                   param_grid,\n",
    "                                   scoring=scorers, \n",
    "                                   refit='tpr', \n",
    "                                   cv=cv_folds, \n",
    "                                   return_train_score=True, \n",
    "                                   n_jobs=n_jobs,\n",
    "                                   verbose=1)\n",
    "    \n",
    "    # train models\n",
    "    grid_search_clf.fit(X_train, y_train)\n",
    "\n",
    "    # predict\n",
    "    y_pred = grid_search_clf.predict(X_val)\n",
    "    print(f'Best params: {grid_search_clf.best_params_}')\n",
    "\n",
    "    # eval metrics\n",
    "    print('Evaluation metrics:')\n",
    "    eval_clf(y_val, y_pred)\n",
    "    \n",
    "    return grid_search_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_params = {\n",
    "    'n_estimators': [10, 25],\n",
    "    'learning_rate': [.1, 1],\n",
    "    'max_depth': [1, 2, 3]\n",
    "}\n",
    "\n",
    "params = {\n",
    "    'n_estimators': [10, 50, 100],\n",
    "    'learning_rate': [.001, .01, .1, 1],\n",
    "    'max_depth': [1, 2, 3]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 36 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed: 14.3min\n",
      "[Parallel(n_jobs=-1)]: Done 360 out of 360 | elapsed: 29.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'learning_rate': 0.1, 'max_depth': 1, 'n_estimators': 50}\n",
      "Evaluation metrics:\n",
      "          pred_neg  pred_pos\n",
      "cond_neg       839         7\n",
      "cond_pos         2       127\n",
      "acc: 0.9908\n",
      "tpr: 0.9845\n",
      "tnr: 0.9917\n"
     ]
    }
   ],
   "source": [
    "gridsearch_clf = gridsearch_wrapper(X_tfidf_svd800_spamcos,\n",
    "                                    y, \n",
    "                                    params,\n",
    "                                    k=10,                        \n",
    "                                    n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>mean_train_acc</th>\n",
       "      <th>mean_train_tpr</th>\n",
       "      <th>mean_train_tnr</th>\n",
       "      <th>mean_val_acc</th>\n",
       "      <th>mean_val_tpr</th>\n",
       "      <th>mean_val_tnr</th>\n",
       "      <th>mean_fit_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.100</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>0.994796</td>\n",
       "      <td>0.980528</td>\n",
       "      <td>0.996978</td>\n",
       "      <td>0.992815</td>\n",
       "      <td>0.974224</td>\n",
       "      <td>0.995666</td>\n",
       "      <td>19.620680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.100</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.993499</td>\n",
       "      <td>0.971660</td>\n",
       "      <td>0.996849</td>\n",
       "      <td>108.593983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.100</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.993499</td>\n",
       "      <td>0.971660</td>\n",
       "      <td>0.996849</td>\n",
       "      <td>54.514598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.000</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.995251</td>\n",
       "      <td>0.982532</td>\n",
       "      <td>0.997197</td>\n",
       "      <td>0.991449</td>\n",
       "      <td>0.969096</td>\n",
       "      <td>0.994879</td>\n",
       "      <td>39.499829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.000</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>0.995251</td>\n",
       "      <td>0.982532</td>\n",
       "      <td>0.997197</td>\n",
       "      <td>0.991449</td>\n",
       "      <td>0.969096</td>\n",
       "      <td>0.994879</td>\n",
       "      <td>19.738885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.000</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.995214</td>\n",
       "      <td>0.982532</td>\n",
       "      <td>0.997153</td>\n",
       "      <td>0.991449</td>\n",
       "      <td>0.969096</td>\n",
       "      <td>0.994879</td>\n",
       "      <td>3.972590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.100</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.993158</td>\n",
       "      <td>0.969096</td>\n",
       "      <td>0.996849</td>\n",
       "      <td>73.330781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.100</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>0.998822</td>\n",
       "      <td>0.991124</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.992474</td>\n",
       "      <td>0.969096</td>\n",
       "      <td>0.996060</td>\n",
       "      <td>36.902974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.100</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.997265</td>\n",
       "      <td>0.986540</td>\n",
       "      <td>0.998905</td>\n",
       "      <td>0.992474</td>\n",
       "      <td>0.969096</td>\n",
       "      <td>0.996061</td>\n",
       "      <td>39.379844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1.000</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990764</td>\n",
       "      <td>0.966532</td>\n",
       "      <td>0.994482</td>\n",
       "      <td>98.218061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1.000</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990424</td>\n",
       "      <td>0.963968</td>\n",
       "      <td>0.994482</td>\n",
       "      <td>54.234256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1.000</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.989741</td>\n",
       "      <td>0.963968</td>\n",
       "      <td>0.993693</td>\n",
       "      <td>10.737860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.100</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.997455</td>\n",
       "      <td>0.980814</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.993841</td>\n",
       "      <td>0.963968</td>\n",
       "      <td>0.998422</td>\n",
       "      <td>10.830613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.100</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.994606</td>\n",
       "      <td>0.967352</td>\n",
       "      <td>0.998774</td>\n",
       "      <td>0.993499</td>\n",
       "      <td>0.963968</td>\n",
       "      <td>0.998030</td>\n",
       "      <td>3.996562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.010</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.994644</td>\n",
       "      <td>0.968210</td>\n",
       "      <td>0.998686</td>\n",
       "      <td>0.993157</td>\n",
       "      <td>0.963968</td>\n",
       "      <td>0.997636</td>\n",
       "      <td>39.104029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1.000</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.998709</td>\n",
       "      <td>0.999140</td>\n",
       "      <td>0.998643</td>\n",
       "      <td>0.985634</td>\n",
       "      <td>0.963900</td>\n",
       "      <td>0.988958</td>\n",
       "      <td>73.558265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1.000</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>0.998709</td>\n",
       "      <td>0.999140</td>\n",
       "      <td>0.998643</td>\n",
       "      <td>0.985293</td>\n",
       "      <td>0.963900</td>\n",
       "      <td>0.988564</td>\n",
       "      <td>36.863408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.010</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.995745</td>\n",
       "      <td>0.968210</td>\n",
       "      <td>0.999956</td>\n",
       "      <td>0.993157</td>\n",
       "      <td>0.961404</td>\n",
       "      <td>0.998030</td>\n",
       "      <td>73.632019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.010</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.997455</td>\n",
       "      <td>0.980815</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.993499</td>\n",
       "      <td>0.961404</td>\n",
       "      <td>0.998422</td>\n",
       "      <td>108.443716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1.000</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.998405</td>\n",
       "      <td>0.997421</td>\n",
       "      <td>0.998555</td>\n",
       "      <td>0.985975</td>\n",
       "      <td>0.958772</td>\n",
       "      <td>0.990139</td>\n",
       "      <td>7.525877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.100</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.995745</td>\n",
       "      <td>0.968210</td>\n",
       "      <td>0.999956</td>\n",
       "      <td>0.992474</td>\n",
       "      <td>0.956275</td>\n",
       "      <td>0.998030</td>\n",
       "      <td>7.420003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.001</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.867350</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.867351</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.030223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.867350</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.867351</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>38.396236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.867350</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.867351</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.663034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>0.867350</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.867351</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>36.702575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.001</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.867350</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.867351</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>73.654760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.001</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.867350</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.867351</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>108.070001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.001</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>0.867350</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.867351</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>54.137997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.010</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.867350</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.867351</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.108987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.010</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.867350</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.867351</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.001400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.010</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>0.867350</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.867351</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>19.509921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.010</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.867350</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.867351</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.412873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.010</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>0.867350</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.867351</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>36.683290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>0.867350</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.867351</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>17.264790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.010</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>0.867502</td>\n",
       "      <td>0.001146</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.867351</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>54.317012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.867350</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.867351</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.451511</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    learning_rate  max_depth  n_estimators  mean_train_acc  mean_train_tpr  \\\n",
       "19          0.100          1            50        0.994796        0.980528   \n",
       "26          0.100          3           100        1.000000        1.000000   \n",
       "25          0.100          3            50        1.000000        1.000000   \n",
       "29          1.000          1           100        0.995251        0.982532   \n",
       "28          1.000          1            50        0.995251        0.982532   \n",
       "27          1.000          1            10        0.995214        0.982532   \n",
       "23          0.100          2           100        1.000000        1.000000   \n",
       "22          0.100          2            50        0.998822        0.991124   \n",
       "20          0.100          1           100        0.997265        0.986540   \n",
       "35          1.000          3           100        1.000000        1.000000   \n",
       "34          1.000          3            50        1.000000        1.000000   \n",
       "33          1.000          3            10        1.000000        1.000000   \n",
       "24          0.100          3            10        0.997455        0.980814   \n",
       "18          0.100          1            10        0.994606        0.967352   \n",
       "11          0.010          1           100        0.994644        0.968210   \n",
       "32          1.000          2           100        0.998709        0.999140   \n",
       "31          1.000          2            50        0.998709        0.999140   \n",
       "14          0.010          2           100        0.995745        0.968210   \n",
       "17          0.010          3           100        0.997455        0.980815   \n",
       "30          1.000          2            10        0.998405        0.997421   \n",
       "21          0.100          2            10        0.995745        0.968210   \n",
       "6           0.001          3            10        0.867350        0.000000   \n",
       "2           0.001          1           100        0.867350        0.000000   \n",
       "3           0.001          2            10        0.867350        0.000000   \n",
       "4           0.001          2            50        0.867350        0.000000   \n",
       "5           0.001          2           100        0.867350        0.000000   \n",
       "8           0.001          3           100        0.867350        0.000000   \n",
       "7           0.001          3            50        0.867350        0.000000   \n",
       "15          0.010          3            10        0.867350        0.000000   \n",
       "9           0.010          1            10        0.867350        0.000000   \n",
       "10          0.010          1            50        0.867350        0.000000   \n",
       "12          0.010          2            10        0.867350        0.000000   \n",
       "13          0.010          2            50        0.867350        0.000000   \n",
       "1           0.001          1            50        0.867350        0.000000   \n",
       "16          0.010          3            50        0.867502        0.001146   \n",
       "0           0.001          1            10        0.867350        0.000000   \n",
       "\n",
       "    mean_train_tnr  mean_val_acc  mean_val_tpr  mean_val_tnr  mean_fit_time  \n",
       "19        0.996978      0.992815      0.974224      0.995666      19.620680  \n",
       "26        1.000000      0.993499      0.971660      0.996849     108.593983  \n",
       "25        1.000000      0.993499      0.971660      0.996849      54.514598  \n",
       "29        0.997197      0.991449      0.969096      0.994879      39.499829  \n",
       "28        0.997197      0.991449      0.969096      0.994879      19.738885  \n",
       "27        0.997153      0.991449      0.969096      0.994879       3.972590  \n",
       "23        1.000000      0.993158      0.969096      0.996849      73.330781  \n",
       "22        1.000000      0.992474      0.969096      0.996060      36.902974  \n",
       "20        0.998905      0.992474      0.969096      0.996061      39.379844  \n",
       "35        1.000000      0.990764      0.966532      0.994482      98.218061  \n",
       "34        1.000000      0.990424      0.963968      0.994482      54.234256  \n",
       "33        1.000000      0.989741      0.963968      0.993693      10.737860  \n",
       "24        1.000000      0.993841      0.963968      0.998422      10.830613  \n",
       "18        0.998774      0.993499      0.963968      0.998030       3.996562  \n",
       "11        0.998686      0.993157      0.963968      0.997636      39.104029  \n",
       "32        0.998643      0.985634      0.963900      0.988958      73.558265  \n",
       "31        0.998643      0.985293      0.963900      0.988564      36.863408  \n",
       "14        0.999956      0.993157      0.961404      0.998030      73.632019  \n",
       "17        1.000000      0.993499      0.961404      0.998422     108.443716  \n",
       "30        0.998555      0.985975      0.958772      0.990139       7.525877  \n",
       "21        0.999956      0.992474      0.956275      0.998030       7.420003  \n",
       "6         1.000000      0.867351      0.000000      1.000000      11.030223  \n",
       "2         1.000000      0.867351      0.000000      1.000000      38.396236  \n",
       "3         1.000000      0.867351      0.000000      1.000000       7.663034  \n",
       "4         1.000000      0.867351      0.000000      1.000000      36.702575  \n",
       "5         1.000000      0.867351      0.000000      1.000000      73.654760  \n",
       "8         1.000000      0.867351      0.000000      1.000000     108.070001  \n",
       "7         1.000000      0.867351      0.000000      1.000000      54.137997  \n",
       "15        1.000000      0.867351      0.000000      1.000000      11.108987  \n",
       "9         1.000000      0.867351      0.000000      1.000000       4.001400  \n",
       "10        1.000000      0.867351      0.000000      1.000000      19.509921  \n",
       "12        1.000000      0.867351      0.000000      1.000000       7.412873  \n",
       "13        1.000000      0.867351      0.000000      1.000000      36.683290  \n",
       "1         1.000000      0.867351      0.000000      1.000000      17.264790  \n",
       "16        1.000000      0.867351      0.000000      1.000000      54.317012  \n",
       "0         1.000000      0.867351      0.000000      1.000000       3.451511  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = extract_df(gridsearch_clf)\n",
    "df.sort_values(by=['mean_val_tpr'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data\\\\3_modeling\\\\02102021_gb_gridsearch.joblib']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# persist\n",
    "save_path = os.path.join(\"data\", \"3_modeling\", \"02102021_gb_gridsearch.joblib\")\n",
    "joblib.dump(gridsearch_clf, save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
