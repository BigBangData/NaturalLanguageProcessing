{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voting Classifier\n",
    "\n",
    "---\n",
    "\n",
    "__This Notebook__\n",
    "\n",
    "- Tries to implement a quick voting classifier using a baseline logistic classifier, the optimized random forest classifier, along with a quick SVM classifier, in the hopes that these estimators make different enough kinds of mistakes that the voting classifier outperforms them\n",
    "\n",
    "__Results__ \n",
    "\n",
    "- It appears as if the *wisdom of the crowds* only works when everyone in the crowd is more or less clueless. When we have an \"expert\" in the crowd (the random forest model), we should probably follow that expert and not vote... so a voting classifier will not necessarily outperform nor recognize the expert\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Revised on: 2021-01-22\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "import time\n",
    "import joblib \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "dt_object = datetime.fromtimestamp(time.time())\n",
    "day, T = str(dt_object).split('.')[0].split(' ')\n",
    "print('Revised on: ' + day)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to rerun the pipeline and scale the SVD otherwise the logistic classifier will perform badly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import urlextract\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "def load_data(data):\n",
    "    raw_path = os.path.join(\"data\",\"1_raw\")\n",
    "    filename = ''.join([data, \".csv\"])\n",
    "    out_dfm = pd.read_csv(os.path.join(raw_path, filename))\n",
    "    out_arr = np.array(out_dfm.iloc[:,0].ravel())\n",
    "    return out_arr\n",
    "\n",
    "X_train = load_data(\"X_train\")\n",
    "y_train = load_data(\"y_train\")\n",
    "\n",
    "y = y_train.copy()\n",
    "\n",
    "# transform y_array into int type\n",
    "y[y=='ham'] = 0\n",
    "y[y=='spam'] = 1\n",
    "y = y.astype('int')\n",
    "\n",
    "# load contractions map for custom cleanup\n",
    "with open(\"contractions_map.json\") as f:\n",
    "    contractions_map = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import custom.clean_preprocess as cp\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "pipe = Pipeline([('counter', cp.DocumentToNgramCounterTransformer(n_grams=3)),\n",
    "                 ('bot', cp.WordCounterToVectorTransformer(vocabulary_size=2000)),\n",
    "                 ('tfidf', TfidfTransformer(sublinear_tf=True))])\n",
    "\n",
    "X_tfidf = pipe.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse.linalg import svds\n",
    "from sklearn.utils.extmath import svd_flip\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "\n",
    "def perform_SVD(X, n_components=300): \n",
    "    \n",
    "    X_array = X.asfptype()\n",
    "    U, Sigma, VT = svds(X_array.T, # term-document matrix\n",
    "                        k=n_components)\n",
    "    # reverse outputs\n",
    "    Sigma = Sigma[::-1]\n",
    "    U, VT = svd_flip(U[:, ::-1], VT[::-1])\n",
    "    \n",
    "    # return V \n",
    "    V = VT.T\n",
    "    scaler = MaxAbsScaler()\n",
    "    V_scaled = scaler.fit_transform(V)\n",
    "    return V_scaled # scaled for Logistic Regression\n",
    "\n",
    "X_tfidf_svd = perform_SVD(X_tfidf, n_components=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "X_tfidf_svd_allcos = cosine_similarity(X_tfidf_svd)\n",
    "\n",
    "train_df = pd.DataFrame({'sms':X_train, 'target':y_train})\n",
    "\n",
    "# get spam indexes\n",
    "spam_ix = train_df.loc[train_df['target']=='spam'].index\n",
    "\n",
    "# calculate average spam similarity on SVD\n",
    "mean_spam_sims = []\n",
    "\n",
    "for ix in range(X_tfidf_svd_allcos.shape[0]):\n",
    "    mean_spam_sims.append(np.mean(X_tfidf_svd_allcos[ix, spam_ix]))\n",
    "\n",
    "X_tfidf_svd800_spamcos_scaled = sp.hstack((csr_matrix(mean_spam_sims).T, X_tfidf_svd)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Persist__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "proc_dir = os.path.join(\"data\", \"2_processed\")\n",
    "filename = 'X_tfidf_svd800_spamcos_scaled.npz'\n",
    "sp.save_npz(os.path.join(proc_dir, filename), X_tfidf_svd800_spamcos_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, accuracy_score, recall_score\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_tfidf_svd800_spamcos_scaled,\n",
    "                                                  y, \n",
    "                                                  stratify=y,\n",
    "                                                  random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate estimators\n",
    "log_clf = LogisticRegression(\n",
    "    solver=\"liblinear\"\n",
    "    , random_state=42\n",
    ")\n",
    "\n",
    "rnd_clf = RandomForestClassifier(\n",
    "    n_jobs=-1\n",
    "    , random_state=42\n",
    "    , max_depth=8\n",
    "    , max_features=150\n",
    "    , min_samples_split=3\n",
    "    , n_estimators=100\n",
    ")\n",
    "\n",
    "svm_clf = SVC(\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "svm_clf_prob = SVC(\n",
    "    random_state=42\n",
    "    , probability=True\n",
    ")\n",
    "\n",
    "vot_clf_hard = VotingClassifier(\n",
    "    estimators=[('log', log_clf), ('rnd', rnd_clf), ('svm', svm_clf)]\n",
    "    , voting='hard'\n",
    ")\n",
    "\n",
    "vot_clf_soft = VotingClassifier(\n",
    "    estimators=[('log', log_clf), ('rnd', rnd_clf), ('svm', svm_clf_prob)]\n",
    "    , voting='soft'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quick_eval(classifiers):\n",
    "    for clf in classifiers:\n",
    "        T1 = time.time()\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_val)\n",
    "        mins, secs = divmod(time.time() - T1, 60)\n",
    "        print(clf.__class__, 'acc', round(accuracy_score(y_val, y_pred), 4))\n",
    "        print(clf.__class__, 'tpr', round(recall_score(y_val, y_pred, pos_label=1) , 4))\n",
    "        print(clf.__class__, 'tnr', round(recall_score(y_val, y_pred, pos_label=0), 4))\n",
    "        print(f'{clf.__class__} - train time: {mins:0.0f}m {secs:0.0f}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.linear_model._logistic.LogisticRegression'> acc 0.9723\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'> tpr 0.8062\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'> tnr 0.9976\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'> - train time: 0m 0s\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> acc 0.9887\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> tpr 0.938\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> tnr 0.9965\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> - train time: 0m 9s\n",
      "<class 'sklearn.svm._classes.SVC'> acc 0.959\n",
      "<class 'sklearn.svm._classes.SVC'> tpr 0.6899\n",
      "<class 'sklearn.svm._classes.SVC'> tnr 1.0\n",
      "<class 'sklearn.svm._classes.SVC'> - train time: 0m 24s\n",
      "<class 'sklearn.ensemble._voting.VotingClassifier'> acc 0.9744\n",
      "<class 'sklearn.ensemble._voting.VotingClassifier'> tpr 0.8062\n",
      "<class 'sklearn.ensemble._voting.VotingClassifier'> tnr 1.0\n",
      "<class 'sklearn.ensemble._voting.VotingClassifier'> - train time: 0m 37s\n"
     ]
    }
   ],
   "source": [
    "quick_eval([log_clf, rnd_clf, svm_clf, vot_clf_hard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.svm._classes.SVC'> acc 0.959\n",
      "<class 'sklearn.svm._classes.SVC'> tpr 0.6899\n",
      "<class 'sklearn.svm._classes.SVC'> tnr 1.0\n",
      "<class 'sklearn.svm._classes.SVC'> - train time: 1m 37s\n",
      "<class 'sklearn.ensemble._voting.VotingClassifier'> acc 0.9836\n",
      "<class 'sklearn.ensemble._voting.VotingClassifier'> tpr 0.8837\n",
      "<class 'sklearn.ensemble._voting.VotingClassifier'> tnr 0.9988\n",
      "<class 'sklearn.ensemble._voting.VotingClassifier'> - train time: 1m 48s\n"
     ]
    }
   ],
   "source": [
    "quick_eval([svm_clf_prob, vot_clf_soft])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `.predict` method on the SVM classifier that trains using `probability=True` is just a waste of training time..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even after scaling to help out the logistic classifier, this ensemble still does more poorly than the highly optimized random forest model, which isn't performing its best because of the scaled SVD. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unscaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load previously saved unscaled SVD\n",
    "filename = 'X_tfidf_svd800_spamcos.npz'\n",
    "X_tfidf_svd800_spamcos = sp.load_npz(os.path.join(proc_dir, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_tfidf_svd800_spamcos,\n",
    "                                                  y, \n",
    "                                                  stratify=y,\n",
    "                                                  random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vot_clf_soft_noLR = VotingClassifier(\n",
    "    estimators=[('rnd', rnd_clf), ('svm', svm_clf_prob)]\n",
    "    , voting='soft'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> acc 0.9928\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> tpr 0.969\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> tnr 0.9965\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> - train time: 0m 8s\n",
      "<class 'sklearn.ensemble._voting.VotingClassifier'> acc 0.9867\n",
      "<class 'sklearn.ensemble._voting.VotingClassifier'> tpr 0.9147\n",
      "<class 'sklearn.ensemble._voting.VotingClassifier'> tnr 0.9976\n",
      "<class 'sklearn.ensemble._voting.VotingClassifier'> - train time: 1m 48s\n"
     ]
    }
   ],
   "source": [
    "# only need to test random forest and new soft voting without logistic classifier\n",
    "quick_eval([rnd_clf, vot_clf_soft_noLR])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The unscaled SVD performs better, the logistic classifier was just pulling the voting down."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Thresholds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Briefly comparing the `.predict_proba` and `.predict` methods as `.predict_proba` allows for changing decision thresholds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(probability=True, random_state=42)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_clf_prob.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob = svm_clf_prob.predict_proba(X_val)\n",
    "y_pred = svm_clf_prob.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.991, 0.009],\n",
       "        [0.988, 0.012],\n",
       "        [0.996, 0.004],\n",
       "        [0.   , 1.   ],\n",
       "        [0.992, 0.008],\n",
       "        [0.989, 0.011],\n",
       "        [0.   , 1.   ],\n",
       "        [0.989, 0.011],\n",
       "        [0.993, 0.007],\n",
       "        [0.   , 1.   ]]),\n",
       " array([0, 0, 0, 1, 0, 0, 1, 0, 0, 1]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.set_printoptions(precision=3, suppress=True) \n",
    "y_prob[0:10], y_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_thresh(y_prob, tresh):\n",
    "    y_pred = []\n",
    "    for n, p in y_prob:\n",
    "        if n > tresh:\n",
    "            y_pred.append(0)\n",
    "        else:\n",
    "            y_pred.append(1)\n",
    "    print(f'acc: {accuracy_score(y_val, y_pred):0.4f}')\n",
    "    print(f'tpr: {recall_score(y_val, y_pred, pos_label=1):0.4f}')\n",
    "    print(f'tnr: {recall_score(y_val, y_pred, pos_label=0):0.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.9764\n",
      "tpr: 0.8605\n",
      "tnr: 0.9941\n"
     ]
    }
   ],
   "source": [
    "change_thresh(y_prob, .5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.9774\n",
      "tpr: 0.8760\n",
      "tnr: 0.9929\n"
     ]
    }
   ],
   "source": [
    "change_thresh(y_prob, .6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.9754\n",
      "tpr: 0.8915\n",
      "tnr: 0.9882\n"
     ]
    }
   ],
   "source": [
    "change_thresh(y_prob, .7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.9764\n",
      "tpr: 0.9147\n",
      "tnr: 0.9858\n"
     ]
    }
   ],
   "source": [
    "change_thresh(y_prob, .8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.9713\n",
      "tpr: 0.9302\n",
      "tnr: 0.9775\n"
     ]
    }
   ],
   "source": [
    "change_thresh(y_prob, .9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjusting the class weight according to the data\n",
    "\n",
    "- Alternatively, we could pass `class_weight={0:1, 1:7}` to balance out the classes...\n",
    "- However, on testing `{0:1, 1:7}` and `{0:7, 1:1}` I got similar and confusing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_clf_prob_bal = SVC(\n",
    "    random_state=42\n",
    "    , probability=True\n",
    "    , class_weight='balanced'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(class_weight='balanced', probability=True, random_state=42)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_clf_prob_bal.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob = svm_clf_prob_bal.predict_proba(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.9764\n",
      "tpr: 0.8682\n",
      "tnr: 0.9929\n"
     ]
    }
   ],
   "source": [
    "change_thresh(y_prob, .5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.9764\n",
      "tpr: 0.8760\n",
      "tnr: 0.9917\n"
     ]
    }
   ],
   "source": [
    "change_thresh(y_prob, .6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.9764\n",
      "tpr: 0.8915\n",
      "tnr: 0.9894\n"
     ]
    }
   ],
   "source": [
    "change_thresh(y_prob, .7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.9744\n",
      "tpr: 0.9070\n",
      "tnr: 0.9846\n"
     ]
    }
   ],
   "source": [
    "change_thresh(y_prob, .8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.9692\n",
      "tpr: 0.9225\n",
      "tnr: 0.9764\n"
     ]
    }
   ],
   "source": [
    "change_thresh(y_prob, .9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "__Setting C__: `C=1.0`. If you have a lot of noisy observations you should decrease it: decreasing C corresponds to more regularization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_clf_prob_reg = SVC(\n",
    "    random_state=42\n",
    "    , probability=True\n",
    "    , class_weight='balanced'\n",
    "    , C=.7\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=0.7, class_weight='balanced', probability=True, random_state=42)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_clf_prob_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob = svm_clf_prob_reg.predict_proba(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.9764\n",
      "tpr: 0.8682\n",
      "tnr: 0.9929\n"
     ]
    }
   ],
   "source": [
    "change_thresh(y_prob, .5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.9764\n",
      "tpr: 0.8760\n",
      "tnr: 0.9917\n"
     ]
    }
   ],
   "source": [
    "change_thresh(y_prob, .6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.9754\n",
      "tpr: 0.8915\n",
      "tnr: 0.9882\n"
     ]
    }
   ],
   "source": [
    "change_thresh(y_prob, .7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.9723\n",
      "tpr: 0.9070\n",
      "tnr: 0.9823\n"
     ]
    }
   ],
   "source": [
    "change_thresh(y_prob, .8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.9672\n",
      "tpr: 0.9225\n",
      "tnr: 0.9740\n"
     ]
    }
   ],
   "source": [
    "change_thresh(y_prob, .9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
