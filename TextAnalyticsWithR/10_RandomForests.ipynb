{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forests\n",
    "\n",
    "---\n",
    "\n",
    "*Features*\n",
    "\n",
    "- Add new features\n",
    "\n",
    "*Results*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup & Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Revised on: 2020-12-29\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import urlextract\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "start_time = time.time()\n",
    "dt_object = datetime.fromtimestamp(time.time())\n",
    "day, T = str(dt_object).split('.')[0].split(' ')\n",
    "print('Revised on: ' + day)\n",
    "\n",
    "def load_data(data):\n",
    "    raw_path = os.path.join(\"..\",\"data\",\"1_raw\")\n",
    "    filename = ''.join([data, \".csv\"])\n",
    "    out_dfm = pd.read_csv(os.path.join(raw_path, filename))\n",
    "    out_arr = np.array(out_dfm.iloc[:,0].ravel())\n",
    "    return out_arr\n",
    "\n",
    "X_train = load_data(\"X_train\")\n",
    "y_train = load_data(\"y_train\")\n",
    "\n",
    "y = y_train.copy()\n",
    "\n",
    "# transform y_array into int type\n",
    "y[y=='ham'] = 0\n",
    "y[y=='spam'] = 1\n",
    "y = y.astype('int')\n",
    "\n",
    "# load contractions map for custom cleanup\n",
    "with open(\"contractions_map.json\") as f:\n",
    "    contractions_map = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BoT & Tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import custom.clean_preprocess as cp\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "pipe = Pipeline([('counter', cp.DocumentToNgramCounterTransformer(n_grams=3)),\n",
    "                 ('bot', cp.WordCounterToVectorTransformer(vocabulary_size=2000)),\n",
    "                 ('tfidf', TfidfTransformer(sublinear_tf=True))\n",
    "                ])\n",
    "\n",
    "X_counter = pipe['counter'].fit_transform(X_train)\n",
    "X_bot = pipe['bot'].fit_transform(X_counter)\n",
    "X_tfidf = pipe.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse as sp\n",
    "from scipy.sparse.linalg import svds\n",
    "from sklearn.utils.extmath import svd_flip\n",
    "\n",
    "def perform_SVD(X, n_components=300):\n",
    "    X_array = X.asfptype()\n",
    "    U, Sigma, VT = svds(X_array.T, k=n_components)\n",
    "    # reverse outputs\n",
    "    Sigma = Sigma[::-1]\n",
    "    U, VT = svd_flip(U[:, ::-1], VT[::-1])\n",
    "    # return V \n",
    "    V = VT.T\n",
    "    return V\n",
    "\n",
    "X_svd_bot = perform_SVD(X_bot)\n",
    "X_svd_tfidf = perform_SVD(X_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "X_cossim_svd_bot = cosine_similarity(X_svd_bot)\n",
    "X_cossim_svd_tfidf = cosine_similarity(X_svd_tfidf)\n",
    "\n",
    "train_df = pd.DataFrame({'sms':X_train, 'target':y_train})\n",
    "\n",
    "# get spam indexes\n",
    "spam_ix = train_df.loc[train_df['target']=='spam'].index\n",
    "\n",
    "# calculate average spam similarity on SVD\n",
    "mean_spam_sims_bot, mean_spam_sims_tfidf = [], []\n",
    "\n",
    "for ix in range(X_cossim_svd_bot.shape[0]):\n",
    "    mean_spam_sims_bot.append(np.mean(X_cossim_svd_bot[ix, spam_ix]))\n",
    "    mean_spam_sims_tfidf.append(np.mean(X_cossim_svd_tfidf[ix, spam_ix]))\n",
    "\n",
    "# stack representations\n",
    "X_bot_cossim_bot = sp.hstack((csr_matrix(mean_spam_sims_bot).T, X_bot))\n",
    "X_tfidf_cossim_tfidf = sp.hstack((csr_matrix(mean_spam_sims_tfidf).T, X_tfidf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture output\n",
    "\n",
    "# custom feature engineering module\n",
    "import custom.feature_engineering as Fe\n",
    "\n",
    "try:\n",
    "    clean_train_docs, X_train_feat = Fe.DocumentToFeaturesCounterTransformer().fit_transform(X_train)\n",
    "except Warning as e:\n",
    "    pass # avoids RuntimeErrors because of divisions by zero in calculating means/stds\n",
    "\n",
    "# impute with zeros and remove RSR\n",
    "X_train_feat[np.isnan(X_train_feat)] = 0\n",
    "X_feat = X_train_feat[:,:6] \n",
    "\n",
    "# stack with BoT and SVD of Tfidf\n",
    "X_bot_feat = sp.hstack((X_bot, X_feat))\n",
    "X_svd_feat = sp.hstack((csr_matrix(X_svd_tfidf), X_feat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import make_scorer, accuracy_score, recall_score\n",
    "\n",
    "def scikitlearn_cv(clf, X, y, seed_, cv=5, test_size=.25):\n",
    "    \n",
    "    scorer_ = {\n",
    "        'acc': make_scorer(accuracy_score),\n",
    "        'tpr': make_scorer(recall_score, pos_label=1),\n",
    "        'tnr': make_scorer(recall_score, pos_label=0)\n",
    "    }\n",
    "    \n",
    "    acc = cross_val_score(clf, X, y, cv=cv, verbose=0, scoring=scorer_['acc'], n_jobs=-1)\n",
    "    tpr = cross_val_score(clf, X, y, cv=cv, verbose=0, scoring=scorer_['tpr'], n_jobs=-1)\n",
    "    tnr = cross_val_score(clf, X, y, cv=cv, verbose=0, scoring=scorer_['tnr'], n_jobs=-1)\n",
    "    \n",
    "    return acc.mean(), tpr.mean(), tnr.mean()\n",
    "\n",
    "def collect_cvs(clf, Xs, Xnames, y, seed_, cv=10, test_size=.25):\n",
    "\n",
    "    accs, tprs, tnrs, secs = [], [], [], []\n",
    "    for X in Xs:\n",
    "        start_cv = time.time()\n",
    "        acc, tpr, tnr = scikitlearn_cv(clf, X, y, seed_=seed_, cv=cv, test_size=test_size)\n",
    "        accs.append(round(acc, 4))\n",
    "        tprs.append(round(tpr, 4))\n",
    "        tnrs.append(round(tnr, 4))\n",
    "        secs.append(round(time.time() - start_cv, 1))\n",
    "\n",
    "    data = {'Representation': Xnames,\n",
    "            'mean_accuracy': accs,\n",
    "            'mean_sensitivity': tprs, \n",
    "            'mean_specificity': tnrs,\n",
    "            'elapsed_seconds':secs\n",
    "           }\n",
    "    \n",
    "    return data\n",
    "\n",
    "def build_random_forests(Xs, Xnames, y, cv_seed, rf_seed, mtry_, trees, \n",
    "                         max_leaf_nodes, cv=5, max_samples=None, n_jobs=-1):\n",
    "    \"\"\"Given:\n",
    "           Xs: a list of X representations (training data)\n",
    "           Xnames: a list their names (descriptions)\n",
    "           y: the target variable\n",
    "           cv_seed: random seed for cross validation\n",
    "           rf_seed: random seed for rf classifier\n",
    "           mtry_: a list of values for the max_features param\n",
    "           trees: number of trees\n",
    "           max_leaf_nodes: max number of leaf nodes\n",
    "           cv: number of folds, defaults to k=5\n",
    "           max_samples: max num of samples, defaults to None\n",
    "           n_jobs: defaults to -1 (all cores but one)\n",
    "       Return:\n",
    "           A dataframe of results of cv over various mtry values\n",
    "           With mean accuracy, sensitivity, specificity\n",
    "    \"\"\"\n",
    "    list_of_dfs = []\n",
    "    for mtry in mtry_:\n",
    "        rf_clf = RandomForestClassifier(n_estimators=trees,\n",
    "                                        max_samples=None,\n",
    "                                        max_features=mtry,\n",
    "                                        max_leaf_nodes=max_leaf_nodes,\n",
    "                                        random_state=rf_seed,\n",
    "                                        n_jobs=n_jobs,\n",
    "                                        verbose=0)\n",
    "        \n",
    "        data = collect_cvs(rf_clf, Xs, Xnames, y, seed_=cv_seed, cv=cv)\n",
    "        df = pd.DataFrame(data)\n",
    "        df['mtry'] = mtry\n",
    "        \n",
    "        list_of_dfs.append(df)\n",
    "     \n",
    "    flattened_df = pd.concat(list_of_dfs)\n",
    "    \n",
    "    # reset index\n",
    "    ix_num = len(mtry_) * len(Xs)\n",
    "    flattened_df.index = range(ix_num)\n",
    "    \n",
    "    return flattened_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Gridsearches\n",
    "\n",
    "10-fold CV with on random forest with 500 trees and 99 max leaf nodes on all 7 representations - varying mtry values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs = [\n",
    "      X_bot, \n",
    "      X_tfidf, \n",
    "      X_svd_bot,\n",
    "      X_svd_tfidf,\n",
    "      X_bot_feat,\n",
    "      X_svd_feat,\n",
    "      X_bot_cossim_bot, \n",
    "      X_tfidf_cossim_tfidf\n",
    "     ]\n",
    "\n",
    "Xnames = [\n",
    "          'BoT', \n",
    "          'Tfidf', \n",
    "          'SVD on BoT'\n",
    "          'SVD on Tfidf', \n",
    "          'BoT + features',\n",
    "          'SVD + features',\n",
    "          'Cossim on BoT',\n",
    "          'Cossim on Tfidf'\n",
    "         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cv_data1 = build_random_forests(Xs, \n",
    "#                                Xnames, \n",
    "#                                y, \n",
    "#                                cv_seed=423, \n",
    "#                                rf_seed=514, \n",
    "#                                mtry_=[5, 10, 20, 25, 40 , 50, \n",
    "#                                       75, 100, 150, 200, 250, \n",
    "#                                       300, 350, 400, 450, None],\n",
    "#                                trees=500, \n",
    "#                                max_leaf_nodes=99, \n",
    "#                                cv=10)\n",
    "\n",
    "# arrays must be of same length --- try smaller CVs, try printing more "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_data2 = build_random_forests(Xs, \n",
    "                                Xnames, \n",
    "                                y, \n",
    "                                cv_seed=423, \n",
    "                                rf_seed=514, \n",
    "                                mtry_=[10, 25, 50, 100, 250, \n",
    "                                       500, None],\n",
    "                                trees=1000, \n",
    "                                max_leaf_nodes=99, \n",
    "                                cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_data1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Results*\n",
    "\n",
    "- SVD on Tfidf takes the longest, and sensitivity isn't improving nor better\n",
    "- Cosine Similarities on Tfidf have the best sensitivities\n",
    "\n",
    "*Decision*\n",
    "\n",
    "- ditch SVD on Tfidf\n",
    "- try SVD on BoT\n",
    "- try rest of cosine similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
