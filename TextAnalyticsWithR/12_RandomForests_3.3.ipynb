{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forests 3\n",
    "\n",
    "---\n",
    "\n",
    "__This Notebook__:\n",
    "\n",
    "- performs 3 grid searches:\n",
    "\n",
    "    10. X_bot_tfidf_svd_cos\n",
    "    11. X_bot_tfidf_svd_feat\n",
    "    12. X_bot_tfidf_svd_feat_cos\n",
    "  \n",
    "  \n",
    "__Command Line__:\n",
    "\n",
    "I also ran the `X_bot` again since I accidentally overwrote that grid search:\n",
    "\n",
    "```\n",
    "$python run_gridsearches.py\n",
    "Training 1: X_bot...\n",
    "Elapsed: 1630 s\n",
    "Best params: {'max_depth': 20, 'max_features': 500, 'min_samples_split': 5, 'n_e\n",
    "stimators': 100}\n",
    "Confusion matrix on validation set:\n",
    "     pred_neg  pred_pos\n",
    "neg       843         3\n",
    "pos        15       114\n",
    "Evaluation metrics:\n",
    "accuracy: 0.9815\n",
    "sensitivity: 0.8837\n",
    "specificity: 0.9965\n",
    "\n",
    "Tot elapsed: 27 m 10 s\n",
    "```\n",
    "\n",
    "It took long because I used `n_jobs=4`. This got saved as `01062021_rf_gridsearches_3.joblib` in the `data/3_modeling/` folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Revised on: 2021-01-12\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "import joblib\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "\n",
    "from datetime import datetime\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import make_scorer, recall_score, accuracy_score, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "dt_object = datetime.fromtimestamp(time.time())\n",
    "day, T = str(dt_object).split('.')[0].split(' ')\n",
    "print('Revised on: ' + day)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load target\n",
    "raw_path = os.path.join(\"data\",\"1_raw\")\n",
    "filename = \"y_train.csv\"\n",
    "y = pd.read_csv(os.path.join(raw_path, filename))\n",
    "y = np.array(y.iloc[:,0].ravel())\n",
    "y[y=='ham'] = 0\n",
    "y[y=='spam'] = 1\n",
    "y = y.astype('int')\n",
    "\n",
    "# load 12 matrices\n",
    "proc_dir = os.path.join(\"data\",\"2_processed\")\n",
    "Xnames = [x for x in os.listdir(proc_dir) if re.search('.npz', x)]\n",
    "Xs = []\n",
    "for ix, X in enumerate(Xnames):\n",
    "    path_ = os.path.join(proc_dir, Xnames[ix])\n",
    "    Xs.append(sp.load_npz(path_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 X_bot\n",
      "2 X_bot_feat\n",
      "3 X_bot_svd\n",
      "4 X_bot_svd_cos\n",
      "5 X_bot_svd_feat\n",
      "6 X_bot_svd_feat_cos\n",
      "7 X_bot_tfidf\n",
      "8 X_bot_tfidf_feat\n",
      "9 X_bot_tfidf_svd\n",
      "10 X_bot_tfidf_svd_cos\n",
      "11 X_bot_tfidf_svd_feat\n",
      "12 X_bot_tfidf_svd_feat_cos\n"
     ]
    }
   ],
   "source": [
    "# 12 representations\n",
    "for ix, Xname in enumerate(Xnames):\n",
    "    Xname = Xname.split('.')[0]\n",
    "    print(ix+1, Xname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid search random forest models\n",
    "\n",
    "Using sklearn's GridSearchCV with 10-fold cross validation on a shallow param grid, varying representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_eval_metrics(y_val, y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_val, y_pred).ravel()\n",
    "    acc = (tp + tn) / (tp + tn + fp + fn)\n",
    "    tpr = tp / (tp + fn)\n",
    "    tnr = tn / (tn + fp)\n",
    "    print(f'accuracy: {acc:0.4f}')\n",
    "    print(f'sensitivity: {tpr:0.4f}')\n",
    "    print(f'specificity: {tnr:0.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gridsearch_wrapper(Xs, Xnames, test=False, k=10):\n",
    "    \"\"\"\n",
    "    Performs grid searches and collects them in a list.\n",
    "    Args:\n",
    "        Xs: the numeric matrices\n",
    "        Xnames: their names\n",
    "        test: faster, shallower searches for testing\n",
    "        k: the number of CV folds\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    model_dir = os.path.join(\"data\", \"3_modeling\")\n",
    "    \n",
    "    # instantiate list of dicts to gather results\n",
    "    gridsearches = []\n",
    "    for ix, X_name in enumerate(Xnames):\n",
    "\n",
    "        X_ = Xs[ix].toarray()\n",
    "        X_name = X_name.split('.')[0]\n",
    "\n",
    "        # split into training and validation sets\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X_, y, stratify=y)\n",
    "\n",
    "        # setup testing param grid\n",
    "        test_param_grid = {\n",
    "            'min_samples_split': [5, 10, 20], \n",
    "            'n_estimators' : [50, 100],\n",
    "            'max_depth': [10, 20],\n",
    "            'max_features': [50, 100, 200]\n",
    "        }\n",
    "\n",
    "        # setup param grid for final not-too-deep search\n",
    "        param_grid = {\n",
    "            'min_samples_split': [5, 10, 15],\n",
    "            'n_estimators' : [100, 200],\n",
    "            'max_depth': [5, 10, 20],\n",
    "            'max_features': [50, 100, 250, 500]\n",
    "        }\n",
    "\n",
    "        # setup scorers\n",
    "        scorers = {\n",
    "            'acc': make_scorer(accuracy_score),\n",
    "            'tpr': make_scorer(recall_score, pos_label=1), # sensitivity, recall\n",
    "            'tnr': make_scorer(recall_score, pos_label=0) # specificity, selectivity\n",
    "        }\n",
    "\n",
    "        # instantiate estimator\n",
    "        clf = RandomForestClassifier(n_jobs=-1, random_state=42)\n",
    "\n",
    "        # instantiate k-fold gridsearch\n",
    "        cv_folds = StratifiedKFold(n_splits=k)\n",
    "    \n",
    "        if test == True:\n",
    "            grid_search_clf = GridSearchCV(clf, test_param_grid, # test grid\n",
    "                                           scoring=scorers, \n",
    "                                           refit='tpr', cv=cv_folds, \n",
    "                                           return_train_score=True, n_jobs=-1)\n",
    "        else:\n",
    "            grid_search_clf = GridSearchCV(clf, param_grid,\n",
    "                                           scoring=scorers, \n",
    "                                           refit='tpr', cv=cv_folds, \n",
    "                                           return_train_score=True, n_jobs=-1)           \n",
    "\n",
    "        # train models\n",
    "        print(f'\\nTraining {ix+1}: {X_name}...')\n",
    "        start_gs = time.time()\n",
    "        grid_search_clf.fit(X_train, y_train)\n",
    "        elapsed_secs = time.time() - start_gs\n",
    "        print(f'Elapsed: {elapsed_secs:0.0f} s')\n",
    "\n",
    "        # predict\n",
    "        y_pred = grid_search_clf.predict(X_val)\n",
    "        print(f'Best params: {grid_search_clf.best_params_}')\n",
    "\n",
    "        # confusion matrix on validation set\n",
    "        print(f'Confusion matrix on validation set:')\n",
    "        print(pd.DataFrame(confusion_matrix(y_val, y_pred),\n",
    "                           columns=['pred_neg', 'pred_pos'],\n",
    "                           index=['neg', 'pos']))\n",
    "        # eval metrics\n",
    "        print('Evaluation metrics:')\n",
    "        print_eval_metrics(y_val, y_pred)\n",
    "\n",
    "        data = {'representation':X_name,\n",
    "                'gridsearch_res':grid_search_clf}\n",
    "        \n",
    "        # save gridsearch\n",
    "        filename = ''.join([str(ix+1), \"_\", X_name, \"_rf_gridsearch.joblib\"])\n",
    "        file_path = os.path.join(model_dir, filename)                                                    \n",
    "        joblib.dump(data, file_path)\n",
    "        \n",
    "        # gather results into a list of dicts\n",
    "        gridsearches.append(data)\n",
    "        \n",
    "    mins, secs = divmod(time.time() - start_time, 60)\n",
    "    print(f'\\nTot elapsed: {mins:0.0f} m {secs:0.0f} s')\n",
    "    return gridsearches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['X_bot_tfidf_svd_cos.npz',\n",
       " 'X_bot_tfidf_svd_feat.npz',\n",
       " 'X_bot_tfidf_svd_feat_cos.npz']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xnames[9:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training 1: X_bot_tfidf_svd_cos...\n",
      "Elapsed: 5297 s\n",
      "Best params: {'max_depth': 5, 'max_features': 250, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "Confusion matrix on validation set:\n",
      "     pred_neg  pred_pos\n",
      "neg       838         8\n",
      "pos        18       111\n",
      "Evaluation metrics:\n",
      "accuracy: 0.9733\n",
      "sensitivity: 0.8605\n",
      "specificity: 0.9905\n",
      "\n",
      "Training 2: X_bot_tfidf_svd_feat...\n",
      "Elapsed: 3315 s\n",
      "Best params: {'max_depth': 20, 'max_features': 250, 'min_samples_split': 15, 'n_estimators': 100}\n",
      "Confusion matrix on validation set:\n",
      "     pred_neg  pred_pos\n",
      "neg       845         1\n",
      "pos        15       114\n",
      "Evaluation metrics:\n",
      "accuracy: 0.9836\n",
      "sensitivity: 0.8837\n",
      "specificity: 0.9988\n",
      "\n",
      "Training 3: X_bot_tfidf_svd_feat_cos...\n",
      "Elapsed: 3473 s\n",
      "Best params: {'max_depth': 10, 'max_features': 100, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "Confusion matrix on validation set:\n",
      "     pred_neg  pred_pos\n",
      "neg       842         4\n",
      "pos        16       113\n",
      "Evaluation metrics:\n",
      "accuracy: 0.9795\n",
      "sensitivity: 0.8760\n",
      "specificity: 0.9953\n",
      "\n",
      "Tot elapsed: 201 m 25 s\n"
     ]
    }
   ],
   "source": [
    "results = gridsearch_wrapper(Xs=Xs[9:], Xnames=Xnames[9:], test=False, k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Persist results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'representation': 'X_bot_tfidf_svd_cos',\n",
       "  'gridsearch_res': GridSearchCV(cv=StratifiedKFold(n_splits=10, random_state=None, shuffle=False),\n",
       "               estimator=RandomForestClassifier(n_jobs=-1, random_state=42),\n",
       "               n_jobs=-1,\n",
       "               param_grid={'max_depth': [5, 10, 20],\n",
       "                           'max_features': [50, 100, 250, 500],\n",
       "                           'min_samples_split': [5, 10, 15],\n",
       "                           'n_estimators': [100, 200]},\n",
       "               refit='tpr', return_train_score=True,\n",
       "               scoring={'acc': make_scorer(accuracy_score),\n",
       "                        'tnr': make_scorer(recall_score, pos_label=0),\n",
       "                        'tpr': make_scorer(recall_score, pos_label=1)})},\n",
       " {'representation': 'X_bot_tfidf_svd_feat',\n",
       "  'gridsearch_res': GridSearchCV(cv=StratifiedKFold(n_splits=10, random_state=None, shuffle=False),\n",
       "               estimator=RandomForestClassifier(n_jobs=-1, random_state=42),\n",
       "               n_jobs=-1,\n",
       "               param_grid={'max_depth': [5, 10, 20],\n",
       "                           'max_features': [50, 100, 250, 500],\n",
       "                           'min_samples_split': [5, 10, 15],\n",
       "                           'n_estimators': [100, 200]},\n",
       "               refit='tpr', return_train_score=True,\n",
       "               scoring={'acc': make_scorer(accuracy_score),\n",
       "                        'tnr': make_scorer(recall_score, pos_label=0),\n",
       "                        'tpr': make_scorer(recall_score, pos_label=1)})},\n",
       " {'representation': 'X_bot_tfidf_svd_feat_cos',\n",
       "  'gridsearch_res': GridSearchCV(cv=StratifiedKFold(n_splits=10, random_state=None, shuffle=False),\n",
       "               estimator=RandomForestClassifier(n_jobs=-1, random_state=42),\n",
       "               n_jobs=-1,\n",
       "               param_grid={'max_depth': [5, 10, 20],\n",
       "                           'max_features': [50, 100, 250, 500],\n",
       "                           'min_samples_split': [5, 10, 15],\n",
       "                           'n_estimators': [100, 200]},\n",
       "               refit='tpr', return_train_score=True,\n",
       "               scoring={'acc': make_scorer(accuracy_score),\n",
       "                        'tnr': make_scorer(recall_score, pos_label=0),\n",
       "                        'tpr': make_scorer(recall_score, pos_label=1)})}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data\\\\3_modeling\\\\01062021_rf_gridsearches_2`.joblib']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dir = os.path.join(\"data\", \"3_modeling\")\n",
    "file_path = os.path.join(model_dir, \"\".join([\"01062021\", \"_rf_gridsearches_2`.joblib\"]))\n",
    "\n",
    "# save all gridsearches\n",
    "joblib.dump(results, file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
