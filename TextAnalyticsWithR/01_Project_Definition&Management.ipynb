{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing\n",
    "\n",
    "\n",
    "## Structure\n",
    "\n",
    "1. define the problem, set expectations, include evaluation criteria\n",
    "2. preliminary and minimal EDA and pre-splitting cleanup\n",
    "3. split dataset into trainining and test subsets; set the test subset aside\n",
    "4. create a cleanup and preprocessing pipeline for the training data that can be re-applied to the test data\n",
    "5. train a couple baseline models to ensure process is smooth and pre-processing is dialed in\n",
    "6. using cross-validation, evaluate a variety models without hyperparameter tuning to establish some baselines\n",
    "7. short-list promising models for further hyperparemeter tuning\n",
    "8. iterate on any phase of the project as needed\n",
    "9. consider feature selection and feature engineering (this can be done earlier)\n",
    "10. decide on a final cleanup and processing pipeline\n",
    "11. settle on a final model\n",
    "12. re-apply all cleanup and processing steps to the test set and evaluate final model - once\n",
    "13. create a final presentation of the solution for technical and non-technical audiences\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition\n",
    "\n",
    "*Primary Goals*\n",
    "\n",
    "- create a portfolio-worthy project\n",
    "- start a portfolio of projects online (perhaps beyond GitHub)\n",
    "\n",
    "*Secondary Goals*\n",
    "\n",
    "- learn NLP\n",
    "- practice ML: build classifiers for unstructured, text data\n",
    "\n",
    "*Tertiary Goals*\n",
    "\n",
    "- recreate the 'Intro To Text Analytics With R' project in Python\n",
    "- repurpose and generalize the NLP-ML workflow with Twitter data\n",
    "\n",
    "*Evaluation Criteria*\n",
    "\n",
    "- accuracy, precision-recall curves, possibly MCC\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Management\n",
    "\n",
    "#### Status History\n",
    "\n",
    "*Notebook 3: Tfidf*\n",
    "\n",
    "- $97.5\\%$ accuracy with a Tfidf matrix of 450 unigram terms on sklearn's baseline logistic classifier.\n",
    "\n",
    "*Notebook 4: Bigrams*\n",
    "\n",
    "- $98.5\\%$ accuracy with a Bag-of-(upto)-Bigrams of 2,000 terms on sklearn's baseline logistic classifier.\n",
    "\n",
    "*Notebook 5: Ngrams*\n",
    "    \n",
    "- no clear improvement over previous representation and model after grid searches and evaluation plots.\n",
    "    \n",
    "*Notebook 6: Dimensionality Reduction*\n",
    "\n",
    "- SVD on Tfidf or Bag-of-Bigams do not differ as far as accuracy with the baseline classifier\n",
    "- accuracy is lower than using original data - it remains to be seen whether SVD with new features and more complex models improves accuracy\n",
    "\n",
    "*Notebook 7: Feature Engineering*\n",
    "\n",
    "- After visualizations, the first feature (raw document length) appears to be the most useful in separating the target\n",
    "\n",
    "*Notebook 8: Comparing Representations*\n",
    "\n",
    "- Keep best two representations:\n",
    "    * Bag-of-upto-Bigrams with 2,000 terms\n",
    "    * SVD on the bigrams above + document length - for testing with more complex models\n",
    "\n",
    "\n",
    "#### Current Status\n",
    "\n",
    "- Revisit R Analytis: create a Cosine Similarity feature\n",
    "\n",
    "\n",
    "#### Future Steps\n",
    "\n",
    "- Finalize cleanup pipeline:\n",
    "    * maybe use a .py script\n",
    "    \n",
    "    \n",
    "- Modeling\n",
    "- Evaluation\n",
    "- Presentation\n",
    "\n",
    "#### Topic Modeling\n",
    "\n",
    "- Latent Dirichlet Allocation (LDA)\n",
    "- lda2Vec (word2vec)\n",
    "\n",
    "#### Statistical Modeling\n",
    "\n",
    "- SGD\n",
    "- Decision Trees\n",
    "- Random Forests\n",
    "- Boosting\n",
    "- SVC\n",
    "- Ensembles\n",
    "\n",
    "#### Feature Selection\n",
    "\n",
    "- Random Forest + VarImp plot \n",
    "- LASSO\n",
    "\n",
    "#### Evaluation\n",
    "\n",
    "- MCC\n",
    "- confusion matrix\n",
    "- specific predictions\n",
    "\n",
    "#### Thoughts\n",
    "\n",
    "- what's the use case?\n",
    "- what about using TextBlob?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
